Volume 31 Issue 4 Article 16 
The Pr e-Processing of W T Blade Images b y SS and Bilater al Filter with The Pr e-Processing of W T Blade Images b y SS and Bilater al Filter with 
Machine Learning F rameworks Machine Learning F rameworks 
Joy Iong-Z ong Chen 
Depar tment of Electrical Engineering, Da-Y eh Univ ersity , No. 168 Univ ersity Rd., Dacun, Changhua 51591, T aiwan , 
jchen@mail.dyu.edu.tw 
Chien-Y eh Lee 
Depar tment of Electrical Engineering, Da-Y eh Univ ersity , No. 168 Univ ersity Rd., Dacun, Changhua 51591, T aiwan 
Wien-Chieh Lo 
Depar tment of Electrical Engineering, Da-Y eh Univ ersity , No. 168 Univ ersity Rd., Dacun, Changhua 51591, T aiwan 
Follow this and additional works at: https:/ /jmstt.nt ou.edu.tw/journal 
 Part of the Fresh W ater Studies Commons , Marine Biology Commons , Ocean Engineering Commons , 
Oceanogr aphy Commons , and the Other Oceanogr aphy and A tmospheric Sciences and Meteor ology Commons 
Recommended Citation Recommended Citation 
Chen, Jo y Iong-Z ong; Lee, Chien-Y eh; and Lo, Wien-Chieh (2023) "The Pr e-Processing of W T Blade Images b y SS and 
Bilater al Filter with Machine Learning F rameworks, " Journal of Marine Science and T echnology : Vol. 31: Iss. 4, Ar ticle 
16. 
DOI: 10.51400/2709-6998.2724 
Available at: https:/ /jmstt.nt ou.edu.tw/journal/v ol31/iss4/16 
This Resear ch Ar ticle is br ought t o you for fr ee and open access b y Journal of Marine Science and T echnology . It has been 
accepted for inclusion in Journal of Marine Science and T echnology b y an authoriz ed edit or of Journal of Marine Science and 
Technology . 
------------------------------End of the page -----------------------------------
RESEARCH ARTICLE
The Pre-processing of WT Blade Images by SS and
Bilateral Filter with Machine Learning Frameworks
Joy Iong-Zong Chen *, Chien-Yeh Lee, Wien-Chieh Lo
Department of Electrical Engineering, Da-Yeh University, No. 168 University Rd., Dacun, Changhua 51591, Taiwan
Abstract
This paper discusses the motivation behind turbine migration and addresses the challenges of using NN (neural
network) computing systems. Moreover, it focuses on high-dimensional data from WT (wind turbine) blades. The threekey aspects addressed in this study are turbine migration, over ﬁtting, and strict feature selection. To evaluate the per-
formance of the machine learning system, the study considers the characteristics of WT blades, speci ﬁcally the similarity
in blade color and the differences in shape. The authors apply pre-processing techniques, in particular a bilateral ﬁlter,
in conjunction with the SS (selective synthesizer) of blade fouling patterns. The SS method adopts the framework of
ResNet50 to evaluate the computational ef ﬁciency. The experimental results show that the introduction of the SS method
for feature selection improves the accuracy rate of the NN model to over 92 %. For data validation, the study employs theYOLO (You Only Look Once) deep learning framework. Speci ﬁcally, YOLOv4-Tiny is used due to its trade-off between
recognition speed and accuracy. In addition, YOLOv4-Tiny was integrated with the Nvidia Jetson Nano edge computing
hardware. Overall, the article focuses on the use of machine learning techniques, such as preprocessing and feature
selection, to improve the performance of NN computing systems in analyzing high-dimensional data from WT blades.The authors validate their approach using the YOLO framework, speci ﬁcally YOLOv4-Tiny, and highlight the inte-
gration with Nvidia Jetson Nano for edge computing.
Keywords: Bilateral ﬁlter, Selective synthesizer, WT (wind turbine) blades, YOLOv4-Tiny model
1. Introduction
To maintain power generation ef ﬁciency and
safe operation of WT (wind turbine), regular
inspection of WT blades is necessary. According torecent market research, the revenue generated bythe widespread use of UAVs (Unmanned AerialVehicles) is expected to exceed $8.5 billion by 2027.In addition, the UAV-based architectures areexplored for the development and implementation
of next-generation technologies such as 5G, V2X
(vehicle-to-everything) communications, etc. [ 1].
The current status of wind power development inTaiwan, at present an important indicator of thecountry 's energy policy is that the government
hopes to achieve the goal of a non-nuclear home-land by 2025. In 2025, the proportion of renewableenergy power generation can account for more than
20 % of the country 's total power generation. The
beneﬁts of installations are more economical in
scale, and solar power generation faces problemssuch as power generation ef ﬁciency land acquisition
difﬁculties, and the reduction of wholesale elec-
tricity prices. Currently, the demand for construc-
tion is gradually slowing down, and wind powergeneration is gradually becoming a developmentdue to issues such as offshore wind turbines.Renewable energy is an important option. With in-ternational wind turbine manufacturers, Taiwan hasbecome the focus of offshore wind power develop-ment in the Asia region, which was discussed in the
literature [ 2].
The blade is one of the most important compo-
nents embedded into the WT skeleton. Compared
Received 15 April 2023; revised 12 November 2023; accepted 13 November 2023.
Available online 15 December 2023
*Corresponding author.
E-mail addresses: jchen@mail.dyu.edu.tw (J.I.-Z. Chen), D1003004@cloud.dyu.edu.tw (C.-Y. Lee), lowctwan@gmail.com (W.-C. Lo).
https://doi.org/10.51400/2709-6998.2724
2709-6998/ ©2023 National Taiwan Ocean University.
------------------------------End of the page -----------------------------------
with other wind turbine components, the test or
certiﬁcation requirements for wind turbine blades
are the most stringent. Different wind farm envi-ronments present different challenges. In Europeanwind farms, when it is extremely cold in winter, theblades can freeze and not rotate. At the wind farmlocated in Taiwan, the blades may rotate too fast andcause thermal damage when a typhoon is raging in
summer. It is known that the risk could happen
surrounding the WT, thus, addressing the event ofexactly inspecting the safety of WT blades is a crit-ical issue. Recently, machine learning techniqueshave been applied to the inspection of WT bladesthat followed. The paper by [ 3] empirically in-
vestigates the performance of state-of-the-art deeplearning algorithms, namely, YOLOv3, YOLOv4,
and Mask R eCNN for defect detection and classi-
ﬁcation by type. The paper proposes new perfor-
mance evaluation measures suitable for defectdetection tasks, and these include Prediction BoxAccuracy, Recognition Rate, and False Label Rate.Experiments were carried out using a dataset, pro-vided by the industrial partner, that contains imagesfrom WTB inspections. A YOLOv4-based wind tur-
bine blade crack detection method is proposed in [ 4]
which ﬁrstly establishes the WT blade crack image
dataset, then the anchor box parameters in YOLOv4are optimized by K-means
þþalgorithm to make the
anchor box parameters match the crack defect size.Besides, a novel SHM (structural health monitoring)methodology that takes advantage of the fact thatthe WT blades are nominally identical in structural
properties is proposed in [ 5]. The methodology is
used to predict the edge frequencies of one bladegiven that of another after these relationships be-tween the pairs of blades have been learned whenthe blades are in a healthy state. Recently, a fast WTdefect detection model has been proposed with aCascade Mask R eCNN (Region Convolutional
Neural network) [ 6]. Instead of the standard
convolution in the backbone network of Cascade
Mask R eCNN, a depth separable convolution is
used to minimize the computational cost. Theexperimental results announced that the proposedWT blade defect detection and classi ﬁcation model
shows better performance with 82.42 % MAP, and97.8 % classi ﬁer accuracy.
To capture wind energy and to propose an auto-
mated visual inspection system for WTB are
completed in [ 7,8], respectively. In the former, the
human mind must rely on both hands to performactions or designations, and an improved YOLO (YouOnly Look Once) model is developed with a deeplearning framework in the latter. To achieve practi-cally acceptable detection accuracy for small-sizeddefects on WTB, they utilized a database of 23,807
images annotated with three types of defects: cracks,oil, and sand inclusions. The comprehensive review in[9] provides the state-of-the-art embedded sensors,
communication technologies, computing platforms,and machine learning techniques used in autono-mous UAVs. The key performance metrics along withoperating principles and a detailed comparative study
of the various technologies are also studied and pre-
sented. Besides, to test the applicability of acquiringaccuracy, in [ 10] the random forest machine learning
algorithm for classi ﬁcation processing is presented. It
is applied with radiometric features and geometriccharacteristics derived from covariance features(curvature, omnivariance, ﬂatness, linearity, surface
variance, anisotropy, and normalized terrain surface)
of points. There a DL-based method for UAV detec-
tion in pulse-Doppler radar is proposed in [ 11]. It
considers the position offset of the target to the centerof the local window which method designs a CNNwith not only a classi ﬁcation head but also a regression
head to achieve the precise location of the target forUAV detection. Moreover, based on backgroundremoval a preprocessing method is proposed in [ 12]t o
overcome the drawbacks of image blurring occurring
at WT blades. The idea of the method is to carry outimage segmentation to get the background part, andthen the intensities of pixels in the background partare replaced by the same value. The robustness of theparameters and the capability of image stitching of theproposed method is well veri ﬁed. For solving the
existing problems of stability, sensor installation, and
data storage and processing. A novel blade inspection
method based on deep learning and unmanned aerialvehicles is proposed in [ 13]. Onsite visual surface in-
spection is still the most common inspection methodsince most studies of WT blade inspection focusattention on acquired sensor signal processing. It isinefﬁcient and requires a long downtime. The con-
tents of [ 14] put forward a set WT blade detection
method based on an arti ﬁcial intelligence image
recognition system. A lot of image acquisition pro-cessing is carried out for WT blades in service with thehelp of high-de ﬁnition camera array and image
recognition software. Eventually, the automaticdetection of blade surface defects is realized.
Based on the vibration signal of the shaft bearings
during multi-SVM (support vector machine) process,
a multi-class SVM and a CNN were employed for
fault diagnosis and the RUL (remaining useful life)prediction of the shaft bearings used in WT [ 15]. In
addition, the authors in [ 16,17] also applied a similar
algorithm framework to detect WT blade defects andobtained similar and excellent research results. Theeffectiveness of the YOLO algorithm in the detection540 JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552
------------------------------End of the page -----------------------------------
of WT blades has never been found in the afore-
mentioned studies. Based on the self-assessment ofthe risk analysis score sheet and the re-assessment bythe director of the ﬁre department in the onshore
wind power area and the business unit, the expertsassessed the higher hazard risks including bladestructure breakage (risk level >3) and falling (risk
level >3), unit structure Collapses (risk level >3) and
adjacent site ﬁres cause structural damage to wind
power. Due to structural damage or deterioration, theblades are prone to breakage, cracking, falling, andother risk factors. After falling, it is easy to causedamage to power facilities and cause electrical ﬁres.
Therefore, it is recommended to implement regularinspections of WT blades [ 18,19].
Speci ﬁcally, in this study, an algorithm is proposed
not only to overcome the problems with high-
dimensional data and data over ﬁtting but also the SS
(selective synthesizer) scheme is used to ﬁnd solu-
tions and address the limitation of NN (neuralnetwork) computation for recognition the WT bladespossible damage. On the other hand, the motivationof this study is to propose a novel method by using ofBilateral ﬁlter [ 24] for image pre-processing to
improve the effectiveness and ef ﬁciency of TW blade
detection and identi ﬁcation. The provided research
data is screened for data elements. That is, thisinvestigation is mainly based on the image data ofWT blade contamination identi ﬁcation and the
detection of WT blades. The classi ﬁcation of hazards
such as “blade structure ”and“unit structure ”in
“Hazard Identi ﬁcation and Risk of Personnel in Adjacent
Areas”by structure and a high-correlation pre-pro-
cessing study is proposed. Executed by a host com-puter with image processing unit GPU (graphicalprocessing unit) computing speed, and a largenumber of original data rooms come from commer-cial wind farms [ 21,22], and through the website [ 9]
which provides images of WT blade. Thus, the WTblade identi ﬁcation practice can enter the mold
Group establishment and veri ﬁcation phase. The WT
blade image pre-processing detection algorithm anddevelopment results proposed in this article, it isenough to help the wind farm blade mutation iden-tiﬁcation accuracy successfully reach more than 90 %.
Traditional image preprocessing systems, whose re-quirements for preprocessing deep learning models,are RGB images belonging to databases of any size.
Since the leaf map to be used in this investigation is
not the expected data in the investigation, it is theoriginal map provided by the external undeterminedform, and it is believed that the content of the mapcontains various leaf forms, not the only one.
Therefore, to improve the accuracy of the ﬁnal WT
blade defect identi ﬁcation and reduce the loss rateof data training, it is necessary to signi ﬁcantly
improve image uniformity and obtain the bene ﬁts of
peer-to-peer training. The captured images usuallyhave different image features. If the training processproduces gradient dissipation or gradient diver-gence, the identi ﬁcation number may not be con-
verted correctly [
22]. This image pre-processing
platform is established to solve this problem.
The rest of the paper is divided into four sections
described as follows, after the introduction section, theproblems and requirements of land WT blades arediscussed in section II. In section III the pre-process-ing of the WT blades with normal (A) and damaged (B)WT is investigated. Apart from this, the discussion ofthe Bilateral ﬁlter and the SVD techniques for the
proposed DNN-LSTM framework is presented in
section IV. Eventually, the experiments plus results
and a brief conclusion are presented in section VI.
2. Description of problems and requirements
In this section, the critical issues of the possible
fact caused by the WT blade will be explained indetail. Hazard identi ﬁcation and risk assessment of
land-based WT blades will also be discussed. Many
useful theoretical techniques are also included, such
as the SS scheme.
2.1. Discussion of possible problems happen in
damage of WT blades
Through the risk analysis method, the damage of
WT blades in the land area is used to determine the
risk factors of damage to the adjacent areas. Through
the disaster risk analysis, the disaster risk factors withhigh destructive force are locked, and then the highrisk factors are analysed for the application of disasterprevention and early warning in the wind powersystem with bene ﬁts. Therefore, the prerequisite of
this study is ﬁrst to understand the results of the
hazard from the craft of WT blade, which includes,
(1).The Identi ﬁcation of the factors ,
Investigate all possibilities of blade fall, compile
and list all conditions for risk assessment, thendiscuss with experts and scientists, eliminate,conﬁrm and integrate all equipment and processes
that need to be assessed.
(2).The Identi ﬁcation of possible hazards and
consequences
Deﬁne the classi ﬁcation or type of potential haz-
ards according to the characteristics of each type ofhazard, and identify all potential hazards, theirJOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552 541
------------------------------End of the page -----------------------------------
causes and the reasonable and most serious conse-
quences according to the accident (risk) classi ﬁca-
tion as hazard identi ﬁcation.
(3).The assessment of the risk of all hazards ,
The following factors must be taken into account
when assessing the possibility of establishing a
reference example for the possibility classi ﬁcation
benchmark, such as the level of hazard, the fre-quency, and duration of exposure to the hazard, etc.For example, if the frequency of exposure or durationof exposure is higher, the likelihood of a hazardousevent will be higher. For example, if the frequency ofexposure is higher or the duration of exposure islonger, the likelihood of a hazard event will be higher.
(4).Theassessment of the hazard risk severity,
The following factors must be considered in
evaluating the severity to establish a referenceexample of the severity grading benchmark.
(a) The parts of nearby people who may be injured
or affected, the number of people injured, etc.
(b) The degree of injury, such as death, permanent
disability, temporary disability, ﬁrst aid treat-
ment, etc.
Finally, the various hazard factors that can cause
WT blades to fall are listed separately for each
possible hazard type, and the situation or process inwhich the consequences can occur is also describedin detail. The severity and risk levels are evaluated,and a risk assessment table is produced in Table I .
Generally speaking, in the technical application
framework of machine learning, if it needs to beapplied to dynamic image recognition, YOLO neu-
ral modules are the best choice. In addition, to
reduce the dynamic error caused by dynamicorientation, the YOLO module can avoid the prob-lem of excessive loss of image data caused by theabove-mentioned error. Based on the above dis-cussion, some measures have been taken for thisresearch, because the goal to be achieved accordingto this research is to identify the fouling of WT
blades in an instantaneous and dynamic environ-ment. Therefore, this research uses the YOLOmodule in the training process of the actual veri ﬁ-
cation image data, on the one hand, it can reducethe signal training loss of the dynamic error. On theother hand, it is also expected that in the real-timeand dynamic condition environment, more accurate
training modules can be obtained and the accuracy
can be improved, which is helpful to the researchobject. On the other hand, 3 points can be madeabout the advantages of YOLO. The ﬁrst point is
that YOLO has a strong spatial constraint on thebounding box. If there are more than two objectsthat are very close in space, the model cannot beeffectively trained. Secondly, when the trained
model is asked to predict other new objects or ob-
jects with odd proportions, it may not be able toframe them well. Part of the reason for this is thatYOLO itself has many layers of pooling (down-sampling). The last feature is used to predict thebounding box, which is relatively coarse in spacecompared to the original image. Finally [ 26], points
out that when calculating the RoI (Region of Inter-
est), if a small object is just a little bit off, the
localization error will have a large impact, but thereis not much difference for a large object.
ResNet stands for Residual Network. Resnet-50 is
used to describe the variant that can work with 50neural network layers [ 27,28]. When working with
deep convolutional neural networks to solve aproblem related to a computer vision problem,
machine learning experts are concerned with
stacking more layers. These additional layers help tosolve complex problems more ef ﬁciently, as the
different layers can be trained for different tasks toachieve highly accurate results. While the numberof stacked layers can enrich the features of themodel, a deeper network can reveal the problem ofdegradation. In other words, as the number of layers
in the neural network increases, the accuracy levels
may become saturated and slowly degrade after acertain point. As a result, the performance of themodel deteriorates in both training and test data.
Table 1. Hazard identi ﬁcation and risk assessment.
Items Hazard classi ﬁcation
A WT Unit structure Falling 、Broken、Crack、Collapse 、Mechanical failure 、
The hazards are divided into natural disasters (typhoons,storms, strong winds, earthquakes, lightning strikes …), and
so on.
B Wind power ﬁre Mechanical failure 、Debris falls 、Falling、Ignite the ﬁeld、
Building disaster 、Natural disasters (typhoons, storms, strong winds,
earthquakes, lightning strikes, etc.)
C WT blade structure Component falling 、Wind blade broken 、Wind blade crack 、
Collapse 、Debris falls 、Mechanical failure 、Natural disasters
(typhoons, storms, strong winds, earthquakes, lightning strikes …)542 JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552
------------------------------End of the page -----------------------------------
The application of both YOLO and Resnet-50 to the
experimental process is discussed in section IV.
2.2. Description of the SS techniques
The best damage pattern is selected from the
output end of the synthesizer as the ﬁnal output of
the WT blade that can cause damage, which is called
SS. It can be divided into pure SS and threshold SS.
The SS does not necessarily select only one optimaloutput destruction pattern of the WT blade but canselect two or three, or even more optimal destruc-tion patterns as output after synthesis. The selectionof two (or three) a synthesizer with the best signal iscalled a second-order (or third-order) SS.
2.2.1. Pure SS
Pure SS is to continuously monitor the received
signal to select the best optimal damage pattern. Intheory, it must select the possible jamming patternwith the best probability value, but in practice this isdifﬁcult to do. It can only select the jamming pattern
with the highest output probability. Each branch ofthe SS must have its own decision algorithm, which
increases the cost and complexity of the equipment.
2.2.2. Threshold SS
The basic principle of the Critical Value SS is that
each received damage pattern is scanned sequen-tially and the ﬁrst scanned damage pattern greater
than the Critical Value is selected as the output. Aslong as the damage pattern of this damage pattern
probability value is still greater than the critical
value, this damage type will be used as the outputdamage type. Otherwise the synthesizer will repeatthe scan. The critical value setting can be ﬁxed or
variable. Before setting the critical value, the prob-ability value generated by the average damagepattern of the geographical area must be fullycaptured. If the damage pattern is assessed in a ﬁxed
area, the ﬁxed critical value method can be used.
However, as for the non- ﬁxed blade operation area,
since the non- ﬁxed blade operation area often moves
in different regions, the average probability judg-ment strength of each region may not be the same. Iftheﬁxed critical value method is used, the system
judgment result will be unstable and unnecessary.The switching action occurs, so the method of
changing the threshold value is more suitable.
2.3. Ordered statistics
If there are independent random variables and a
random variable whose size ranks k-th is selected
from them, then the statistical characteristics of thisrandom variable are what order statistics will discuss.
Since the second-order (third-order) SS selects two(three) types with the strongest strength from amongthese items after receiving the items, and then addsthe probability value of the two (three) items andoutputs them with the appropriate results. Thus, theconcept of ordered statistics must be used. This sub-section gives a brief discussion of the distribution of
single, two, and more than two-ordered statistics [ 23].
2.3.1. Single-ordered statistic distribution
Assume that there have nindependent random
variables, X
1;X2;…;Xn, which all have the same CDF
(cumulate distribution function), FðxÞ, and pdf
(probability density function), fðxÞ. Now arranging
thenrandom variables in the order from large to
small Xð1Þ/C20Xð2Þ/C20//C20XðnÞwhere XðrÞis the r-th
ordered variate. Thus, the event is given as theexpression [ 18],
It is known that in the range of Xi/C20xwhere has
r/C01, and just one and n/C0rlocated during the
duration of x<Xi/C20xþdxand Xi>xþdx, respec-
tively. Consider that dxis a very small value, hence
the probability for the event of x<XðrÞ/C20xþdxcan
be determined as
P/C0
x<XðrÞ/C20xþdx/C1
¼n!
ðr/C01Þ!ðn/C0rÞ!½FðxÞ/C138r/C01
½1/C0FðxþdxÞ/C138n/C0r/C2½FðxþdxÞ/C0FðxÞ/C138þO/C16
ðdxÞ2/C17 ð1Þ
where OððdxÞ2Þrepresents the probability value for
two or larger than two Xiwhich fall during the in-
terval of ðx;xþdx/C138, dividing both of the two sides of
Eq.(1)with dx,and the probability value of XðrÞover
ð1/C20r/C20nÞcan get as
frðxÞ¼lim
dx/0/C26P/C0
x<XðrÞ/C20xþdx/C1
dx/C27
¼n!
ðr/C01Þ!ðn/C0rÞ!½FðxÞ/C138r/C01½1/C0FðxÞ/C138n/C0rfðxÞð2Þ
where the variable dxis considered as approaching
zero. Therefore, by substituting r¼ninto Eq. (2)the
pdf for the maximum variable of XðnÞcan be deter-
mined as
fnðxÞ¼n!
ðn/C01Þ!ðn/C0nÞ!½FðxÞ/C138n/C01½1/C0FðxÞ/C138n/C0nfðxÞ
¼n½FðxÞ/C138n/C01fðxÞð3ÞJOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552 543
------------------------------End of the page -----------------------------------
2.3.2. Joint distribution of multiple-ordered statistics
In this subsection the derivation of jpdf (joint pdf)
for two ordered variables, XðrÞand XðsÞ
ð1/C20r<s/C20nÞ, is provided. The event of
fxr<XðrÞ/C20xrþdxr;xs<XðsÞ/C20xsþdxsgis analyzed as
the following expression,
where has the number of r/C01 for variable Xi
occupies the range of Xi/C20xr. One of Xiis just located
in the duration of xr<Xi/C20xrþdxr, and there s/C0r/C01
ofXiare dwelling on the interval of xrþdxr<Xi/C20xs.
Besides, one of Xiis just located at the interval of xs<
Xi/C20xsþdxs, and there have n/C0sofXilimited in Xi>
xsþdxs. Onward, after the variables of dxranddxsare
assumed as approaching to zero, the probability ofoutcome for the event of can be calculated as
P/C8
x
r<XðrÞ/C20xrþdxr;xs<XðsÞ/C20xsþdxs/C9
¼n!
ðr/C01Þ!ðs/C0r/C01Þ!ðn/C0sÞ!½FðxrÞ/C138r/C01
½FðxsÞ/C0FðxrþdxrÞ/C138s/C0r/C01/C2½1/C0FðxsþdxsÞ/C138n/C0s
½FðxrþdxrÞ/C0FðxrÞ/C138½FðxsþdxsÞ/C0FðxsÞ/C138
þO/C16
ðdxrÞ2dxs/C17
þO/C16
dxrðdxsÞ2/C17ð4Þ
where both of OððdxrÞ2dxsÞand OðdxrðdxsÞ2Þare poly-
nomial with higher order. On the other hand, the
previous probability is conditioned on the followingconstrains, (A) there has two or greater than two var-iables X
ifalls into the interval of ðxr;xrþdxr/C138, (B) there is
at least one variable located at the duration of ðxs;
xsþdxs/C138, (C) there is at least one variable of Xilocated at
the duration of ðxr;xrþdxr/C138and two or more than two
variables of Xidwells on ðxs;xsþdxs/C138. Next, let dxr/0
anddxs/0 then divides dxrdxsfor both side of equiv-
alent in Eq. (4).T h ej p d fo f XðrÞand XðsÞwith the con-
dition of ð1/C20r<s/C20nÞcan be obtained as
frsðxr;xsÞ¼lim
dxr/0
dxs/0/C26P/C8
xr<XðrÞ/C20xrþdxr;xs<XðsÞ/C20xsþdxs/C9
dxrdxs/C27
¼n!
ðr/C01Þ!ðs/C0r/C01Þ!ðn/C0sÞ!½FðxrÞ/C138r/C01½FðxsÞ/C0FðxrÞ/C138s/C0r/C01
/C2½1/C0FðxsÞ/C138n/C0sfðxrÞfðxsÞ
ð5Þ
The jpdf under the condition of obtaining the
largest one and the second largest one can beobtained by substituting r¼n/C01 and s¼ninto Eq.
(5). Thus, it can be expressed as
fn;n/C01ðxn;xn/C01Þ¼n!
ðn/C01/C01Þ!ðn/C0nþ1/C01Þ!ðn/C0nÞ!
½Fðxn/C01Þ/C138n/C01/C01/C2½FðxnÞ/C0Fðxn/C01Þ/C138n/C0nþ1/C01
½1/C0FðxnÞ/C138n/C0nfðxn/C01ÞfðxnÞ¼nðn/C01Þ
½Fðxn/C01Þ/C138n/C02fðxn/C01ÞfðxnÞ
ð6Þ
Similarity, the derivative process can be extended
to determine the jpdf for kordered variables. That is,
the jpdf of ordered variables Xðn1Þ;Xðn2Þ;…;XðnkÞ,
x1/C20x2/C20//C20xk, corresponding to the ordered vari-
ables of ð1/C20n1<n2</<nk/C20n;1/C20k/C20nÞwith k
ordered observations can be evaluated as
fn1;n2;…;nkðx1;x2;…;xkÞ
¼n!
ðn1/C01Þ!ðn2/C0n1/C01Þ!/ðn/C0nkÞ!½Fðx1Þ/C138n1/C01fðx1Þ
/C2½Fðx2Þ/C0Fðx1Þ/C138n2/C0n1/C01fðx2Þ/½1/C0FðxkÞ/C138n/C0nkfðxkÞ
¼n!"Yk
j¼1f/C0
xj/C1#Yk
j¼0(/C2
F/C0
xjþ1/C1
/C0F/C0
xj/C1/C3njþ1/C0nj/C01
/C0
njþ1/C0nj/C01/C1
!)ð7Þ
As the previous discussion to the ordered sta-
tistic in which the WT blade damage type can beassigned as the ordered variables, for example,
X
1;X2;…;Xncorresponding to the blade damage
type. On the other hand, the r-th ordered variate
could be assigned as “damaged type A00,“damaged type
B00,“non-damaged type (c) ”, and (or) “unknown
damaged type (D) ”, and so on. The discussion to the
classi ﬁcation of damaged types for WT blades is
going to be presented in the later section.
2.4. The major constrains and necessity
In fact, there are many critical limitations of the
proposed methodologies that will be discussed inthis subsection.
Overall, it is known that the limitations of current
knowledge in this ﬁeld would include 3 critical
points,
1. The acquisition of images for WT blades in real
time status.
2. The limitation of the transmission bandwidth
provided to the transceiver between the edge
device embedded in the NVIDIA Jetson Nano
Xavier and the monitoring instruments.
3. Since the environment is assumed to be too
clean (without noise) in this article, the valida-tion and prediction phases become major544 JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552
------------------------------End of the page -----------------------------------
obstacles in the investigation. In order to prove
the results can be used as a practical method forvaluable reference, certainly adds a lot of noiseto simulate the situation in the factory is neces-sary. That is, when the environment is requiredfor training or in the test stage, the requirementof setting up a practical environment should beconsidered ﬁrst.
However, even there, the aforementioned con-
straints and concerns remain. The possible safety
and emergency hazards caused by WT blades are
indeed the key points when considering the opera-tion of wind turbines. Therefore, how to really usemachine learning technology and apply it deeply tothe detection and maintenance of WT blades isindeed a very important public safety issue. There-fore, the research topic proposed in this article hasbeen veri ﬁed by actual experiments and found to be
a feasible solution.
3. Pre-processing of the WT blades
The research will use the block diagram shown in
Fig. 1 to complete the blade damage detection in
three steps. In the ﬁrst step, the acquisition of WT
blades and the pre-processing after the acquisitionare carried out. This includes edge detection of the
blades and noise removal, then by performing
normalisation with normal distribution. The moreimportant blade characteristics are retained in theextracted blades, such as colour change, stainingand/or deformation cracks. After training, the bladefeatures are sent to the framework for con ﬁrmation.
The training mode of the diagnosis and predictionframework must be set before con ﬁrmation. Of
course, the parameters of the main framework and
then the building of the prediction model must bedetermined ﬁrst. In addition, it will go through the
blade training and testing after the completion ofthe blade identi ﬁcation ﬁgures out in the ﬁrst stage.
In the ﬁnal stage of this project, the evaluation of the
blade identi ﬁcation results will be carried out. This
work will use the YOLOv4 model in the con ﬁrma-
tion process. It is expected to adopt four types of
identi ﬁcation, from Type A to Type D damage
classi ﬁcation. Finally, the performance evaluation of
theﬁnal identi ﬁcation results will be determined by
the schemes of R2, MSE and MA-1.
Accordingly, the pre-processing of the WT blade
images is shown in Fig. 2 . The original WT blade
image is ﬁrst sliced and the number of slices de-
pends on the resolution degree of the edge and
segments of the results. The judgement of whetherit is suitable for fouling and worn blades or not ismade according to the results of the classi ﬁcation. At
this moment, the different types for the classi ﬁcation
of the damaged WT blade have been assigned 4types as follows, “Damaged Type A
00,“Damaged
Type B00,“Non-Damaged Type (c)", and (or) “Un-
known Damaged Type (D)".
Of course, the con ﬁrmation of the type of damage
and (or) other items on the edge is made by calcu-lating the probability through the SS scheme. That
is, the activity selection at this time has the damage
types including shape, size and type of blade crackthen the obtained probability is synthesized. Inaddition, the normal and damaged WT blades areshown in Fig. 3 , where the size of the resolution is
also shown. There are many section images showninFig. 4 corresponding to the case of normal and
damaged type of WT blades.
The determined likelihood is then given to
determine if the given likelihood is appropriate. Ifthe con ﬁrmed probability is suitable, it means that
the image is worth keeping and can be used as animage for identi ﬁcation. Conversely, a new captureFig. 1. The block diagram includes three stages for the proposed project.JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552 545
------------------------------End of the page -----------------------------------
action is performed on the WT blade image, and
then the next judgement is made with a new itera-tion. On the other hand, the capture iteratively of
performing edge and segment actions on thecaptured WT blade, and this previously described
action has been done repeatedly until the 5 execu-tion times are arrival. If the given blade is selectively
synthesized, the identi ﬁcation of the WT and the
Fig. 2. The pre-processing process of the WT blade images.
Fig. 3. The normal (A) and damaged (B) WT blades.546 JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552
------------------------------End of the page -----------------------------------
blade is carried out after an appropriate probability
has been given. If the given extraction edge is notsuitable, bilateral ﬁltering, edge correction and
segmentation modi ﬁcation are performed, and then
it is judged whether the corrected result of this edgeis correct. This cycling process is the pre-processingprocess of WT blade images proposed in this study.
4. SS and bilateral ﬁlter
Feature selection refers to the process of reducing
the number of unnecessary features before feeding
them into a classi ﬁer. The feature extraction algo-
rithm proposed in this paper relies mainly on thefeatures of SVD. The main purpose of this techniqueis to achieve reliable usability for color images.Therefore, SVD is a numerical technique fordecomposing input data into expected submatrices[15]. In addition, this subsection introduces the
bilateral ﬁlter, which is a ﬁlter that can be used to
preserve the edge and denoise an original image.
4.1. Description of the SVD techniques
The feature extraction algorithm proposed in the
current article, where the technique depends mainlyon the features of SVD. Several feature selectiontechniques have been discussed and implemented
so far. A perfect classi ﬁer does not need feature
selection because it can ignore irrelevant features. Inreal time, no classi ﬁer is perfect and there is no
guarantee that feature selection will improve itsaccuracy. The main goal of the proposed techniqueis to achieve reliable robustness for color images.Accordingly, SVD is a numerical technique thatdecomposes the input data into expectedsubmatrices [ 21]. Basically, after decomposing the
input image, one obtains a graph matrix with sin-gular values for the diagonal elements. Assuming
this is the input signal, it represents the left and
right singular vector matrices respectively, andthese singular values correspond to the energy ofthe signal. Rendered as a graph matrix, given as
A¼USV
Tð8Þ
where Tis the transpose. Based on the SVD tech-
nique and steps described in Fig. 5 .
Normally, feature extraction is the most important
stage before the above-mentioned activity of imagecutting, which is discussed in section III. To the bestof the authors 'knowledge, the proposed scheme of
image clipping is a completely new method.
Certainly, it must follow the steps shown in Fig. 5 .
Dimensionality reduction is a key technique forextracting the most important features and at thesame time reducing the complexity of theprocessing.
4.2. Describe the techniques for preserve edge and
denoise techniques
A traditional ﬁlter that can preserve the edge and
denoise is usually the bilateral ﬁlter. It can ﬁlter out
the noise in the image data and even preserve theedge, texture, etc. of the image. This is because thenoise is a high frequency signal. Therefore, theGaussian ﬁlter will blur the edge while ﬁltering the
noise because the edge and texture are also high
frequency information. So the question is, what kindof event exactly is such an excellent ﬁlter? In fact, it
uses a convolution kernel (template matrix), just like
Fig. 4. Corresponding to the case of normal and damaged type.JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552 547
------------------------------End of the page -----------------------------------
the ordinary Gaussian ﬁlter. This ﬁlter is also
superimposed on the pixels to be processed and thecorresponding neighbouring pixels are provided.
The weighted sum of the points is used as the
method for the value of the new output pixel point.In simple terms, bilateral ﬁltering is the same as
Gaussian ﬁltering, the only difference being the
template matrix. Normally, the template coef ﬁcient
matrix of the Bilaterial ﬁlter is obtained by dot-
multiplying (element-level multiplication) the rangecoefﬁcients of the Gaussian template matrix. Two
ﬁlters that can be compared with each other are the
Gaussian low-pass ﬁlter and the a-truncated mean
ﬁlter (the mean of the remaining pixels after
removing the minimum and maximum percentagesofais used as the ﬁlter) [ 17]. The reason for this is
similar to the previous description. Accordingly, in aﬂat area, the pixel difference is small and the cor-
responding value domain weight is close to 1. At
this point, the spatial domain weight plays an
important role, which is equivalent to directlyapplying Gaussian blur to this area. In the edge areathe pixel difference value is large. The coef ﬁcient of
the range decreases that is resulting in the decreaseof the kernel function here (due to w¼r/C2d), and
the less the current pixel is affected. Thus, it is ableto maintain the detail information of the edge pixel.
Suppress pixels with a large difference in value from
the center pixel (even if you are close in space).
Onwards, the calculation method is brie ﬂy
descripted following up. For each neighborhoodpixel calculate its corresponding spatial coef ﬁcient
and value domain coef ﬁcient ﬁrst. With the multiply
to obtain the total coef ﬁcient is the next step then
perform weighted summation and
PVði;jÞ¼X
k;lfðk;lÞwgði;j;k;lÞ,X
k;lwgði;j;k;lÞð 9Þ
where the weighting factor wgði;j;k;lÞdepends on
the kernel value of de ﬁnite domain areaKLði;j;k;lÞ¼e"
/C0ði/C0kÞ2þðj/C0lÞ2
2m2
KL#
ð10Þ
and the value kernel
VLði;j;k;lÞ¼e"
/C0kPVði;jÞ/C0PVðk;lÞk2
2m2
VL#
ð11Þ
respectively. Eventually, the total weight
parameter is provided with the calculation ofmultiplying the last two equations and obtained as,
W
gði;j;k;lÞ¼e(
/C0"
ði/C0kÞ2þðj/C0lÞ2
2m2
KLþkPVði;jÞ/C0PVðk;lÞk2
2m2
VL#)
ð12Þ
It is known that the assessment for the ways of
feature extraction is much easier when the basictheories of combining the SS with the Bilaterial ﬁlter
is adopted. On the other hand, the statement of SS
and Bilaterial ﬁlter is quite suitable to apply to
preserve the edge area and denoise for the clean theblur occurring in an image of WT blade.
5. The discussion of experiments and results
When using many skills to carry out the pre-
processing of the WT blades, such as the combina-tion of SS with Bilaterial Filter. This session will set
up the experimental environment for identifying
and predicting the possible damage or deteriorationof WT blades with high accuracy. Some of the re-sults of the experimental classi ﬁcation will also be
discussed in this section.
Currently, the experiment of the proposed algo-
rithm in this study is being carried out. The wholeframework of pre-trained Tensor ﬂow_keras Resnet-
50 is shown in Fig. 6 , which is used in the process of
experiment for image pre-processing [ 19]. The
different types of WT blade are described in Sec. III,where the dataset of WT blade is divided into fourtypes. Another method of damage assessment is the
Fig. 5. Flowchart of the extraction process of the SVD algorithm.548 JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552
------------------------------End of the page -----------------------------------
regular or cracked process, which is implemented
by the methods proposed in the current article. In
the following, Table II lists the deployment of
hyperparameters applied to the adopted NNframework to repeat the experiments. It is easy toobserve from Table II that the items of hyper-
parameters are “Pixel Size #", “Class #", “Epochs #",
“Freeze Layer #", “Batch Size #". The ratio of the
selected data set to the establishment of the trained
model with ML is 7 to 3. In the process of deploy-
ment to the architecture of NN there are the distri-bution graphs of the input layer, hidden layer andoutput layer of the RESNET-50 model. After thetrained model is built, it can be learned throughdeep learning adaptive training and in the processof validation and testing stages.
Although the video of collecting WT blades in
time could not be presented in the context of the
article, the training step is still able to be expressedwith text. So far, after learning the model is obtainedto generate the ML framework for the work oftesting with the ﬁlename of model-resnet50- ﬁnal.h5.
The building block model performs data processingand divides the data into normal and damagedimages in the ﬁrst step. First, the individual input
images are analyzed by 5280 times 2970, and then
the regular images are reshaped into 224x224 im-ages. Speci ﬁcally, at the image acquisition stage, a
total of 1270 images including normal and damagedimages are provided with image pre-processing.
During the training stage to build the deep learning
model, the accuracy rate and loss rate are shown inFig. 7 (A) and (B) , respectively.
The image is then split and divided into the cor-
responding type A and type B worn images. Inaddition, the normal images are also retained afterclassi ﬁcation. Finally, there are some images with
severe background noise that cannot be removed,
and they are classi ﬁed as unknown images, called
type-D images. The results of the ﬁnal experiments
can be obtained to verify the validity of the pre-processed images.
YOLO 's convolutional network architecture is a
model of GoogleNet. YOLO 's network has 24 con-
volutional layers and 2 layers of fully connected layers[27]. The difference from GoogleNet is that in some
3/C23 the author uses a 1 /C21 convolutional layer before
the convolutional layer to reduce the number of ﬁlters.
For validation purposes, the YOLOv4 neural networkis used as the model to train the corrective action of theimage pre-processing. In the process of real-time WTblade image acquisition, it can be seen that when theUAV is close to the WT blade, the camera alwaystargets and marks the damaged part in the WT blade.
No matter its size, spot or regular, the captured WT
blades are immediately retrieved including theabnormal parts. The retrieval and storage actions thenfollow the previous image acquisition steps.
Fig. 6. The whole framework of pre-trained Tensor ﬂow_keras Resnet-50.
Table 2. Hyperparameters applied to the RESNET-50 model.
Hyperparameter items Learn rate Pixel size Class # Epochs # Freeze Layers # Batch size # Dropout rateDeployed number 0.001 (224, 224) 2 80 2 8 7:3JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552 549
------------------------------End of the page -----------------------------------
Furthermore, the hypermeters to be used to imple-
ment the YOLOv4 framework, which will becompleted later, are shown in Table III . In the given
table, where includes the hardware environment,
software version and training network parameters forthis experiment, and which can look in depth into theinspection of the repetition for the experimentshyperparameters in. Accordingly, there the Model-1and Model-2 are implemented in the proposed algo-rithms to validate the training framework comes fromthe Resnet-50, and they are corresponding to the
YOLOv4-Tiny and YOLOv4 models. On the other
hand, the former and later are designed for the edgecomputing device of YOLOv4-Tiny and traditionalYOLOv4 models, respectively.
As this article is a practical project, the feasibility of
future commercial transfer should be considered.Therefore, the deep learning model with a recogni-tion rate of more than 90 % is ﬁnally transplanted to
Nvidia Jetson Nano as a basis for edge computing,
which is available for commercial migration forlarge-scale UAV applications in the future. Theapplication scenario is shown in Fig. 8 [20,25].
In this research, a Generative Adversarial
Network (GAN) was imported into the data pre-processing part to generate a set of virtual defectphotos, and combined with real photos, a YOLOdeep learning model was established to achieve
95 % blade defect recognition.
Finally, download the algorithm module to the
NVIDIA Jetson Xavier NX development version, as
shown in Fig. 9 . In fact, the installed edge devices of
Jetson Nano could be replaced with other availableoptions, such as the edge MCU with STM series,Arduino or even the Raspberry@ modular. That 's
why the type of available edge devices de ﬁnitely
depends on the computing speed and working
Fig. 7. The loss rate of training model with ResNet50 NN.
Table 3. Hyperparameters applied to the YOLOv4 models.
Hyperparameter items Hardware environment: Windows 10/RAM: 128GB/GPU: NVIDIA 1080
Optimizer: AdamDeployed numbersLearn rate Pixel size Class # Epochs # Freeze Layers # Batch size # Dropout rate
Model-1 (YOLOv4-Tiny) 0.0025 (448,448) 2 6000 1 64 7:3
Model-2 (YOLOv4) 0.0025 (448,448) 2 10000 1 64 8:2
Fig. 8. A photo for real-time capturing to the image of the WT blade.550 JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552
------------------------------End of the page -----------------------------------
efﬁciency. The ﬂow continued by actually applying
the training model to the NVIDIA Jetson Xavier NXdevelopment board combined with the Raspberry PiCamera v2 lens, we put the image of the damagedfan blade on the screen, install the trained YOLOv4model and add the lens through the GPU-acceler-ated operation on the development board. Real-timeimage recognition is performed on the data
returned by the terminal.
In the recognized streaming screen, YOLOv4-Tiny
can reach 32FPS and the recognition rate can reachmore than 70 %. However, in YOLOv4, it can present26FPS images, and the actual recognition rate canreach 80 %. Contrary to the above issue, YOLOv4-Tiny can actually accurately identify the damagedarea of the blade. Obviously, although the original
image resources are limited, the GAN in this studycan still generate high resolution simulated images.
Speci ﬁcally, 329 photos were used to build the
framework after model training in the two trainingtimes. From the comparison of them with each otherfrom the point of view of error, the lightweightmodel YOLOv4-Tiny is much faster than YOLOv4-
Tiny in terms of training time. The average target
detection evaluation index (mAP) of YOLOv4-Tinyhas a larger ﬂuctuation, reaching 90 % after 5000
times, but remaining 88 % in the ﬁnal training result
(85 % without GAN image). The error of YOLOv4-Tiny starts to oscillate after 400 iterations. After 3000training times, the average target detection
Fig. 9. The NVIDIA Jetson Nano Xavier NX development version.
Fig. 10. (A). For YOLOV4-Tiny model, and (B). For YOLOv4 model.JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552 551
------------------------------End of the page -----------------------------------
evaluation index stabilizes at 94 % (92 % without
GAN images) and reaches a maximum of 96 % after4000 times. The ﬁnal training result remains at 95 %,
and the reason for this can be discussed later. Twotraining results show that YOLOv4-Tiny has ahigher recognition rate, as shown in Fig. 10 (A) .T w o
training results show that YOLOv4 has a higherrecognition rate, as shown in Fig. 10 (B) .
6. Conclusion
An image pre-processing operation platform for
complete machine learning image data has beenproposed in the article. A machine learning algo-rithm with high accuracy classi ﬁcation ef ﬁciency has
been developed for WT blade defect classi ﬁcation.
In addition, a high-ef ﬁciency and high-accuracy
deep learning algorithm for WT blade defect iden-
tiﬁcation is developed and validated based on the
YOLO framework (combined with GAN virtualgraphics). The simulation report of the ﬁre caused
by the WT disaster has been completed. Therefore,the key hazard factors of the WT blades can bedeﬁnitively de ﬁned after the completion of a WT
disaster risk assessment report. In addition, the
deep learning visual recognition model has been
established and installed on the Nvidia Jetson Nanoedge computing module, which can easily realizereal-time image recognition and even continue to bea commercial transfer prototype.
Conﬂict of interest
The authors declare no con ﬂict of interest.
References
[1] Drone market outlook in 2021. Accessed: Nov. 1, 2021. [On-
line], https://www.businessinsider.com/drone-industry-
analysis market-trends-growth-forecasts .
[2] Accessed: Nov. 1, 2021. [Online], https://www.bnext.com.tw/
article/65236/offshorewind-2021 .
[3] Zhang J, Cosma G, Watkins J. Image enhanced Mask R-
CNN: a deep learning pipeline with new evaluation mea-
sures for wind turbine blade defect detection and classi ﬁ-
cation. J. Imaging 2021;7(No. 3). https://doi.org/10.3390/
jimaging7030046 .
[4] Yan X, Wu G, Zuo Y. YOLOV4-Based wind turbine blade
crack defect detection. Proceedings of IncoME-VI andTEPEN 2021. Mechanisms and Machine Science 2021;117:
293e305.https://doi.org/10.1007/978-3-030-99075-6_25 .
[5] Kartik C, Nevena S, Elizabeth JC, Nikolaos D, Keith W.
Damage detection in operational wind turbine blades using anew approach based on machine learning. Renewable En-ergy; May 2021. p. 1249 e64. https://doi.org/10.1016/
j.renene.2020.12.119 . 168.
[6] Diaz PM, Tittus P. Fast detection of wind turbine blade dam-
age using cascade Mask R-DSCNN-aided drone inspection
analysis, ”signal, Image and video processing. Jan. 2023.
p. 2333 e41.https://doi.org/10.1007/s11760-022-02450-6 . 17.[7] Wang L, Zhang Z, Long H, Xu J, Liu R. Wind turbine gearbox
failure identi ﬁcation with deep neural networks. IEEE Trans
Ind Inf 2017;13(No. 3):1360 e8.
[8] Qiu Z, Wang S, Zeng Z, Yu D. Automatic visual defects in-
spection of wind turbine blades via YOLO-based small ob-ject detection approach. J Electron Imag 2019;28(No. 4):
043023.
[9] Wilson AN, Kumar A, Jha A, Cenkeramaddi LR. Embedded
sensors, communication technologies, computing platformsand machine learning for UAVs: a review. IEEE Sensor J2022;22(No. 3). Feb. 1.
[10] Mustafa Z. Classi ﬁcation of UAV point clouds by random
forest machine learning algorithm. Turkish Journal of Engi-
neering April 2021;5(2):51 e61.
[11] Wang CX, Tian JM, Cao JW, Wang XH. Deep learning-based
UAV detection in pulse-Doppler radar. IEEE Trans GeosciRem Sens 2022;60:5105612 e24.
[12] Li WB, Hu B, Song C, Zhao F, Ma HL, Wang YJ. An image
stitching method for blades of wind turbine based on back-
ground removal preprocessing, ”Proceeding of 5th interna-
tional Conference on communication, Image and signal processing(CCISP). June 2021. p. 174 e9.
[13] Xu DH, Wen CB, Liu JH. Wind turbine blade surface in-
spection based on deep learning and UAV-taken images.J Renew Sustain Energy 2022. https://doi.org/10.1063/
1.5113532 [Online]March. 20.
[14] Zhang NN, Lu CZ. Wind turbine blade defect image acqui-
sition system. J. Phys.: Conf. Ser. 2020;1646:012086. 1-6.
[15] Shaw J, Wu BJ. Prediction of remaining useful life of wind
turbine shaft bearings using machine learning. J Mar SciTechnol 2021;29. https://doi.org/10.51400/2709-6998.2465 .5 ,
Article 4.
[16] Mao Y, Wang S, Yu D, Zhao J. Automatic image detection of
multi-type surface defects on wind turbine blades based oncascade deep learning network. Intell Data Anal 2021;25(No.2):463e82.
[17] Zhang R, Wen C. SOD-YOLO: a small target defect detection
algorithm for wind turbine blades based on improvedYOLOv5. Advanced Theory and Simulations 2022:2100631.
[18] Redmon J, Divvala S, Girshick R, Farhadi A. You only look
once: uni ﬁed, real-time object detection. In: Proceedings of
the IEEE conference on computer vision and pattern recog-nition; 2016. p. 779 e88.
[19] Rahmat N, Nur AF, Muhammad D, Muhammad H. Corre-
lation of safety perceptions and safety behavior in university
teaching laboratory. Malaysian Journal of Public Health
Medicine 2020;20(No. 1):1 e5.
[20] Huang S. Current status and prospects of marine energy
development in taiwan. Marine Research, Trial Issue 2020:25e34.
[21] Wang L, Long H, Zhang Z, Xu J, Liu R. Wind turbine gearbox
failure monitoring based on SCADA data analysis. Proc.
IEEE Power Energy Soc. Gen. Meeting 2016:1 e5.
[22] https://blog.csdn.net/MoFMan/article/details/77482794 .
[23] David HA. Order statistics. New York: John Wiley &Sons,
Inc.; 1981.
[24] Ashiba HI, Mansour HM, Ahmed HM. Enhancement of
infrared images based on ef ﬁcient histogram processing.
Wireless Pers Commun 2018;99:619 e36.
[25] Sha ﬁee M, Zhou Z, Mei L, Dinmohammadi F, Karama J,
Flynn D. Unmanned aerial drones for inspection of offshorewind turbines: a mission-critical failure analysis. Robotics2021;10(No. 1):26.
[26] Islam M, Laskar RH. Geometric distortion correction based
robust watermarking scheme in LWT-SVD domain with
digital watermark extraction using SVM. Multimed. Tools2018;77:14407 e34.
[27] Redmon J, Divvala S, Girshick R, Farhadi A. You only look
once: uni ﬁed, real-time object detection. IEEE Conference on
Computer Vision and Pattern Recognition 2016:779 e88.
[28] Accessed: July. 1, 2022. [Online], https://viso.ai/deep-
learning/resnet-residual-neural-network/ .552 JOURNAL OF MARINE SCIENCE AND TECHNOLOGY 2023;31:539 e552
------------------------------End of the page -----------------------------------
