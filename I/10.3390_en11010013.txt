energies
Article
Machine Learning for Wind T urbine Blades
Maintenance Management
Alfredo Arcos Jim Ã©nez1, Carlos Quiterio G Ã³mez MuÃ±oz2and Fausto Pedro Garc Ã­a MÃ¡rquez1,*ID
1Ingenium Research Group, Castilla-La Mancha University, 13071 Ciudad Real, Spain;
alfredo.arcos@alu.uclm.es
2Ingenier Ã­a Industrial y Aeroespacial, Universidad Europea Madrid, Villaviciosa de Od Ã³n, 28670 Madrid,
Spain; carlosquiterio.gomez@universidadeuropea.es
*Correspondence: faustopedro.garcia@uclm.es; Tel.: +34-926-295-300 (ext. 6331)
Received: 28 October 2017; Accepted: 18 December 2017; Published: 21 December 2017
Abstract: Delamination in Wind Turbine Blades (WTB) is a common structural problem that can
generate large costs. Delamination is the separation of layers of a composite material, which produces
points of stress concentration. These points suffer greater traction and compression forces in working
conditions, and they can trigger cracks, and partial or total breakage of the blade. Early detection of
delamination is crucial for the prevention of breakages and downtime. The main novelty presented
in this paper has been to apply an approach for detecting and diagnosing the delamination WTB.
The approach is based on signal processing of guided waves, and multiclass pattern recognition using
machine learning. Delamination was induced in the WTB to check the accuracy of the approach.
The signal is denoised by wavelet transform. The autoregressive Yuleâ€“Walker model is employed for
feature extraction, and Akaikeâ€™s information criterion method for feature selection. The classiï¬ers are
quadratic discriminant analysis, k-nearest neighbors, decision trees, and neural network multilayer
perceptron. The confusion matrix is employed to evaluate the classiï¬cation, especially the receiver
operating characteristic analysis by: recall, speciï¬city, precision, and F-score.
Keywords: delamination detection; macro ï¬ber composite; wavelet transforms; non-destructive tests;
neural network; guided waves; wind turbine blade
1. Introduction
Wind energy is a clean resource, and one that is growing worldwide, since it is the most efï¬cient
renewable energy source [ 1,2]. Wind turbines present structural health problems, mainly in Wind
Turbine Blades (WTB) [ 3]. Delamination is one of the most common problems in composite materials,
caused by the disunion of their layers or by the detachment of their adhesive bonds. Low speed impact
on working conditions can create a visible fault on WTB [ 4,5]. The microstructural fault increases
because of the cyclic fatigue loads, and it can degrade the rigidity and strength of the composite [ 6].
Similarly, delamination can be generated by an error in the manufacturing process.
State space models are employed to predict the growth of delamination by stress/strain, fracture
mechanic, cohesive zone, extended ï¬nite element method based models [ 7]. Hoon Sohn et al. used
a wavelet-based signal processing technique, together with an active sensing system, to detect
delamination in near-real-time for composite structures [8].
Smart blades are currently used in Structural and Health Monitoring (SHM) systems and applied
to WTB, using sensors in the blades to monitor the condition of the WTB. McGugan et al. propose
a technique for measuring and evaluating the structural integrity by introducing a new concept
of tolerance to damage. It involves the life cycle of a blade, i.e., design, operation, maintenance,
repair, and recycling. Pattern recognition is used to establish a â€œdamages mapâ€ that evaluates the
Energies 2018 ,11, 13; doi:10.3390/en11010013 www.mdpi.com/journal/energies
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 2 of 16
SHM, allowing an efï¬cient operation of the wind turbine in terms of load relief, limited maintenance,
and repairs [ 9,10]. Dynamic models are also employed in SHM to detect instantaneous structural
changes online [ 11,12]. Sohn et al. propose an approach composed of four steps [ 13]: operational
evaluation; data acquisition & cleansing; feature extraction & data reduction; and statistical model
development. The Artiï¬cial Neural Networks (ANN) model produces accurate results in terms of
fault diagnosis. ANN demonstrates advantages, such as speed, simplicity, and robustness [ 14]. Rasit
Ata presents a review of ANN applied in wind energy systems [ 15]. Bork et al. [ 16,17], Yam et al. [ 18],
and Su and Ye [19] have issued different approaches considering Lamb waves and ANN.
Ultrasonic Lamb waves have been employed in this paper to detect and diagnose faults.
Lamb waves can detect internal and surface faults in WTB [ 20,21]. A wide range of potential
defects that employ different algorithms are studied in the literature [ 22,23]. In this paper, Discrete
Wavelet Transforms (DWT) are applied to ï¬lter signals. DWT is effective for signal denoising,
ï¬ltration, compression, and feature extraction of signals [ 24]. A correct signal pre-processing,
or an appropriate selection of characteristics, can result in a simple classiï¬er obtaining excellent
results [ 25]. The Daubechies wavelet family was employed in this paper. It has been demonstrated that
it is sensitive to sudden changes [ 26]. The normalization of the signals regarding the environmental
and operational conditions is a key issue in avoiding false diagnosis [ 27]. The mean value of the
time series has been used to remove the direct current offset from the signal. This result is divided
by the standard deviation of the signal to normalize varying amplitudes in the signal. G Ã³mez et al.
developed a similar pattern recognition approach for diagnosing ice on WTB by employing Daubechies
wavelet [21,28].
The main purposes of Feature Extraction (FE) and Feature Selection (FS) in this paper are
to reduce dimensionality, and to increase computational performance and classiï¬er accuracy.
The Auto-Regressive (AR) method is proposed to extract the FE. The AR model has high sensitivity
to damage features [ 29â€“31]. This technique has been employed in time series analysis and predictive
models for fault detection [ 32,33], but it has not been studied enough for pattern recognition. Yao et al.
applied statistical algorithms of pattern recognition using AR FE techniques by spectral model
and residual AR with acceleration data [ 34]. Nardi et al. studied delamination by means of AR
models [ 35]. Figueiredo et al. [ 36] propose an AR-based approach using acceleration time series in
order to distinguish variations in characteristics related to damage from those related to operational
and environmental effects. In this paper, selection of the number of AR model parameters is carried
out. A higher order model can ï¬t the dataset, but cannot be generalized to other datasets. A lower
model order may not adequately represent the physical dynamics of the system.
FS is employed to set the architecture of the ANN. The number of inputs corresponds to the
features selected, the outputs (number of class) to the network conditions, and the number of nodes in
the hidden layer depend on the features and classes.
Akaikeâ€™s Information Criteria ( AIC) [37], Final Prediction Error (FPE) criterion [ 38], Partial
Autocorrelation Function (PAF) [ 39], Root Mean Square (RMS) [ 40] and Singular Value Decomposition
(SVD) [ 41] have been employed in this paper to obtain the most suitable AR model by choosing the
number of parameters. The results of this work suggest that the optimal order is from 15 to 30.
The ultrasonic waves are analyzed by signal processing and classiï¬ers by Machine Learning
(ML) and ANN to determine the degree of delamination. The experiments consider six levels of
delamination. This study analyses different classiï¬ers of ML and ANN to obtain the best success rate.
The classiï¬ers used to identify the scenarios are quadratic discriminant analysis [ 42], k-nearest
neighbors [ 43], and decision trees [ 44]. The confusion matrix is employed to evaluate the classiï¬cation
using the receiver operating characteristic analysis by: recall, speciï¬city, precision and F-score.
The conventional methods to establish the average performance in all categories were macro and micro
average. The recommendations by DemÅ¡ar, and Garcia and Herrera have been used to compare the
classiï¬ers and analyze their results. The Friedman test has been used to test the null hypothesis that
all classiï¬ers achieve the same average. The Bonferroniâ€“Dunn test has been applied to determine
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 3 of 16
signiï¬cant differences between the top-ranked classiï¬er and the next one. The Holm test was applied
to contrast the results. When this approach was used, all the scenarios showed a high level of accuracy.
The main novelty is to employ the abovementioned approach for fault detection and diagnosis in
WTB that employs guided waves, where it has not been found in literature for detecting delamination
in WTB.
2. Approach for Delamination, Detection, and Diagnosis in WTB
The ultrasonic signal studied should be conditioned and denoised to train the classiï¬ers
properly [45]. The wavelet transform has been used in this paper to perform signal denoising [46,47].
The inputs and training patterns are critical in the design of the classiï¬ers, because they will
determine the performance of the network and its architecture. It is necessary to use a technique that
reduces the number of inputs that maintain the characteristic information of the signal. The feature
coefï¬cients of each ultrasonic signal are extracted using the AR model by the Yuleâ€“Walker method [ 48].
The classiï¬ers considered in ML are: Decision Tree (DT), Quadratic Discriminant Analysis (QDA),
K-Nearest Neighbors (KNN), and neural network multilayer perceptron. The schematized process of
the approach is shown in Figure 1.
EnergiesÂ 2018,Â 11,Â 13Â  3Â ofÂ 16Â 
Â significant Â differences Â betweenÂ theÂ topâ€rankedÂ classifier Â andÂ theÂ nextÂ one.Â TheÂ HolmÂ testÂ wasÂ appliedÂ 
toÂ contrastÂ theÂ results.Â WhenÂ thisÂ approach Â wasÂ used,Â allÂ theÂ scenarios Â showedÂ aÂ highÂ levelÂ ofÂ 
accuracy. Â 
TheÂ mainÂ noveltyÂ isÂ toÂ employÂ theÂ abovementioned Â approach Â forÂ faultÂ detection Â andÂ diagnosis Â 
inÂ WTBÂ thatÂ employs Â guidedÂ waves,Â whereÂ itÂ hasÂ notÂ beenÂ foundÂ inÂ literature Â forÂ detecting Â 
delamination Â inÂ WTB.Â 
2.Â Approach Â forÂ Delamination, Â Detection, Â andÂ Diagnosis Â inÂ WTBÂ 
TheÂ ultrasonic Â signalÂ studiedÂ shouldÂ beÂ conditioned Â andÂ denoised Â toÂ trainÂ theÂ classifiers Â 
properly Â [45].Â TheÂ waveletÂ transform Â hasÂ beenÂ usedÂ inÂ thisÂ paperÂ toÂ performÂ signalÂ denoising Â [46,47].Â 
TheÂ inputsÂ andÂ trainingÂ patternsÂ areÂ criticalÂ inÂ theÂ designÂ ofÂ theÂ classifiers, Â becauseÂ theyÂ willÂ 
determine Â theÂ performance Â ofÂ theÂ networkÂ andÂ itsÂ architecture. Â ItÂ isÂ necessary Â toÂ useÂ aÂ technique Â thatÂ 
reducesÂ theÂ numberÂ ofÂ inputsÂ thatÂ maintain Â theÂ characteristic Â information Â ofÂ theÂ signal.Â TheÂ featureÂ 
coefficients Â ofÂ eachÂ ultrasonic Â signalÂ areÂ extracted Â usingÂ theÂ ARÂ modelÂ byÂ theÂ Yuleâ€“Walker Â methodÂ 
[48].Â Â 
TheÂ classifiers Â considered Â inÂ MLÂ are:Â Decision Â TreeÂ (DT),Â Quadratic Â Discriminant Â Analysis Â 
(QDA),Â Kâ€NearestÂ Neighbors Â (KNN),Â andÂ neuralÂ networkÂ multilayer Â perceptron. Â TheÂ schematized Â 
processÂ ofÂ theÂ approach Â isÂ shownÂ inÂ FigureÂ 1.Â 
Â 
FigureÂ 1.Â ProcessÂ forÂ determining Â theÂ levelÂ ofÂ delamination Â inÂ theÂ WindÂ TurbineÂ BladesÂ (WTB).Â 
Machine Â Learning Â (ML);Â Artificial Â NeuralÂ Networks Â (ANN).Â 
TheÂ waveletÂ threshold Â denoising Â methodÂ isÂ appliedÂ byÂ employing Â aÂ multilevel Â 1DÂ waveletÂ 
analysisÂ byÂ Daubechies Â familyÂ [49,50].Â TheÂ waveletÂ decomposition Â structure Â ofÂ theÂ signalÂ isÂ extracted. Â 
TheÂ threshold Â forÂ theÂ denoising Â isÂ obtained Â byÂ theÂ waveletÂ coefficients Â selection Â ruleÂ usingÂ aÂ 
penalization Â methodÂ provided Â byÂ BirgÃ©â€MassartÂ [51,52].Â 
EachÂ setÂ ofÂ ultrasonic Â signalsÂ ofÂ everyÂ delamination Â levelÂ isÂ averaged Â andÂ normalized Â byÂ 
Equation Â (1)Â toÂ avoidÂ falseÂ positiveÂ damage: Â 
İ•à·œàµŒİ•àµ†ß¤à¯¬
ßªà¯¬Â  (1)Â 
whereÂ İ•à·œ	Â isÂ theÂ normalized Â signal,Â ß¤à¯¬Â isÂ theÂ mean,Â andÂ ßªà¯¬Â isÂ theÂ standard Â deviation Â ofÂ y.Â 
InÂ anÂ ARÂ modelÂ ofÂ orderÂ p,Â theÂ currentÂ outputÂ isÂ aÂ linearÂ combination Â ofÂ theÂ lastÂ pÂ outputÂ plusÂ aÂ 
whiteÂ noiseÂ input.Â TheÂ weightÂ onÂ theÂ lastÂ pÂ outputÂ minimizes Â theÂ meanÂ squareÂ prediction Â errorÂ ofÂ theÂ 
ARÂ model.Â IfÂ y(t)Â isÂ theÂ currentÂ valueÂ ofÂ theÂ output,Â andÂ y(t)Â presentsÂ aÂ zeroâ€meanÂ whiteÂ noiseÂ input,Â 
theÂ AR(p)Â modelÂ canÂ beÂ expressed Â byÂ Equation Â (2):Â 
İ•áˆºİáˆ»àµŒà·âˆ… à¯œà¯£
à¯œà­€à¬µİ•áˆºİàµ†İ…áˆ»àµ… ß¦áˆºİáˆ» Â  (2)Â 
whereÂ y(t)Â isÂ theÂ timeÂ seriesÂ toÂ beÂ modelled, Â âˆ…à¯œÂ areÂ theÂ modelÂ coefficients, Â ß¦áˆºİáˆ»Â isÂ whiteÂ noise,Â 
independent Â ofÂ theÂ previous Â points,Â andÂ pÂ isÂ theÂ orderÂ ofÂ theÂ ARÂ model.Â Â 
Yuleâ€“Walker Â methodÂ isÂ usedÂ forÂ FE.Â TheÂ Yuleâ€“Walker Â parametric Â methodÂ calculates Â theÂ ARÂ 
parameters Â throughÂ theÂ biasedÂ estimation Â ofÂ theÂ autocorrelation Â functionÂ givenÂ byÂ Equation Â (3),Â 
Signal 
collection
Signal Pre-
processing
Feature 
extraction & 
selection
ML & ANN
Level 
Delamination
Figure 1. Process for determining the level of delamination in the Wind Turbine Blades (WTB). Machine
Learning (ML); Artiï¬cial Neural Networks (ANN).
The wavelet threshold denoising method is applied by employing a multilevel 1D wavelet
analysis by Daubechies family [ 49,50]. The wavelet decomposition structure of the signal is
extracted. The threshold for the denoising is obtained by the wavelet coefï¬cients selection rule
using a penalization method provided by Birg Ã©-Massart [51,52].
Each set of ultrasonic signals of every delamination level is averaged and normalized by
Equation (1) to avoid false positive damage:
Ë†y=y my
sy(1)
where Ë†yis the normalized signal, myis the mean, and syis the standard deviation of y.
In an AR model of order p, the current output is a linear combination of the last poutput plus
a white noise input. The weight on the last poutput minimizes the mean square prediction error of the
AR model. If y(t) is the current value of the output, and y(t) presents a zero-mean white noise input,
the AR( p) model can be expressed by Equation (2):
y(t)=p
Ã¥
i=1?iy(t i)+x(t) (2)
where y(t) is the time series to be modelled, ?iare the model coefï¬cients, x(t). is white noise,
independent of the previous points, and pis the order of the AR model.
Yuleâ€“Walker method is used for FE. The Yuleâ€“Walker parametric method calculates the AR
parameters through the biased estimation of the autocorrelation function given by Equation (3),
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 4 of 16
0
BBBBBB@r(0) r(1) r(2) r(p 2)r(p 1)
r(1) r(0) r(1) r(p 3)r(p 2)
...............
r(p 2)r(p 3)r(p 4) r(0) r(1)
r(p 1)r(p 2)r(p 3) r(1) r(0)1
CCCCCCA0
BBBBBB@?(1)
?(2)
...
?(p 1)
?(p)1
CCCCCCA=0
BBBBBB@r(1)
r(2)
...
r(p 1)
r(p)1
CCCCCCA(3)
where r(m)is the biased form of the autocorrelation function. It ensures that the autocorrelation rmatrix
is positive. The value of r(m)is given by Equation (4).
r(m)=1
NN m 1
Ã¥
N=0x(n)+x(n+m) m0 (4)
The AR coefï¬cients ( ?) are obtained using the Levisonâ€“Durbin algorithm [ 53]. Figure 2 shows
Yuleâ€“Walker Power Spectral Density (PSD) of all delamination levels in the WTB.
EnergiesÂ 2018,Â 11,Â 13Â  4Â ofÂ 16Â 
Â Û‰ÛˆÛ‡İáˆºà¬´áˆ»İáˆºà¬µáˆ»İáˆºà¬¶áˆ»â‹¯İáˆºà¯£à¬¿à¬¶áˆ»İáˆºà¯£à¬¿à¬µáˆ»
İáˆºà¬µáˆ»İáˆºà¬´áˆ»İáˆºà¬µáˆ»â‹¯İáˆºà¯£à¬¿à¬·áˆ»İáˆºà¯£à¬¿à¬¶áˆ»
â‹®â‹®â‹® â‹®â‹®
İáˆºà¯£à¬¿à¬¶áˆ»İáˆºà¯£à¬¿à¬·áˆ»İáˆºà¯£à¬¿à¬¸áˆ»â‹¯İ áˆºà¬´áˆ»İáˆºà¬µáˆ»
İáˆºà¯£à¬¿à¬µáˆ»İáˆºà¯£à¬¿à¬¶áˆ»İáˆºà¯£à¬¿à¬·áˆ»â‹¯İ áˆºà¬µáˆ»İáˆºà¬´áˆ»ÛŒÛ‹ÛŠ
Û‰ÛˆÛˆÛ‡âˆ…áˆºà¬µáˆ»
âˆ…áˆºà¬¶áˆ»
â‹®
âˆ…áˆºà¯£à¬¿à¬µáˆ»
âˆ…áˆºà¯£áˆ»ÛŒÛ‹Û‹ÛŠ
àµŒ
Û‰ÛˆÛ‡İáˆºà¬µáˆ»
İáˆºà¬¶áˆ»
â‹®
İáˆºà¯£à¬¿à¬µáˆ»
İáˆºà¯£áˆ»ÛŒÛ‹ÛŠÂ  (3)Â 
whereÂ r(m)Â isÂ theÂ biasedÂ formÂ ofÂ theÂ autocorrelation Â function. Â ItÂ ensuresÂ thatÂ theÂ autocorrelation Â rÂ 
matrixÂ isÂ positive. Â TheÂ valueÂ ofÂ r(m)Â isÂ givenÂ byÂ Equation Â (4).Â 
İáˆºİ‰áˆ»àµŒ1
Ü°	à·İ”âˆ—áˆºİŠáˆ»àµ…İ”áˆºİŠàµ…İ‰áˆ»à¯‡à¬¿à¯ à¬¿à¬µ
à¯‡à­€à¬´İ‰àµ’0Â  (4)Â 
TheÂ ARÂ coefficients Â (âˆ…)Â areÂ obtained Â usingÂ theÂ Levisonâ€“Durbin Â algorithm Â [53].Â FigureÂ 2Â showsÂ 
Yuleâ€“Walker Â PowerÂ SpectralÂ DensityÂ (PSD)Â ofÂ allÂ delamination Â levelsÂ inÂ theÂ WTB.Â 
Â 
FigureÂ 2.Â Yuleâ€“Walker Â powerÂ spectralÂ densityÂ forÂ signalsÂ atÂ 55Â kHzÂ inÂ eachÂ scenario. Â 
Akaikeâ€™s Â Information Â Criterion Â (AIC)Â hasÂ beenÂ usedÂ toÂ reduceÂ theÂ dimensionality Â ofÂ theÂ featureÂ 
extraction. Â TheÂ AICÂ isÂ aÂ measure Â ofÂ theÂ goodness â€ofâ€fitÂ ofÂ anÂ estimated Â statistical Â model,Â basedÂ onÂ theÂ 
tradeâ€offÂ betweenÂ fittingÂ accuracy Â andÂ theÂ numberÂ ofÂ estimated Â parameters. Â AICÂ isÂ givenÂ byÂ Equation Â 
(5):Â 
Ü£Ü¥Ü« àµŒ Ü° à¯§lnáˆºß³áˆ»àµ…2Ü°à¯£Â  (5)Â 
ß³àµŒÜ°/Ü´ÜµÜµ à¯§Â  (6)Â 
whereÂ Ü°à¯£Â isÂ theÂ numberÂ ofÂ estimated Â parameters, Â Ü°à¯§Â theÂ numberÂ ofÂ predicted Â dataÂ points,Â ß³Â theÂ 
error,Â andÂ 	Ü´ÜµÜµÂ theÂ averageÂ sumâ€ofâ€squareÂ residualÂ error.Â 
3.Â Classification Â Procedure Â 
3.1.Â MachineÂ LearningÂ Approach Â Â 
AÂ supervised Â classification Â isÂ considered Â inÂ ML,Â whereÂ theÂ sameÂ numberÂ ofÂ signalsÂ isÂ setÂ forÂ eachÂ 
group,Â orÂ population. Â TheÂ crossâ€validation Â technique Â hasÂ beenÂ employed Â toÂ estimateÂ theÂ probability Â 
ofÂ misclassification, Â andÂ toÂ avoidÂ overfitting Â inÂ allÂ casesÂ considered. Â 
Decision Â TreeÂ (DT)Â isÂ aÂ classifier Â usedÂ toÂ determine Â ifÂ theÂ datasetÂ containsÂ different Â classesÂ ofÂ 
objectsÂ thatÂ canÂ beÂ interpreted Â significantly Â inÂ theÂ contextÂ ofÂ aÂ substantive Â theory.Â DTÂ generates Â aÂ splitÂ 
ofÂ spaceÂ fromÂ aÂ labelledÂ trainingÂ set.Â TheÂ objective Â isÂ toÂ separateÂ theÂ elements Â ofÂ eachÂ classÂ intoÂ 
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Normalized Frequency  (  rad/sample)-100-80-60-40-20020
Yule-Walker Power Spectral Density Estimate
Scenario 1
Scenario 2
Scenario 3
Scenario 4
Scenario 5
Scenario 6
Figure 2. Yuleâ€“Walker power spectral density for signals at 55 kHz in each scenario.
Akaikeâ€™s Information Criterion ( AIC) has been used to reduce the dimensionality of the feature
extraction. The AIC is a measure of the goodness-of-ï¬t of an estimated statistical model, based on
the trade-off between ï¬tting accuracy and the number of estimated parameters. AIC is given by
Equation (5):
AIC =Ntln(e)+2Np (5)
e=SSR/Nt (6)
where Npis the number of estimated parameters, Ntthe number of predicted data points, ethe error,
and SSR the average sum-of-square residual error.
3. Classiï¬cation Procedure
3.1. Machine Learning Approach
A supervised classiï¬cation is considered in ML, where the same number of signals is set for each
group, or population. The cross-validation technique has been employed to estimate the probability of
misclassiï¬cation, and to avoid overï¬tting in all cases considered.
Decision Tree (DT) is a classiï¬er used to determine if the dataset contains different classes of
objects that can be interpreted signiï¬cantly in the context of a substantive theory. DT generates a split
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 5 of 16
of space from a labelled training set. The objective is to separate the elements of each class into different
labelled regions, called leaves, minimizing a local error. Each internal node in the tree is a question,
or decision, that determines the branch of the tree that must be taken to reach a leaf. DT is determined
in the following cases: how to split the space, called Splitting Rules (SR); stopping the condition of
splitting; labelling function of a region, and; measurement of error.
The purpose of the SR is to minimize the impurity of the node. In this case, SR is based on Giniâ€™s
Diversity Index ( GDI) [54], given by Equation (7):
GDI =1 Ã¥
ip2(i) (7)
where the sum is over the classes iat the node, and p(i) is the observed fraction of classes with the class
ithat has the node. For a node with only one class, called the pure node, GDI = 0, being GDI > 0 in
other cases. The algorithm stops if the node is pre-set at maximum depth; all elements of the node are
the same class; there is no empty sub node; or SR does not reach a pre-set value.
DT labels a leaf, or region, when it is already considered as a terminal. The labelling function is
set by Equation (8):
l0=arg min l0(
k
Ã¥
l=1NIcl,l0)
(8)
where NIis the number of elements of class l,l0is the class to label, and cl,l0is the labelling cost.
The labelling cost considering all classes is calculated, and l0is selected to minimize the error,
where a random one is chosen in case of a tie. Equation (9) provides a classiï¬cation average error:
e=1
NÃ¥N
I=1err(li,l0
i) (9)
where err 
li,l0
i
is the error of labelling a class lasl0. This error will be solved by splitting the space
and assigning a label to each split.
The number of partitions has been adjusted using the Decision Tree Complex (DTC) algorithm.
It allows a maximum of 100 partitions to avoid overï¬tting.
Quadratic Discriminant Analysis (QDA) is employed to classify each feature ( x) in pre-existing
different groups, from the information of a set of variables ( x), called variable classiï¬ers [ 55].
The information of each variable ( x) is synthesized in a discriminant function. Each class produces
a dataset using Gaussian mixture distribution, given by Equation (10):
fk(x)=1
(2p)P/2jÃ¥kj1/2exp"
 1
2(x mk)T 1
Ã¥
k(x mk)#
(10)
where miandÃ¥kis the class k(kiK) population mean vector and covariance matrix.
The metric distance to each class is calculated using the varianceâ€“covariance matrix of each class,
instead of the global matrix grouped in QDA [56], according to the Equation (11);
d2
ik=(xi xk)C 1
k(xi xk)0(11)
where d2
ikis the squared distance between sample i, and the class kcentroid, and CKis the corresponding
varianceâ€“covariance matrix for that class.
The maximum of the a posteriori discriminant function gk(x), employing the Bayes rule and
natural logs, is given by Equation (12):
gk(x)= 1
2(x mk)T 1
Ã¥
k(x mk) 1
2logÃ¥k
+log(pk) (12)
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 6 of 16
K-Nearest Neighbors (KNN). The KNN classiï¬er has been used for pattern classiï¬cation and ML.
The KNN is based on the principle that an unclassiï¬ed instance within a dataset is assigned to the
class of the nearest previously sorted instances [ 57]. Each instance can be considered as a point within
an n-dimensional instance space, where each of the n-dimensions corresponds to one of the n-features
that deï¬ne an instance [58].
The accuracy of KNN classiï¬cation depends on the metric used to compute distances between
different instances. In this case, the best performing classiï¬er is Weighted KNN (WKNN). WKNN
assigns weights to neighbors regarding the distance calculated [ 59]. Weighted metric can be deï¬ned as
a distance between an unclassiï¬ed sample x, and a training sample xi, given by Equation (13):
d0(x,xi)=(x,xi)TÃ¥I(x,xi)T(13)
3.2. Artiï¬cial Neuronal Network (ANN): Multilayer Perceptron (MLP)
In this paper, three layers of processing units are used as the structure (15/15/6). Backpropagation,
together with the algorithm scaled conjugate gradient and performance cross entropy [ 60,61] with
â€œearly stoppingâ€ to avoid overï¬tting [62], has been employed as the training mode. ANN is given by
Equation (14):
zk=Ã¥
jw0
kjyj q0
i=Ã¥
jw0
kjf 
Ã¥
iwjixi qj!
 q0
j (14)
where xi. is the input, yi. the hidden layer output, zi. the ï¬nal layer output, tkthe target output, wjithe
hidden layer weight, w0kj. the ï¬nal layer weight, qjhidden layer bias, q0kthe ï¬nal layer bias, and f()
is the activation function sigmoid type.
The sigmoid function, Figure 3, is used as the activation function of the ANN, given by
Equation (15). It provides an output in the range [0, 1].
f(x)=1
1+e x(15)
EnergiesÂ 2018,Â 11,Â 13Â  6Â ofÂ 16Â 
Â TheÂ accuracy Â ofÂ KNNÂ classification Â depends Â onÂ theÂ metricÂ usedÂ toÂ compute Â distances Â betweenÂ 
different Â instances. Â InÂ thisÂ case,Â theÂ bestÂ performing Â classifier Â isÂ Weighted Â KNNÂ (WKNN). Â WKNNÂ 
assignsÂ weightsÂ toÂ neighbors Â regarding Â theÂ distanceÂ calculated Â [59].Â Weighted Â metricÂ canÂ beÂ definedÂ 
asÂ aÂ distanceÂ betweenÂ anÂ unclassified Â sampleÂ x,Â andÂ aÂ trainingÂ sampleÂ İ”à¯œ,Â givenÂ byÂ Equation Â (13):Â 
İ€á‡±áˆºİ”,İ”à¯œáˆ»àµŒáˆºİ”,İ”à¯œáˆ»à¯à·áˆºİ”,İ”à¯œáˆ»à¯
à¯‚Â  (13)Â 
3.2.Â ArtificialÂ Neuronal Â NetworkÂ (ANN):Â Multilayer Â Perceptron Â (MLP)Â 
InÂ thisÂ paper,Â threeÂ layersÂ ofÂ processing Â unitsÂ areÂ usedÂ asÂ theÂ structure Â (15/15/6). Â 
Backpropagation, Â togetherÂ withÂ theÂ algorithm Â scaledÂ conjugate Â gradientÂ andÂ performance Â crossÂ 
entropyÂ [60,61]Â withÂ â€œearlyÂ stoppingâ€ Â toÂ avoidÂ overfitting Â [62],Â hasÂ beenÂ employed Â asÂ theÂ trainingÂ 
mode.Â ANNÂ isÂ givenÂ byÂ Equation Â (14):Â 
İ–à¯àµŒà·â€²İ“ à¯à¯İ•à¯àµ†â€²ß à¯œ	
à¯àµŒà·â€²İ“ à¯à¯
à¯İ‚àµ­à·İ“ à¯à¯œ
à¯œİ”à¯œàµ†ß à¯àµ±àµ†â€²ß à¯Â  (14)Â 
whereÂ İ”à¯œÂ isÂ theÂ input,Â İ•à¯œÂ theÂ hiddenÂ layerÂ output,Â İ–à¯œÂ theÂ finalÂ layerÂ output,Â İà¯Â theÂ targetÂ output,Â 
İ“à¯à¯œÂ theÂ hiddenÂ layerÂ weight,Â â€²İ“à¯à¯Â theÂ finalÂ layerÂ weight,Â ß à¯Â hiddenÂ layerÂ bias,Â â€²ß à¯Â theÂ finalÂ layerÂ 
bias,Â andÂ İ‚(âˆ™)Â isÂ theÂ activation Â functionÂ sigmoidÂ type.Â 
TheÂ sigmoidÂ function, Â FigureÂ 3,Â isÂ usedÂ asÂ theÂ activation Â functionÂ ofÂ theÂ ANN,Â givenÂ byÂ Equation Â 
(15).Â ItÂ provides Â anÂ outputÂ inÂ theÂ rangeÂ [0,Â 1].Â 
İ‚áˆºİ”áˆ»àµŒ1
1àµ…İà¬¿à¯«Â  (15)Â 
Â 
FigureÂ 3.Â SigmoidÂ activation Â function. Â 
TheÂ MLPÂ isÂ testedÂ initiallyÂ withÂ anÂ ANNÂ architecture, Â andÂ trainedÂ withÂ 70%Â ofÂ theÂ experiments. Â 
TheÂ ANNÂ architecture Â isÂ chosenÂ according Â toÂ theÂ bestÂ accuracy Â andÂ performance. Â TheÂ networkÂ isÂ 
validated Â withÂ different Â casesÂ (30%)Â toÂ determine Â ifÂ theÂ learningÂ isÂ correct,Â andÂ toÂ checkÂ ifÂ itÂ classifies Â 
correctly. Â 
3.2.1.Â Training Â ProcessÂ 
Backpropagation Â (BP)Â isÂ oneÂ ofÂ theÂ simplestÂ andÂ mostÂ generalÂ methods Â forÂ supervised Â trainingÂ 
ofÂ multilayer Â ANNs.Â Techniques, Â suchÂ asÂ scaled,Â haveÂ beenÂ developed Â toÂ accelerate Â theÂ trainingÂ 
methodÂ BP,Â standardization, Â orÂ normalization Â thatÂ performs Â preâ€processing Â inputs.Â InÂ thisÂ paper,Â BPÂ 
modeÂ algorithms Â areÂ theÂ scaledÂ conjugate Â gradientÂ andÂ performance Â crossÂ entropy.Â Â 
Conjugate Â gradientÂ algorithm, Â basedÂ onÂ performing Â gradientÂ descendent, Â isÂ aÂ secondâ€orderÂ 
analysisÂ ofÂ theÂ error,Â employed Â toÂ determine Â theÂ optimalÂ rateÂ ofÂ learning, Â andÂ extractÂ information Â 
provided Â byÂ theÂ secondÂ derivative Â ofÂ theÂ errorÂ byÂ theÂ HessianÂ matrix,Â (H),Â Equation Â (16).Â 00.10.20.30.40.50.60.70.80.91
0
Figure 3. Sigmoid activation function.
The MLP is tested initially with an ANN architecture, and trained with 70% of the experiments.
The ANN architecture is chosen according to the best accuracy and performance. The network
is validated with different cases (30%) to determine if the learning is correct, and to check if it
classiï¬es correctly.
3.2.1. Training Process
Backpropagation (BP) is one of the simplest and most general methods for supervised training of
multilayer ANNs. Techniques, such as scaled, have been developed to accelerate the training method
BP , standardization, or normalization that performs pre-processing inputs. In this paper, BP mode
algorithms are the scaled conjugate gradient and performance cross entropy.
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 7 of 16
Conjugate gradient algorithm, based on performing gradient descendent, is a second-order
analysis of the error, employed to determine the optimal rate of learning, and extract information
provided by the second derivative of the error by the Hessian matrix, ( H), Equation (16).
H=Â¶2E(W)
Â¶wijÂ¶wkl(16)
The algorithm uses different approaches to avoid high computational costs. The MLP is employed
in different stages during the learning process, where the reduction of error can be slow. It is suggested
that the Mean Square Error (MSE) replaces the cross-entropy error function, because MSE shows
a better network performance.
3.2.2. Architecture of the Network
Different ANN structures have been tested, and the structure that provides the best results was
a hidden layer with 15 neurons, based on comparative performance by trial and error. The network
architecture set was 15-15-6 (Figure 4).
EnergiesÂ 2018,Â 11,Â 13Â  7Â ofÂ 16Â 
Â Û¶àµŒß²à¬¶Ü§áˆºÜ…áˆ»
İ“ß²à¯œà¯İ“ß²à¯à¯ŸÂ  (16)Â 
TheÂ algorithm Â usesÂ different Â approaches Â toÂ avoidÂ highÂ computational Â costs.Â TheÂ MLPÂ isÂ 
employed Â inÂ different Â stagesÂ duringÂ theÂ learningÂ process,Â whereÂ theÂ reduction Â ofÂ errorÂ canÂ beÂ slow.Â 
ItÂ isÂ suggested Â thatÂ theÂ MeanÂ SquareÂ ErrorÂ (MSE)Â replacesÂ theÂ crossâ€entropyÂ errorÂ function, Â becauseÂ 
MSEÂ showsÂ aÂ betterÂ networkÂ performance. Â 
3.2.2.Â Architecture Â ofÂ theÂ Network Â 
Different Â ANNÂ structures Â haveÂ beenÂ tested,Â andÂ theÂ structure Â thatÂ provides Â theÂ bestÂ resultsÂ wasÂ 
aÂ hiddenÂ layerÂ withÂ 15Â neurons, Â basedÂ onÂ comparative Â performance Â byÂ trialÂ andÂ error.Â TheÂ networkÂ 
architecture Â setÂ wasÂ 15â€15â€6Â (FigureÂ 4).Â 
Â 
FigureÂ 4.Â Artificial Â NeuralÂ Networks Â (ANN)Â architecture. Â 
3.3.Â Classifier Â Evaluation Â 
TheÂ Receiver Â Operating Â Characteristic Â (ROC)Â analysis, Â basedÂ onÂ Confusion Â MatrixÂ (CM),Â isÂ usedÂ 
toÂ evaluateÂ theÂ classification. Â CMÂ determines Â theÂ qualityÂ ofÂ aÂ classifier Â andÂ itsÂ performance. Â TheÂ mainÂ 
parameters Â considered Â inÂ CMÂ are:Â 
ï‚· TP:Â TrueÂ positiveÂ isÂ theÂ realÂ successÂ ofÂ theÂ classifier. Â 
ï‚· FP:Â FalseÂ positiveÂ isÂ theÂ sumÂ ofÂ theÂ valuesÂ ofÂ aÂ classÂ inÂ theÂ corresponding Â CMÂ column,Â excluding Â 
theÂ TP.Â 
ï‚· FN:Â FalseÂ negative Â isÂ theÂ sumÂ ofÂ theÂ valuesÂ ofÂ aÂ classÂ inÂ theÂ corresponding Â CMÂ row,Â excluding Â 
theÂ TP.Â Â 
ï‚· TN:Â TrueÂ negative Â isÂ theÂ sumÂ ofÂ allÂ columns Â andÂ rows,Â excluding Â theÂ columnÂ andÂ rowÂ ofÂ theÂ 
class.Â 
TheÂ following Â equations Â willÂ beÂ appliedÂ toÂ findÂ theÂ mainÂ measurement Â parameters Â whenÂ theyÂ 
areÂ known:Â 
ï‚· Recall,Â R,Â knownÂ asÂ trueÂ positiveÂ rate,Â isÂ theÂ probability Â ofÂ beingÂ correctly Â classified, Â givenÂ byÂ 
Equation Â (17).Â 
Ü´àµŒÜ²Ü¶
Ü²Ü¶ àµ…Ü°Ü¨Â  (17)Â 
Figure 4. Artiï¬cial Neural Networks (ANN) architecture.
3.3. Classiï¬er Evaluation
The Receiver Operating Characteristic (ROC) analysis, based on Confusion Matrix (CM), is used
to evaluate the classiï¬cation. CM determines the quality of a classiï¬er and its performance. The main
parameters considered in CM are:
 TP: True positive is the real success of the classiï¬er.
 FP: False positive is the sum of the values of a class in the corresponding CM column, excluding
theTP.
 FN: False negative is the sum of the values of a class in the corresponding CM row, excluding the TP.
 TN: True negative is the sum of all columns and rows, excluding the column and row of the class.
The following equations will be applied to ï¬nd the main measurement parameters when they
are known:
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 8 of 16
 Recall, R, known as true positive rate, is the probability of being correctly classiï¬ed, given by
Equation (17).
R=TP
TP+FN(17)
 Speciï¬city, S, also called the true negative rate, measures the proportion of negatives that are
correctly identiï¬ed, given by Equation (18).
S=TN
FP+TN(18)
Additional terms associated with ROC curves and CM are:
 Precision, P,
P=TP
FP+TP(19)
 F-score, F,
F=2PR
P+R(20)
The average performance in all categories is set by two conventional methods [63]:
 Macro average ( PM
i):PM,RM,FMis obtained by the averaging overall PM
i, where Mdenotes
macro average, and iis the scenario. They are calculated for each category, i.e., the values precision
is evaluated locally, PM
i, and then globally, PM.
 Micro average ( Pm
i):Pm,Rmand Fmvalue is obtained as: (i) TPi, FP i, FN ivalues are calculated for
each of the scenarios; (ii) the value of TP,FP, and FNare calculated as the sum of TPi, FP i, FN i;
and (iii) applying the equation of the measure that corresponds to it.
There are several indices that are extracted from the ROC curve to evaluate the efï¬ciency of
a classiï¬er. The Area Under Curve ( AUC ), value between 0.5 and 1, is the area between the ROC
curve and the negative diagonal [ 64,65].AUC0.5 indicates that the classiï¬er is invalid, and AUC = 1
indicates a perfect rating, because there is a region in which, for any point cut, the value of Rand Pis 1.
The statistical property of AUC is equivalent to the Wilcoxon test of ranks [ 65]. The AUC is also closely
related to the Gini coefï¬cient [54], which is twice the area between the diagonal and the ROC curve.
The recommendations by DemÅ¡ar, and Garcia and Herrera have been used to compare the
different classiï¬ers and analyze their best performance. Firstly, the Friedman Test will be used to
test the null hypothesis that all classiï¬ers achieve the same average. The Bonferroniâ€“Dunn test will
be applied to determine signiï¬cant differences between the top-ranked classiï¬er and the next one.
The Holm test will be applied to contrast the results.
4. Case Study
The experiments were carried out in laboratory conditions. Regarding reference [ 66], it is possible
to reproduce the test in working conditions by a multi frequency analysis. Low frequencies are
associated with the vibration of the blade, medium frequencies with acoustic emissions, and high
frequencies with the ultrasonic excitation signal.
Delamination, perpendicular to the direction of propagation according to Reference [ 19], has been
carried out, with the smallest side perpendicular to the direction of propagation, and the larger side
parallel to the propagation direction. The occurrence of multiple-delamination and transverse cracking
has not been encountered in this study, but, according to [ 66], it would be affected in a similar way to
the case study considered in this paper. Therefore, it would be possible to detect a potential failure
with the presented approach.
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 9 of 16
Six different scenarios have been studied: the WTB without delamination (free of fault) was
considered in the ï¬rst scenario. A separation of layers was induced in the second scenario.
The dimensions of the disunion were one centimeter wide by one centimeter deep. Subsequently,
from scenarios three to six, deeper delamination was induced by increasing the depth in a centimeter
in each state. Figure 5 shows the arrangement of the transducers and delamination in the WTB section,
and Table 1 shows the deep values ( x).
EnergiesÂ 2018,Â 11,Â 13Â  9Â ofÂ 16Â 
Â Â 
FigureÂ 5.Â SchemeÂ ofÂ MacroÂ FiberÂ Composite Â (MFC)Â transducers Â locationÂ forÂ delamination Â detection. Â 
TableÂ 1.Â Delamination Â sizeÂ inÂ WindÂ TurbineÂ BladesÂ (WTB)Â section.Â 
LevelÂ  x(cm) Delamination Â AreaÂ (cm2)
1Â  0Â (freeÂ ofÂ fault)Â  0Â 
2Â  1Â Â  1Â 
3Â  2Â Â  2Â 
4Â  3Â Â  3Â 
5Â  4Â Â  4Â 
6Â  5Â Â  5Â 
GuidedÂ wavesÂ wereÂ generated Â inÂ theÂ WTBÂ sectionÂ usingÂ MacroÂ FiberÂ Composite Â (MFC)Â 
transducers. Â FigureÂ 6Â showsÂ theÂ transducer Â arrangement Â onÂ theÂ downwind Â sideÂ ofÂ theÂ WTB.Â TheÂ 
ultrasonic Â technique Â usedÂ isÂ calledÂ â€œpitchÂ andÂ catchâ€Â [67].Â AÂ shortÂ ultrasonic Â pulseÂ isÂ emittedÂ byÂ theÂ 
MFCÂ transmitter Â (Tx).Â TheÂ signalÂ isÂ collected Â byÂ theÂ MFCÂ sensorÂ (Rx).Â TheÂ excitation Â pulseÂ isÂ aÂ sixÂ 
cycleÂ Hanning Â pulseÂ [68,69].Â 
Â 
FigureÂ 6.Â Placement Â ofÂ sensorÂ andÂ delamination. Â 
FiveÂ different Â excitation Â frequencies Â wereÂ conducted Â forÂ eachÂ scenarioÂ ofÂ delamination Â toÂ checkÂ 
theÂ accuracy Â regarding Â theÂ frequencies Â ofÂ delamination Â detection: Â 18Â kHz,Â 25Â kHz,Â 30Â kHz,Â 37Â Hz,Â andÂ 
55Â kHz.Â SixÂ hundred Â signalsÂ fromÂ eachÂ frequency Â wereÂ collected. Â TheÂ bestÂ accuracy Â wasÂ foundÂ atÂ 55Â 
kHz.Â FigureÂ 7Â showsÂ signalsÂ acquired Â atÂ 55Â kHzÂ inÂ allÂ scenarios. Â Â 
Figure 5. Scheme of Macro Fiber Composite (MFC) transducers location for delamination detection.
Table 1. Delamination size in Wind Turbine Blades (WTB) section.
Level x(cm) Delamination Area (cm2)
1 0 (free of fault) 0
2 1 1
3 2 2
4 3 3
5 4 4
6 5 5
Guided waves were generated in the WTB section using Macro Fiber Composite (MFC)
transducers. Figure 6 shows the transducer arrangement on the downwind side of the WTB.
The ultrasonic technique used is called â€œpitch and catchâ€ [ 67]. A short ultrasonic pulse is emitted by
the MFC transmitter (Tx). The signal is collected by the MFC sensor (Rx). The excitation pulse is a six
cycle Hanning pulse [68,69].
EnergiesÂ 2018,Â 11,Â 13Â  9Â ofÂ 16Â 
Â Â 
FigureÂ 5.Â SchemeÂ ofÂ MacroÂ FiberÂ Composite Â (MFC)Â transducers Â locationÂ forÂ delamination Â detection. Â 
TableÂ 1.Â Delamination Â sizeÂ inÂ WindÂ TurbineÂ BladesÂ (WTB)Â section.Â 
LevelÂ  x(cm) Delamination Â AreaÂ (cm2)
1Â  0Â (freeÂ ofÂ fault)Â  0Â 
2Â  1Â Â  1Â 
3Â  2Â Â  2Â 
4Â  3Â Â  3Â 
5Â  4Â Â  4Â 
6Â  5Â Â  5Â 
GuidedÂ wavesÂ wereÂ generated Â inÂ theÂ WTBÂ sectionÂ usingÂ MacroÂ FiberÂ Composite Â (MFC)Â 
transducers. Â FigureÂ 6Â showsÂ theÂ transducer Â arrangement Â onÂ theÂ downwind Â sideÂ ofÂ theÂ WTB.Â TheÂ 
ultrasonic Â technique Â usedÂ isÂ calledÂ â€œpitchÂ andÂ catchâ€Â [67].Â AÂ shortÂ ultrasonic Â pulseÂ isÂ emittedÂ byÂ theÂ 
MFCÂ transmitter Â (Tx).Â TheÂ signalÂ isÂ collected Â byÂ theÂ MFCÂ sensorÂ (Rx).Â TheÂ excitation Â pulseÂ isÂ aÂ sixÂ 
cycleÂ Hanning Â pulseÂ [68,69].Â 
Â 
FigureÂ 6.Â Placement Â ofÂ sensorÂ andÂ delamination. Â 
FiveÂ different Â excitation Â frequencies Â wereÂ conducted Â forÂ eachÂ scenarioÂ ofÂ delamination Â toÂ checkÂ 
theÂ accuracy Â regarding Â theÂ frequencies Â ofÂ delamination Â detection: Â 18Â kHz,Â 25Â kHz,Â 30Â kHz,Â 37Â Hz,Â andÂ 
55Â kHz.Â SixÂ hundred Â signalsÂ fromÂ eachÂ frequency Â wereÂ collected. Â TheÂ bestÂ accuracy Â wasÂ foundÂ atÂ 55Â 
kHz.Â FigureÂ 7Â showsÂ signalsÂ acquired Â atÂ 55Â kHzÂ inÂ allÂ scenarios. Â Â 
Figure 6. Placement of sensor and delamination.
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 10 of 16
Five different excitation frequencies were conducted for each scenario of delamination to check
the accuracy regarding the frequencies of delamination detection: 18 kHz, 25 kHz, 30 kHz, 37 Hz,
and 55 kHz. Six hundred signals from each frequency were collected. The best accuracy was found at
55 kHz. Figure 7 shows signals acquired at 55 kHz in all scenarios.
EnergiesÂ 2018,Â 11,Â 13Â  10Â ofÂ 16Â 
Â Â 
FigureÂ 7.Â SignalsÂ forÂ different Â scenarios Â atÂ 55Â kHz.Â 
5.Â ResultsÂ andÂ Discussion Â 
5.1.Â FeaturesÂ SelectionÂ Â 
FifteenÂ featuresÂ (theÂ optimalÂ rangeÂ beingÂ fromÂ 15Â toÂ 30)Â haveÂ beenÂ usedÂ initiallyÂ toÂ avoidÂ theÂ 
problemÂ ofÂ overfitting Â andÂ overâ€dimensioning Â ofÂ theÂ ANNÂ architecture. Â TheÂ AICÂ methodÂ hasÂ beenÂ 
appliedÂ inÂ allÂ levels.Â InÂ thisÂ case,Â theÂ numberÂ ofÂ featuresÂ thatÂ optimizes Â theÂ modelÂ isÂ pÂ =Â 15Â (seeÂ FigureÂ 
8)Â becauseÂ theÂ minimum Â AICÂ valueÂ forÂ allÂ levelsÂ isÂ found.Â Therefore, Â theÂ inputsÂ wereÂ setÂ toÂ 15Â forÂ eachÂ 
classifier. Â TheÂ FPEÂ criterionÂ hasÂ beenÂ used,Â andÂ produced Â similarÂ results.Â 
Â 
FigureÂ 8.Â Akaikeâ€™s Â Information Â Criterion Â (AIC)Â curveÂ features. Â AR:Â Autoâ€Regressive. Â 
Â Â 
Amplitude
â€16â€14â€12â€10â€8â€6â€4â€20
123456789 1 0 1 1 1 2 1 3 1 4 1 5Magnitude
AR order (p)Appropriate Model Order Selection using AIC
Technique
Level 1 Level 2 Level 3
Level 4 Level 5 Level 6
Figure 7. Signals for different scenarios at 55 kHz.
5. Results and Discussion
5.1. Features Selection
Fifteen features (the optimal range being from 15 to 30) have been used initially to avoid the
problem of overï¬tting and over-dimensioning of the ANN architecture. The AIC method has been
applied in all levels. In this case, the number of features that optimizes the model is p= 15 (see Figure 8)
because the minimum AIC value for all levels is found. Therefore, the inputs were set to 15 for each
classiï¬er. The FPE criterion has been used, and produced similar results.
EnergiesÂ 2018,Â 11,Â 13Â  10Â ofÂ 16Â 
Â Â 
FigureÂ 7.Â SignalsÂ forÂ different Â scenarios Â atÂ 55Â kHz.Â 
5.Â ResultsÂ andÂ Discussion Â 
5.1.Â FeaturesÂ SelectionÂ Â 
FifteenÂ featuresÂ (theÂ optimalÂ rangeÂ beingÂ fromÂ 15Â toÂ 30)Â haveÂ beenÂ usedÂ initiallyÂ toÂ avoidÂ theÂ 
problemÂ ofÂ overfitting Â andÂ overâ€dimensioning Â ofÂ theÂ ANNÂ architecture. Â TheÂ AICÂ methodÂ hasÂ beenÂ 
appliedÂ inÂ allÂ levels.Â InÂ thisÂ case,Â theÂ numberÂ ofÂ featuresÂ thatÂ optimizes Â theÂ modelÂ isÂ pÂ =Â 15Â (seeÂ FigureÂ 
8)Â becauseÂ theÂ minimum Â AICÂ valueÂ forÂ allÂ levelsÂ isÂ found.Â Therefore, Â theÂ inputsÂ wereÂ setÂ toÂ 15Â forÂ eachÂ 
classifier. Â TheÂ FPEÂ criterionÂ hasÂ beenÂ used,Â andÂ produced Â similarÂ results.Â 
Â 
FigureÂ 8.Â Akaikeâ€™s Â Information Â Criterion Â (AIC)Â curveÂ features. Â AR:Â Autoâ€Regressive. Â 
Â Â 
Amplitude
â€16â€14â€12â€10â€8â€6â€4â€20
123456789 1 0 1 1 1 2 1 3 1 4 1 5Magnitude
AR order (p)Appropriate Model Order Selection using AIC
Technique
Level 1 Level 2 Level 3
Level 4 Level 5 Level 6
Figure 8. Akaikeâ€™s Information Criterion ( AIC) curve features. AR: Auto-Regressive.
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 11 of 16
5.2. Precision
Table 2 shows that the lowest precision is for QDA classiï¬er at Level 3, and is 28.50% in the worst
case. The best case is found for WKNN at Level 5, 99.83%. Level 5 provides the best results in all
classiï¬ers. The results of micro average and macro average vary from 62.25% to 91.50%.
Table 2. Precision. DTC: Decision Tree Complex; QDA: Quadratic Discriminant Analysis; WKNN:
Weighted K-Nearest Neighbors; ANN: Artiï¬cial Neural Networks.
Level DTC QDA WKNN ANN
1 0.8267 0.5633 0.8717 0.9262
2 0.8133 0.4000 0.8550 0.8583
3 0.7667 0.2850 0.8350 0.8593
4 0.9200 0.9217 0.9700 0.9089
5 0.9633 0.9733 0.9983 0.9934
6 0.8933 0.5917 0.9283 0.9457
Pm0.8639 0.6225 0.9097 0.9150
PM0.8639 0.6225 0.9097 0.9150
Ranking 1.8700 1.3700 3.2500 3.5000
Position 3 4 2 1
The recommendations by DemÅ¡ar have been employed to analyze the results of the classiï¬ers.
The Friedman test E-1 did not reject the null hypothesis ( p-value = 0.01690.05). The Bonferroniâ€“Dunn
test rejected the null hypothesis for p0.05, with a conï¬dence value a= 0.05 (Figure 9). The Holm test
rejected the null hypothesis for classiï¬er 2.
EnergiesÂ 2018,Â 11,Â 13Â  11Â ofÂ 16Â 
Â 5.2.Â PrecisionÂ 
TableÂ 2Â showsÂ thatÂ theÂ lowestÂ precision Â isÂ forÂ QDAÂ classifier Â atÂ LevelÂ 3,Â andÂ isÂ 28.50%Â inÂ theÂ worstÂ 
case.Â TheÂ bestÂ caseÂ isÂ foundÂ forÂ WKNNÂ atÂ LevelÂ 5,Â 99.83%.Â LevelÂ 5Â provides Â theÂ bestÂ resultsÂ inÂ allÂ 
classifiers. Â TheÂ resultsÂ ofÂ microÂ averageÂ andÂ macroÂ averageÂ varyÂ fromÂ 62.25%Â toÂ 91.50%.Â 
TableÂ 2.Â Precision. Â DTC:Â Decision Â TreeÂ Complex; Â QDA:Â Quadratic Â Discriminant Â Analysis; Â WKNN:Â 
Weighted Â Kâ€NearestÂ Neighbors; Â ANN:Â Artificial Â NeuralÂ Networks. Â 
LevelÂ  DTC QDA WKNN ANN
1Â  0.8267Â  0.5633Â  0.8717Â  0.9262Â 
2Â  0.8133Â  0.4000Â  0.8550Â  0.8583Â 
3Â  0.7667Â  0.2850Â  0.8350Â  0.8593Â 
4Â  0.9200Â  0.9217Â  0.9700Â  0.9089Â 
5Â  0.9633Â  0.9733Â  0.9983Â  0.9934Â 
6Â  0.8933Â  0.5917Â  0.9283Â  0.9457Â 
Ü²à°“Â  0.8639Â  0.6225Â  0.9097Â  0.9150Â 
Ü²à¯†Â  0.8639Â  0.6225Â  0.9097Â  0.9150Â 
RankingÂ  1.8700Â  1.3700Â  3.2500Â  3.5000Â 
PositionÂ  3Â  4Â  2Â  1Â 
TheÂ recommendations Â byÂ DemÅ¡arÂ haveÂ beenÂ employed Â toÂ analyzeÂ theÂ resultsÂ ofÂ theÂ classifiers. Â 
TheÂ Friedman Â testÂ Eâ€1Â didÂ notÂ rejectÂ theÂ nullÂ hypothesis Â (pâ€valueÂ =Â 0.0169Â â‰¤ 0.05).Â TheÂ Bonferroniâ€“
DunnÂ testÂ rejectedÂ theÂ nullÂ hypothesis Â forÂ pÂ â‰¤Â 0.05,Â withÂ aÂ confidence Â valueÂ Î±	=Â 0.05Â (FigureÂ 9).Â TheÂ 
HolmÂ testÂ rejectedÂ theÂ nullÂ hypothesis Â forÂ classifier Â 2.Â 
Â 
FigureÂ 9.Â Bonferroni â€DunnÂ test.Â ANN:Â Artificial Â NeuralÂ Networks; Â WKNN:Â Weighted Â Kâ€NearestÂ 
Neighbors; Â QDA:Â Quadratic Â Discriminant Â Analysis; Â DTC:Â Decision Â TreeÂ Complex. Â 
TheÂ bestÂ accuracy Â wasÂ foundÂ byÂ employing Â theÂ ANNÂ classifier Â (TableÂ 2).Â TheÂ testÂ indicates Â thatÂ 
QDAÂ shouldÂ beÂ discarded. Â 
5.3.Â RecallÂ 
TheÂ resultsÂ areÂ shownÂ inÂ TableÂ 3.Â TheÂ Friedman Â testÂ rejectedÂ theÂ nullÂ hypothesis Â (pâ€valueÂ =Â 
0.000076Â â‰¤Â 0.05),Â seeÂ TableÂ 3.Â TheÂ rejection Â ofÂ theÂ nullÂ hypothesis Â wasÂ confirmed Â byÂ aÂ postÂ hocÂ test.Â Â 
Â  Â 0.5 1 1.5 2 2.5 3 3.5 4 4.5
Critical Value for Significance4321
Figure 9. Bonferroni-Dunn test. ANN: Artiï¬cial Neural Networks; WKNN: Weighted K-Nearest
Neighbors; QDA: Quadratic Discriminant Analysis; DTC: Decision Tree Complex.
The best accuracy was found by employing the ANN classiï¬er (Table 2). The test indicates that
QDA should be discarded.
5.3. Recall
The results are shown in Table 3. The Friedman test rejected the null hypothesis ( p-value = 0.000076
0.05), see Table 3. The rejection of the null hypothesis was conï¬rmed by a post hoc test.
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 12 of 16
Table 3. Recall.
Level DTC QDA WKNN ANN
1 0.8656 0.7161 0.9175 0.9200
2 0.7428 0.5240 0.8328 0.8783
3 0.8028 0.3087 0.8254 0.8450
4 0.9200 0.7238 0.9417 0.9483
5 0.9666 0.6213 0.9788 0.9983
6 0.8948 0.8617 0.9653 0.9000
Rm0.8639 0.6225 0.9097 0.9150
RM0.8654 0.6259 0.9103 0.9150
Ranking 2.0000 1.0000 3.1700 3.8300
Position 3 4 2 1
The Holm and Bonferroniâ€“Dunn tests rejected the null hypothesis for the QDA classiï¬er (Table 4).
Table 4. Test Holm.
Test p-Value a Comment
2â€“4 0.0002 0.0085 Reject Ho
2â€“3 0.0003 0.0102 Reject Ho
1â€“2 0.0015 0.0127 Reject Ho
1â€“4 0.4551 0.0170 Fail to Reject Ho
1â€“3 0.4988 No comparison made Ho is accepted
5.4. F-score
The results given by F-score are shown in Table 5. The Friedman test rejected the null hypothesis
(p-value = 0.000938 0.05). The post hoc test showed that there is a signiï¬cant difference between
ANN and QDA classiï¬ers. The Holm test provided the same results.
Table 5. F-score.
Level DTC QDA WKNN ANN
1 0.8457 0.6306 0.8940 0.9231
2 0.7765 0.4537 0.8438 0.8682
3 0.7843 0.2964 0.8302 0.8521
4 0.9200 0.8109 0.9557 0.9282
5 0.9649 0.7584 0.9884 0.9958
6 0.8941 0.7016 0.9465 0.9223
Fm
10.8639 0.6225 0.9097 0.9150
FM
10.8642 0.6086 0.9098 0.9150
Ranking 1.8300 1.5000 3.3300 3.3400
Position 3 4 2 1
5.5. Area under Curve (AUC)
The Friedman, Holm, and post hoc tests rejected the QDA classiï¬er (see Table 6). The classiï¬ers
WKNN and ANN showed the best results.
Table 6. Area under Curve ( AUC ).
LEVEL DTC QDA WKNN ANN
1 0.9170 0.8400 0.9480 0.9551
2 0.8760 0.7590 0.9070 0.9169
3 0.9030 0.6810 0.9020 0.9142
4 0.9520 0.8580 0.9680 0.9494
5 0.9890 0.8100 0.9890 0.9965
6 0.9510 0.9030 0.9760 0.9630
Ranking 2.4200 1.0000 3.0800 3.5000
Position 3 4 2 1
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 13 of 16
5.6. Discussion
The selection process is based on trial and error, and technical AIC for ANN. The optimal
architecture of ANN is 15 input neurons, 15 hidden layer neurons, and 6 output neurons (number
of levels).
ANN is the most accurate classiï¬er with 91.50% success in real positives, where WKNN presents
90.97%. WKKN provides higher accuracy in 4 and 5 scenarios. ANN presents more sensitivity (91.50%).
F-score shows the best harmonic average of the precision and recall (91.50% for ANN and
90.98 for WKNN).
The AUC results are more than 0.91 for every level and ANN/WKNN.
QDA classiï¬er was rejected. The Friedman, post hoc, Bonferroniâ€“Dunn and Holm tests showed
the existence of signiï¬cant differences. In all cases, except for the QDA classiï¬er, they indicated
an accuracy rate of more than an 85% average, and 90% for the best classiï¬er.
6. Conclusions
The main novelty presented in this paper has been to apply an approach for detecting and
diagnosing the delamination in Wind Turbine Blades (WTB) to guided waves. The signals were
experimentally obtained in a real WTB. The signal is ï¬ltered by wavelet transform with Daubechies
family. The signal is studied by normalized and non-normalized signal tests, to avoid the effects of
environmental and operational variations.
Feature extraction is done by the AR Yuleâ€“Walker model, and Feature Selection (FS) by Akaikeâ€™s
information criterion.
The FS is done by the autoregressive model, where the selection process is based on trial and
error, speciï¬cally for artiï¬cial neural network, where several input conï¬gurations and neuron nodes in
the hidden layer have been tested.
Machine learning and artiï¬cial neuronal networks are used for pattern recognition. Six scenarios
of delamination were considered. The approach detected and classified all the scenarios. The classifiers
used to identify the scenarios are: quadratic discriminant analysis, k-nearest neighbors, and decision trees.
The confusion matrix is used to evaluate the classification, especially the receiver operating characteristic
analysis by recall, specificity , precision and F-score . The conventional methods to establish the average
performance in all categories were macro and micro average. The recommendations by DemÅ¡ar,
and Garcia and Herrera have been used to compare the different classiï¬ers and analyze their best
performance. Firstly, the Friedman test has been used to conï¬rm the null hypothesis that all classiï¬ers
achieve the same average. The Bonferroniâ€“Dunn test has been applied to determine signiï¬cant
differences between the top-ranked classiï¬er and the next one. The Holm test was applied to contrast
the results. In this paper, the approach shows a high level of accuracy for the scenarios considered at
room temperature, according to the results of the tests.
The performance of diagnostic system testing for multi-level detection of delamination in ANN
and WKNN classiï¬ers indicate a high level of accuracy, ANN being the best classiï¬er.
Acknowledgments: The work reported herewith has been ï¬nancially supported by the Spanish Ministerio de
Econom Ã­a y Competitividad, under Research Grants DPI2015-67264-P .
Author Contributions: The work presented here was carried out through the cooperation of all authors. A.A.J.,
C.Q.G.M. and F.P .G.M. conducted the research and wrote the paper. They edited the manuscript including the
literature review. All authors read and approved the manuscript.
Conï¬‚icts of Interest: The authors declare no conï¬‚ict of interest.
References
1. GarcÃ­a MÃ¡rquez, F.P .; Pinar P Ã©rez, J.M.; Pliego Marug Ã¡n, A.; Papaelias, M. Identiï¬cation of critical components
of wind turbines using FTA over the time. Renew. Energy 2016 ,87, 869â€“883. [CrossRef]
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 14 of 16
2. Pliego Marug Ã¡n, A.; Garc Ã­a MÃ¡rquez, F.P .; Pinar P Ã©rez, J.M. Optimal maintenance management of offshore
wind farms. Energies 2016 ,9, 46. [CrossRef]
3. GÃ³mez MuÃ±oz, C.Q.; Garc Ã­a MÃ¡rquez, F.P .; Tom Ã¡s, J.M.S. Ice detection using thermal infrared radiometry on
wind turbine blades. Measurement 2016 ,93, 157â€“163. [CrossRef]
4. Pinar P Ã©rez, J.M.; Garc Ã­a MÃ¡rquez, F.P .; Hern Ã¡ndez, D.R. Economic viability analysis for icing blades detection
in wind turbines. J. Clean. Prod. 2016 ,135, 1150â€“1160. [CrossRef]
5. Pliego Marug Ã¡n, A.; Garc Ã­a MÃ¡rquez, F.P .; Lev, B. Optimal decision-making via binary decision diagrams for
investments under a risky environment. Int. J. Prod. Res. 2017 , 1â€“16. [CrossRef]
6. PÃ©rez, M.A.; Gil, L.; Oller, S. Impact damage identiï¬cation in composite laminates using vibration testing.
Compos. Struct. 2014 ,108, 267â€“276. [CrossRef]
7. Pascoe, J.; Alderliesten, R.; Benedictus, R. Methods for the prediction of fatigue delamination growth in
composites and adhesive bondsâ€”A critical review. Eng. Fract. Mech. 2013 ,112, 72â€“96. [CrossRef]
8. Sohn, H.; Park, G.; Wait, J.R.; Limback, N.P .; Farrar, C.R. Wavelet-based active sensing for delamination
detection in composite structures. Smart Mater. Struct. 2003 ,13, 153. [CrossRef]
9. McGugan, M.; Pereira, G.; SÃ¸rensen, B.F.; Toftegaard, H.; Branner, K. Damage tolerance and structural
monitoring for wind turbine blades. Philos. Trans. R. Soc. A 2015 ,373, 20140077. [CrossRef] [PubMed]
10. GarcÃ­a MÃ¡rquez, F.P .; Pliego Marug Ã¡n, A.; Pinar P Ã©rez, J.M.; Hillmansen, S.; Papaelias, M. Optimal dynamic
analysis of electrical/electronic components in wind turbines. Energies 2017 ,10, 1111. [CrossRef]
11. GarcÃ­a MÃ¡rquez, F.P .; MuÃ±oz, J.M.C. A pattern recognition and data analysis method for maintenance
management. Int. J. Syst. Sci. 2012 ,43, 1014â€“1028. [CrossRef]
12. GarcÃ­a MÃ¡rquez, F.P . A new method for maintenance management employing principal component analysis.
Struct. Durab. Health Monit. 2010 ,6, 89â€“99.
13. Sohn, H.; Farrar, C.R.; Hunter, N.F.; Worden, K. Structural health monitoring using statistical pattern
recognition techniques. J. Dyn. Syst. Meas. Control 2001 ,123, 706â€“711. [CrossRef]
14. Mellit, A.; Kalogirou, S.A. Artiï¬cial intelligence techniques for photovoltaic applications: A review.
Prog. Energy Combust. Sci. 2008 ,34, 574â€“632. [CrossRef]
15. Ata, R. Artiï¬cial neural networks applications in wind energy systems: A review. Renew. Sustain. Energy Rev.
2015 ,49, 534â€“562. [CrossRef]
16. Bork, U.; Challis, R. Artiï¬cial neural networks applied to lamb wave testing of t-form adhered joints.
In Proceedings of the Conference on the Inspection of Structural Composites, London, UK, 9â€“10 June 1994.
17. Bork, U.; Challis, R. Non-destructive evaluation of the adhesive ï¬llet size in a t-peel joint using ultrasonic
lamb waves and a linear network for data discrimination. Meas. Sci. Technol. 1995 ,6, 72. [CrossRef]
18. Yam, L.; Yan, Y.; Jiang, J. Vibration-based damage detection for composite structures using wavelet transform
and neural network identiï¬cation. Compos. Struct. 2003 ,60, 403â€“412. [CrossRef]
19. Su, Z.; Ye, L.; Lu, Y. Guided lamb waves for identiï¬cation of damage in composite structures: A review.
J. Sound Vib. 2006 ,295, 753â€“780. [CrossRef]
20. Gomez Munoz, C.; De la Hermosa Gonzalez-Carrato, R.; Trapero Arenas, J.; Garcia Marquez, F. A novel
approach to fault detection and diagnosis on wind turbines. Glob. NEST J. 2014 ,16, 1029â€“1037.
21. GÃ³mez MuÃ±oz, C.Q.; Garc Ã­a MÃ¡rquez, F.P . A new fault location approach for acoustic emission techniques in
wind turbines. Energies 2016 ,9, 40. [CrossRef]
22. Rose, J.L. Recent advances in guided wave NDE. In Proceedings of the Ultrasonics Symposium, San Francisco,
CA, USA, 16â€“18 October 1995; pp. 761â€“770.
23. Rose, J.L. A baseline and vision of ultrasonic guided wave inspection potential. J. Press. Vessel Technol. 2002 ,
124, 273â€“282. [CrossRef]
24. De da Gonz Ã¡lez-Carrato, R.R.; M Ã¡rquez, G.; Pedro, F.; Papaelias, M. Vibration-based tools for the optimisation
of large-scale industrial wind turbine devices. Int. J. Cond. Monit. 2016 ,6, 33â€“37. [CrossRef]
25. Worden, K.; Manson, G. The application of machine learning to structural health monitoring. Philos. Trans.
R. Soc. Lond. A Math. Phys. Eng. Sci. 2007 ,365, 515â€“537. [CrossRef] [PubMed]
26. Jain, B.; Jain, S.; Nema, R. Investigations on power quality disturbances using discrete wavelet transform.
Int. J. Electr. Electron Comput. Eng. 2013 ,2, 47â€“53.
27. Farrar, C.R.; Sohn, H.; Worden, K. Data Normalization: A Key for Structural Health Monitoring ; Los Alamos
National Lab.: Los Alamos, NM, USA, 2001.
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 15 of 16
28. GÃ³mez MuÃ±oz, C.Q.; Jim Ã©nez, A.A.; Garc Ã­a MÃ¡rquez, F.P . Wavelet transforms and pattern recognition on
ultrasonic guides waves for frozen surface state diagnosis. Renew. Energy 2017 . [CrossRef]
29. Gui, G.; Pan, H.; Lin, Z.; Li, Y.; Yuan, Z. Data-driven support vector machine with optimization techniques
for structural health monitoring and damage detection. KSCE J. Civ. Eng. 2017 ,21, 523â€“534. [CrossRef]
30. Sharma, A.; Amarnath, M.; Kankar, P . Feature extraction and fault severity classiï¬cation in ball bearings.
J. Vib. Control 2016 ,22, 176â€“192. [CrossRef]
31. Manupati, V .; Anand, R.; Thakkar, J.; Benyoucef, L.; Garsia, F.P .; Tiwari, M. Adaptive production control
system for a ï¬‚exible manufacturing cell using support vector machine-based approach. Int. J. Adv.
Manuf. Technol. 2013 , 1â€“13. [CrossRef]
32. Sohn, H.; Farrar, C.R. Damage diagnosis using time series analysis of vibration signals. Smart Mater. Struct.
2001 ,10, 446. [CrossRef]
33. Lu, Y.; Gao, F. A novel time-domain auto-regressive model for structural damage diagnosis. J. Sound Vib.
2005 ,283, 1031â€“1049. [CrossRef]
34. Yao, R.; Pakzad, S.N. Autoregressive statistical pattern recognition algorithms for damage detection in civil
structures. Mech. Syst. Signal Process. 2012 ,31, 355â€“368. [CrossRef]
35. Nardi, D.; Lampani, L.; Pasquali, M.; Gaudenzi, P . Detection of low-velocity impact-induced delaminations
in composite laminates using auto-regressive models. Compos. Struct. 2016 ,151, 108â€“113. [CrossRef]
36. Figueiredo, E.; Figueiras, J.; Park, G.; Farrar, C.R.; Worden, K. Inï¬‚uence of the autoregressive model order on
damage detection. Comput. Aided Civ. Infrastruct. Eng. 2011 ,26, 225â€“238. [CrossRef]
37. Akaike, H. A new look at the statistical model identiï¬cation. IEEE Trans. Autom. Control 1974 ,19, 716â€“723.
[CrossRef]
38. Akaike, H. Fitting autoregressive models for prediction. Ann. Inst. Stat. Math. 1969 ,21, 243â€“247. [CrossRef]
39. Box, G.E.; Jenkins, G.M.; Reinsel, G.C.; Ljung, G.M. Time Series Analysis: Forecasting and Control ; John
Wiley & Sons: New York, NY, USA, 2015.
40. Willmott, C.J.; Matsuura, K. Advantages of the mean absolute error (MAE) over the root mean square error
(RMSE) in assessing average model performance. Clim. Res. 2005 ,30, 79â€“82. [CrossRef]
41. Konstantinides, K. Threshold bounds in SVD and a new iterative algorithm for order selection in ar models.
IEEE Trans. Signal Process. 1991 ,39, 1218â€“1221. [CrossRef]
42. Mika, S.; Ratsch, G.; Weston, J.; Scholkopf, B.; Mullers, K.-R. Fisher discriminant analysis with kernels.
In Proceedings of the Neural Networks for Signal Processing IX 1999, 1999 IEEE Signal Processing Society
Workshop, Madison, WI, USA, 25 August 1999; pp. 41â€“48.
43. Cunningham, P .; Delany, S.J. K-nearest neighbour classiï¬ers. Mult. Classif. Syst. 2007 ,34, 1â€“17.
44. Quinlan, J.R. Induction of decision trees. Mach. Learn. 1986 ,1, 81â€“106. [CrossRef]
45. GarcÃ­a MÃ¡rquez, F.P .; Garc Ã­a-Pardo, I.P . Principal component analysis applied to ï¬ltered signals for
maintenance management. Qual. Reliab. Eng. Int. 2010 ,26, 523â€“527. [CrossRef]
46. De la Hermosa Gonz Ã¡lez, R.R.; Garc Ã­a MÃ¡rquez, F.P .; Dimlaye, V . Maintenance management of wind turbines
structures via mfcs and wavelet transforms. Renew. Sustain. Energy Rev. 2015 ,48, 472â€“482. [CrossRef]
47. De la Hermosa Gonz Ã¡lez, R.R.; Garc Ã­a MÃ¡rquez, F.P .; Dimlaye, V .; Ruiz-Hern Ã¡ndez, D. Pattern recognition by
wavelet transforms using macro ï¬bre composites transducers. Mech. Syst. Signal Process. 2014 ,48, 339â€“350.
[CrossRef]
48. De Lautour, O.R.; Omenzetter, P . Damage classiï¬cation and estimation in experimental structures using time
series analysis and pattern recognition. Mech. Syst. Signal Process. 2010 ,24, 1556â€“1569. [CrossRef]
49. Daqrouq, K.; Abu-Isbeih, I.N.; Daoud, O.; Khalaf, E. An investigation of speech enhancement using wavelet
ï¬ltering method. Int. J. Speech Technol. 2010 ,13, 101â€“115. [CrossRef]
50. Alfaouri, M.; Daqrouq, K. ECG signal denoising by wavelet transform thresholding. Am. J. Appl. Sci. 2008 ,5,
276â€“281. [CrossRef]
51. BirgÃ©, L.; Massart, P . From model selection to adaptive estimation. In Festschrift for Lucien Le Cam ; Springer:
Berlin, Germany, 1997; pp. 55â€“87.
52. Ramirez, I.S.; G Ã³mez MuÃ±oz, C.Q.; Marquez, F.P .G. A condition monitoring system for blades of wind
turbine maintenance management. In Proceedings of the Tenth International Conference on Management
Science and Engineering Management, Baku, Azerbaijan, 30 Augustâ€“2 September 2016; pp. 3â€“11.
53. Castiglioni, P . Levinsonâ€“durbin algorithm. In Encyclopedia of Biostatistics ; John Wiley and Sons Ltd.: London,
UK, 2005.
------------------------------End of the page -----------------------------------
Energies 2018 ,11, 13 16 of 16
54. Breiman, L.; Friedman, J.; Olshen, R.; Stone, C. Classiï¬cation and Regression Trees ; Wadsworth International
Group: Belmont, CA, USA, 1984.
55. Wu, W.; Mallet, Y.; Walczak, B.; Penninckx, W.; Massart, D.; Heuerding, S.; Erni, F. Comparison of regularized
discriminant analysis linear discriminant analysis and quadratic discriminant analysis applied to NIR data.
Anal. Chim. Acta 1996 ,329, 257â€“265. [CrossRef]
56. Friedman, J.H. Regularized discriminant analysis. J. Am. Stat. Assoc. 1989 ,84, 165â€“175. [CrossRef]
57. Cover, T.; Hart, P . Nearest neighbor pattern classiï¬cation. IEEE Trans. Inf. Theory 1967 ,13, 21â€“27. [CrossRef]
58. Kotsiantis, S.B.; Zaharakis, I.; Pintelas, P . Supervised machine learning: A review of classiï¬cation techniques.
Inform. Int. J. Comput. Inform. 2007 ,31, 249â€“268.
59. Zuo, W.; Zhang, D.; Wang, K. On kernel difference-weighted k-nearest neighbor classiï¬cation.
Pattern Anal. Appl. 2008 ,11, 247â€“257. [CrossRef]
60. MÃ¸ller, M.F. A scaled conjugate gradient algorithm for fast supervised learning. Neural Netw. 1993 ,6,
525â€“533. [CrossRef]
61. Kroese, D.P .; Rubinstein, R.Y.; Cohen, I.; Porotsky, S.; Taimre, T. Cross-entropy method. In Encyclopedia of
Operations Research and Management Science ; Springer: Berlin, Germany, 2013; pp. 326â€“333.
62. Prechelt, L. Automatic early stopping using cross validation: Quantifying the criteria. Neural Netw. 1998 ,11,
761â€“767. [CrossRef]
63. Yang, Y. An evaluation of statistical approaches to text categorization. Inf. Retr. 1999 ,1, 69â€“90. [CrossRef]
64. Bradley, A.P . The use of the area under the ROC curve in the evaluation of machine learning algorithms.
Pattern Recognit. 1997 ,30, 1145â€“1159. [CrossRef]
65. Hanley, J.A.; McNeil, B.J. The meaning and use of the area under a receiver operating characteristic (ROC)
curve. Radiology 1982 ,143, 29â€“36. [CrossRef] [PubMed]
66. GÃ³mez, C.Q.; Villegas, M.A.; Garc Ã­a, F.P .; Pedregal, D.J. Big data and web intelligence for condition
monitoring: A case study on wind turbines. In Handbook of Research on Trends and Future Directions in
Big Data and Web Intelligence ; IGI Global: Hershey, PA, USA, 2015; pp. 149â€“163.
67. GÃ³mez MuÃ±oz, C.Q.; Arcos Jimenez, A.; Garc Ã­a Marquez, F.P .; Kogia, M.; Cheng, L.; Mohimi, A.; Papaelias, M.
Cracks and welds detection approach in solar receiver tubes employing electromagnetic acoustic transducers.
Struct. Heal. Monit. 2017 , 1475921717734501. [CrossRef]
68. Gomez Munoz, C.Q.; Garcia Marquez, F.P .; Jimenez, A.A.; Cheng, L.; Kogia, M.; Mohimi, A.; Papaelias, M.
A heuristic method for detecting and locating faults employing electromagnetic acoustic transducers.
Eksploatacja I Niezawodnoscâ€”Maint. Reliab. 2017 ,19, 493â€“500. [CrossRef]
69. GÃ³mez MuÃ±oz, C.Q.; Garc Ã­a Marquez, F.P .; Lev, B.; Arcos, A. New pipe notch detection and location method
for short distances employing ultrasonic guided waves. Acta Acust. United Acust. 2017 ,103, 772â€“781.
[CrossRef]
Â©2017 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).
------------------------------End of the page -----------------------------------
