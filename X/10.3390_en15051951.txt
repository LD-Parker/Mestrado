/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001
/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046Citation: Xiao, X.; Liu, J.; Liu, D.;
Tang, Y.; Zhang, F. Condition
Monitoring of Wind Turbine Main
Bearing Based on Multivariate Time
Series Forecasting. Energies 2022 ,15,
1951. https://doi.org/10.3390/
en15051951
Academic Editor: Davide Astolï¬
Received: 7 February 2022
Accepted: 3 March 2022
Published: 7 March 2022
Publisherâ€™s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afï¬l-
iations.
Copyright: Â© 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed under the terms and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
energies
Article
Condition Monitoring of Wind T urbine Main Bearing Based on
Multivariate Time Series Forecasting
Xiaocong Xiao1,2, Jianxun Liu2,*, Deshun Liu1, Yufei Tang3
and Fan Zhang1
1School of Mechanical Engineering, Hunan University of Science and Technology, Xiangtan 411201, China;
xiaoxc@hnust.edu.cn (X.X.); liudeshun@hnust.edu.cn (D.L.); zhangfan@hnust.edu.cn (F.Z.)
2School of Computer Science and Engineering, Hunan University of Science and Technology,
Xiangtan 411201, China
3Department of Electrical Engineering and Computer Science, Florida Atlantic University,
Boca Raton, FL 33431, USA; tangy@fau.edu
*Correspondence: liujx@hnust.edu.cn
Abstract: Condition monitoring and overheating warnings of the main bearing of large-scale wind
turbines (WT) plays an important role in enhancing their dependability and reducing operating
and maintenance (O&M) costs. The temperature parameter of the main bearing is the key indicator
to characterize the normal or abnormal operating condition. Therefore, forecasting the trend of
temperature change is critical for overheating warnings. To achieve forecasting with high accuracy,
this paper proposes a novel model for the WT main bearing, named stacked long-short-term memory
with multi-layer perceptron (SLSTM-MLP) by utilizing supervisory control and data acquisition
(SCADA) data. The model is mainly composed of multiple LSTM cells and a multi-layer perceptron
regression layer. By combining condition parameters into a characteristic matrix, SLSTM can mine
nonlinear, non-stationary dynamic feature relationships between temperature and its related variables.
To evaluate the performance of the SLSTM-MLP model, experimental analysis was carried out from
three aspects: different sample capacity sizes, different sampling time segments, and different
sampling frequencies. Furthermore, the modelâ€™s capability of online fault detection was also carried
out by simulation. The results of comparative studies and online fault simulation tests show that the
proposed SLSTM-MLP has better performance for temperature forecasting of the main bearing of
large-scale WTs.
Keywords: wind turbine; SCADA; stacked LSTM; main bearing; temperature forecasting
1. Introduction
Wind energy is the most widely used clean and low-carbon renewable energy with
the fastest development. More and more countries have attached great importance to wind
turbines, and many wind farms and larger capacity large-scale wind turbines are coming
into use. However, because of the harsh natural working environment (especially for
offshore large-scale wind turbines) complex and changeable operating condition of large-
scale wind turbines (WT), some core components, such as main bearings, frequently fail,
resulting in prolonged downtime and increased O&M costs of wind farms [ 1]. Therefore,
in order to enhance component reliability, avoid faults, and reduce O&M cost, it is of vital
practical signiï¬cance to study the operating condition monitoring methods of the core
components of large-scale WTs [2].
The main bearing of large-scale WTs, as an important physical component of the
WT transmission chain, connects the hub and the generator or the gearbox. According
to the European Academy of Wind Energy (EAWE) [ 3], WT main bearings have been
identiï¬ed as one of the critical components in terms of increasing WT reliability and
availability for the transmission system in the wind industry. The WT main bearing is a
large component, and its internal structure is complicated. Furthermore, the operating
Energies 2022 ,15, 1951. https://doi.org/10.3390/en15051951 https://www.mdpi.com/journal/energies
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 2 of 23
environment of the WT main bearing is very harsh and complex, and the alternating load
in the axial and radial directions and strong impact make it prone to failure. According
to literature reports, the failure rate of the WT main bearings reaches 15% and 30% [ 4].
A lot of research has been carried out on monitoring the operating conditions of the WT
main bearings [ 5]. These methods are mainly divided into two categories, i.e., vibration-
based analysis methods and temperature-based analysis methods. (1) Vibration-based
analysis methods include the following. Natili et al. [ 6] used the vibration data of the
turbine condition monitoring (TCM) to realize multi-scale condition monitoring and fault
detection of the WT main bearings. Artigao et al. [ 7] used the fast Fourier transform
method to analyze the frequency domain of the bearing vibration spectrum to identify
bearing faults on the drive chain of wind turbines under different loads. Siegel et al. [ 8]
used fast Fourier transform and envelope analysis to analyze the frequency domain of
bearing vibration spectrum to identify bearing faults on the drive chain of wind turbines.
Peeters et al. [9] proposed a more intelligent automated cepstrum editing procedure (ACEP)
for peak automatic selection based on vibration signal parameters to detect bearing faults.
Lu et al. [ 10] proposed an improved auxiliary classiï¬er generative adversarial network
(ACGAN) model with data enhancement function for vibration signal parameters, which
balanced vibration data of WT main bearing faults and improved the accuracy of fault
diagnosis of the WT main bearing. The above works mainly focus on the analysis and
modeling of high-frequency vibration data. However, in the actual wind ï¬eld SCADA
system, the collected data are usually low-frequency vibration data, such as 1 s, 1 min, 5 min,
10 min, etc. These methods may not be suitable. In addition, the relationship between ï¬eld
SCADA data parameters is complex, and the existing shallow machine learning methods
have limited ability to extract features. Although the deep learning GAN model is adopted
in the literature [ 10], its data also comes from the laboratory rather than the ï¬eld. Therefore,
the analysis and modeling of low-frequency vibration data and multi-parameters are less
accurate. (2) Temperature-based analysis methods include the following. Zhang [ 11]
utilized SCADA data to build a neural network model to forecast the temperature of the
WT main bearing to diagnose the main bearing failure. Zhao et al. [ 12] used SCADA data
condition parameters, such as the temperature of the WT main bearing, to build a restricted
Boltzmann machine-based deep learning model, which can reconstruct the overall WT
main bearing conditions to predict the faults of the WT main bearing. Wang et al. [ 13],
based on SCADA data, constructed a deep belief network based on a restricted Boltzmann
machine (RBM) to predict the temperature of the WT main bearing and to monitor and
detect anomalies of the WT main bearing. Zhao et al. [ 14] proposed an improved deep
belief network based on RBM to reconstruct the normal condition of the WT main bearing
and used the reconstruction error to monitor and detect whether the WT main bearing was
in an abnormal condition. Yucesan et al. [ 15] established a deep neural network model
based on the fusion of physical information and data-driven parameters such as the main
bearing temperature to detect the fatigue and oil degradation of the main bearing. The
above studies have examined a variety of methods, from simple neural network structure to
complex deep belief models. These studies carried out main bearing condition monitoring,
fatigue detection, and oil degradation by reconstructing a vector or predicting a single
value. However, some methods do not consider wind speed, parameter selection, and
model structure determination in detail, and some temperature prediction models have
low accuracy and large error.
In summary, condition monitoring and fault detection of the main bearing of large-
scale WTs-based on the WT SCADA system has become a research hotspot [ 16,17]. The
research results of the vibration-based analysis method and temperature-based analysis
method described above have deepened the understanding of operating state monitor-
ing, detection, and fault detection of the main bearing of large-scale WTs based on the
application of these methods, such as neural network models, support vector machines,
deep belief networks, and adversarial learning. However, some of the models above are
shallow machine learning models, which have limited ability to comprehensively extract
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 3 of 23
data features from the SCADA dataset. In addition, parameter selection and structure
determination for models are not discussed in detail, which limits the application and
promotion of models to a certain extent. Some research needs to be further expanded.
In this paper, we take the main bearing of large-scale direct-driven WTs as the research
object to carry out operating condition monitoring and abnormal detection research based
on SCADA data from a real wind farm. It is well known that the temperature of the
main bearing of large-scale direct-driven WTs is an important parameter to monitor to
determine whether the WT main bearing is abnormal. In the long-term monitoring process,
temperature time series does not have obvious details of high-frequency mutation, but has
certain random characteristics, obvious temporal characteristics, and short-term correlation.
The model based on long-short term memory (LSTM) is very suitable for dealing with
this situation. LSTM network models have great processing power for solving long-term
or short-term time series dependency problems and can be used to automatically learn
the temporal dependence structures of complex relationships between the temperature
change of the main bearing itself and other related variables. In addition, the LSTM model,
its variants, and combination models have been successfully applied in forecasting and
classiï¬cation [ 18â€“20]. The motivation for this manuscript is to overcome two issues in
the existing research: (1) The mining of time series feature information is insufï¬cient in
the existing literature research, and temporal characteristics of multivariable parameters
are not considered in condition monitoring and anomaly detection. (2) Model structure
determination and hyper-parameter selection are not discussed in-depth, and the model
has poor reproducibility, which leads to application limitations of the model. Therefore,
in this study, we propose a novel deep learning model for temperature forecasting of the
main bearing of large-scale direct-driven WTs by using a SCADA dataset from a real wind
farm. Taking a single LSTM cell as the basic component, we stack LSTM cells to build a
deep model with multiple perceptual regression layers, named stacked long-short term
memory with multi-layer perceptron (SLSTM-MLP), to provide robust operating condition
monitoring and anomaly detection through multivariate time series datasets. The main
contributions of this paper are summarized as follows:
(1) A novel deep learning network framework SLSTM-MLP is proposed for forecasting
the temperature of the main bearing of large-scale direct-driven WTs to mine time-
series information of multiple parameter variables and coupling information between
parameter variables. In the model, we stack multiple LSTM cells to train for achieving
high forecasting accuracy in order to obtain the nonlinear and non-stationary dynamic
features relationship between temperature itself and its related parameter variables.
(2) We conduct extensive experiments utilizing SCADA data to evaluate the performance
for the proposed model from different sample capacity sizes, different sampling time
segments, and different sampling frequencies. The experimental results show that the
SLSTM-MLP model is superior to the other approaches.
(3) We put forward a framework for online condition monitoring and abnormal detec-
tion of WT main bearings and then simulate two different degree faults by adding
two cumulative temperature offsets to two associated variables. The simulation re-
sults show that the proposed SLSTM-MLP model is effective in the forecasting and
monitoring process.
The remainder of this paper is organized as follows. Section 2 presents the proposed
SLSTM-MLP model, including the problem deï¬nition, the framework, and training al-
gorithm. Section 3 describes the experiment setup, data cleansing and resampling, and
model structure determination. Performance comparison with other models is presented
in Section 4. The framework for online operating condition monitoring and abnormal
detection and fault simulation are presented in Section 5. Finally, conclusions are drawn in
Section 6.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 4 of 23
2. The Proposed Method of SLSTM-MLP
In this section, we ï¬rst give the deï¬nition of the multivariable time series forecasting
problem of the WT main bearing temperature. Then, we introduce some basic theoreti-
cal knowledge of LSTM. Then, we put forward a novel deep learning recurrent neural
network framework for large-scale WT main bearing temperature forecasting through
a multivariable time series modeling method. At last, we introduce the corresponding
training algorithm for the proposed SLSTM-MLP model.
2.1. Problem Deï¬nition
Temperature time series data of WT main bearing has strong autocorrelation with its
historical values and also has a strong correlation with the other related external variables,
such as wind speed, output power, rotor speed, ambient temperature, generator stator
temperature. Therefore, the temperature time series forecasting problem of WT main
bearing is a multivariable time series (MTS) forecasting problem with temperature itself and
several other related variables. It is still challenging to effectively model such correlations
and then enable accurate condition monitoring. The multivariable time series forecasting
problem of the main bearing temperature of WT is described as follows:
[yt,yt+1, . . . , yt+k 1]=f(Xt 1,Yt 1) (1)
where Xt 1=fx1,t 1,x1,t 2, . . . , x1,t n;x2,t 1,x2,t 2, . . . , x2,t n; . . . ; xm,t 1,xm,t 2, . . . ,
xm,t ng2Rmn.represents the historical dataset of the conditional parameter related to the
WT main bearing before time interval t, and m is the number of related conditional param-
eter variables; Yt 1=fyt 1,yt 2, . . . , yt ng2Rnrepresents historical data backward from
the current time interval t; n represents the length of the series; [yt,yt+1, . . . , yt+k 1]2Rkis
the forecasted temperature of the WT main bearing at the next k time interval; fis a com-
plicated nonlinear mapping function. We label (Xt 1,Yt 1)asDt, and [yt,yt+1, . . . , yt+k 1]
asOtin subsequent analysis.
2.2. LSTM Theoretical Basis
LSTM, a special recursive neural network model, was proposed by Hochreiter and
Schmidhuber [ 21] and is well suited to capture nonlinear and non-stationary dynamic
features for time series data sequences. It has been widely used in speech recognition,
natural language processing, machine translation, video tagging, and generated image
description [ 22â€“25]. A single LSTM cell consists of a cell state, a forgetting gate, an input
gate, and an output gate. Its internal structure is shown in Figure 1.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  4Â ofÂ 22Â 
Â 
Â inÂ SectionÂ 4.Â TheÂ framework Â forÂ onlineÂ operating Â condition Â monitoring Â andÂ abnormal Â deâ€
tectionÂ andÂ faultÂ simulation Â areÂ presented Â inÂ SectionÂ 5.Â Finally,Â conclusions Â areÂ drawnÂ inÂ 
SectionÂ 6.Â 
2.Â TheÂ Proposed Â MethodÂ ofÂ SLSTMâ€MLPÂ 
InÂ thisÂ section,Â weÂ firstÂ giveÂ theÂ definition Â ofÂ theÂ multivariable Â timeÂ seriesÂ forecasting Â 
problemÂ ofÂ theÂ WTÂ mainÂ bearingÂ temperature. Â Then,Â weÂ introduce Â someÂ basicÂ theoretical Â 
knowledge Â ofÂ LSTM.Â Then,Â weÂ putÂ forwardÂ aÂ novelÂ deepÂ learningÂ recurrent Â neuralÂ netâ€
workÂ framework Â forÂ largeâ€scaleÂ WTÂ mainÂ bearingÂ temperature Â forecasting Â throughÂ aÂ mulâ€
tivariable Â timeÂ seriesÂ modeling Â method.Â AtÂ last,Â weÂ introduce Â theÂ corresponding Â trainingÂ 
algorithm Â forÂ theÂ proposed Â SLSTMâ€MLPÂ model.Â 
2.1.Â ProblemÂ Definition Â 
Temperature Â timeÂ seriesÂ dataÂ ofÂ WTÂ mainÂ bearingÂ hasÂ strongÂ autocorrelation Â withÂ itsÂ 
historical Â valuesÂ andÂ alsoÂ hasÂ aÂ strongÂ correlation Â withÂ theÂ otherÂ relatedÂ externalÂ variables, Â 
suchÂ asÂ windÂ speed,Â outputÂ power,Â rotorÂ speed,Â ambientÂ temperature, Â generator Â statorÂ 
temperature. Â Therefore, Â theÂ temperature Â timeÂ seriesÂ forecasting Â problemÂ ofÂ WTÂ mainÂ bearâ€
ingÂ isÂ aÂ multivariable Â timeÂ seriesÂ (MTS)Â forecasting Â problemÂ withÂ temperature Â itselfÂ andÂ 
severalÂ otherÂ relatedÂ variables. Â ItÂ isÂ stillÂ challenging Â toÂ effectively Â modelÂ suchÂ correlations Â 
andÂ thenÂ enableÂ accurateÂ condition Â monitoring. Â TheÂ multivariable Â timeÂ seriesÂ forecasting Â 
problemÂ ofÂ theÂ mainÂ bearingÂ temperature Â ofÂ WTÂ isÂ described Â asÂ follows:Â 
áˆ¾ğ‘¦à¯§,ğ‘¦à¯§à¬¾à¬µ,â‹¯,ğ‘¦ à¯§à¬¾à¯à¬¿à¬µ áˆ¿àµŒğ‘“áˆºğ‘¿à¯§à¬¿à¬µ,ğ’€à¯§à¬¿à¬µáˆ»Â  (1)
whereÂ ğ‘¿à¯§à¬¿à¬µàµŒáˆ¼ ğ‘¥ à¬µ,à¯§à¬¿à¬µ ,ğ‘¥à¬µ,à¯§à¬¿à¬¶ ,â‹¯,ğ‘¥ à¬µ,à¯§à¬¿à¯¡ ;ğ‘¥à¬¶,à¯§à¬¿à¬µ ,ğ‘¥à¬¶,à¯§à¬¿à¬¶ ,â‹¯,ğ‘¥ à¬¶,à¯§à¬¿à¯¡ ;â‹¯;ğ‘¥ à¯ ,à¯§à¬¿à¬µ ,ğ‘¥à¯ ,à¯§à¬¿à¬¶ ,â‹¯,ğ‘¥ à¯ ,à¯§à¬¿à¯¡ áˆ½âˆˆ
ğ‘…à¯ âˆ—à¯¡Â represents Â theÂ historical Â datasetÂ ofÂ theÂ conditional Â parameter Â relatedÂ toÂ theÂ WTÂ mainÂ 
bearingÂ beforeÂ timeÂ intervalÂ t,Â andÂ mÂ isÂ theÂ numberÂ ofÂ relatedÂ conditional Â parameter Â varâ€
iables;Â ğ’€à¯§à¬¿à¬µàµŒáˆ¼ ğ‘¦ à¯§à¬¿à¬µ,ğ‘¦à¯§à¬¿à¬¶,â‹¯,ğ‘¦ à¯§à¬¿à¯¡áˆ½âˆˆğ‘…à¯¡Â represents Â historical Â dataÂ backward Â fromÂ theÂ curâ€
rentÂ timeÂ intervalÂ t;Â nÂ represents Â theÂ lengthÂ ofÂ theÂ series;Â áˆ¾ğ‘¦à¯§,ğ‘¦à¯§à¬¾à¬µ,â‹¯,ğ‘¦ à¯§à¬¾à¯à¬¿à¬µ áˆ¿âˆˆğ‘…à¯Â isÂ theÂ 
forecasted Â temperature Â ofÂ theÂ WTÂ mainÂ bearingÂ atÂ theÂ nextÂ kÂ timeÂ interval;Â ğ‘“Â isÂ aÂ compliâ€
catedÂ nonlinear Â mapping Â function. Â WeÂ labelÂ áˆºğ‘¿à¯§à¬¿à¬µ,ğ’€à¯§à¬¿à¬µáˆ»Â asÂ ğ‘«à¯§,Â andÂ áˆ¾ğ‘¦à¯§,ğ‘¦à¯§à¬¾à¬µ,â‹¯,ğ‘¦ à¯§à¬¾à¯à¬¿à¬µ áˆ¿Â 
asÂ ğ‘¶à¯§Â inÂ subsequent Â analysis. Â 
2.2.Â LSTMÂ Theoretical Â BasisÂ 
LSTM,Â aÂ specialÂ recursive Â neuralÂ networkÂ model,Â wasÂ proposed Â byÂ Hochreiter Â andÂ 
Schmidhuber Â [21]Â andÂ isÂ wellÂ suitedÂ toÂ captureÂ nonlinear Â andÂ nonâ€stationary Â dynamic Â 
featuresÂ forÂ timeÂ seriesÂ dataÂ sequences. Â ItÂ hasÂ beenÂ widelyÂ usedÂ inÂ speechÂ recognition, Â 
naturalÂ language Â processing, Â machine Â translation, Â videoÂ tagging,Â andÂ generated Â imageÂ 
description Â [22â€“25].Â AÂ singleÂ LSTMÂ cellÂ consistsÂ ofÂ aÂ cellÂ state,Â aÂ forgetting Â gate,Â anÂ inputÂ 
gate,Â andÂ anÂ outputÂ gate.Â ItsÂ internalÂ structure Â isÂ shownÂ inÂ FigureÂ 1.Â 
Â 
FigureÂ 1.Â InternalÂ structure Â diagramÂ ofÂ aÂ singleÂ LSTMÂ cell.Â 
Figure 1. Internal structure diagram of a single LSTM cell.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 5 of 23
As shown in Figure 1, the xtrepresents input data vector. The ht 1andhtrepresent
the hidden state vector of the cell in the previous time step t-1 and at the current time
step, respectively. The Ct 1andCtrepresent the cell state at the previous time step and
current time step, respectively. The ft,it, and Otrepresent the forget, input, and output
gates, respectively; sand tanh represent two kinds of activation functions, namely sigmoid
and tanh. Based on the backpropagation through time (BPTT) algorithm, these parameters
are updated by the following formulas:
ft=s
Wf[ht 1,xt]+bf
(2)
it=s(Wi[ht 1,xt]+bi) (3)
eCt=tanh(Wc[ht 1,xt]+bc) (4)
Ct=ftCt 1+iteCt (5)
Ot=s(Wo[ht 1,xt]+bo) (6)
ht=Ottanh(Ct) (7)
where Wf,Wi,Wc,Wo,bf,bi,bc, and borepresent the corresponding weight coefï¬cient
matrixes and bias terms, respectively.
2.3. The Framework of the Proposed Model
To further mine the temporal correlation from the SCADA data related to WT main
bearings and achieve forecasting with high accuracy, we developed the framework of the
SLSTM-MLP model for WT main bearing temperature forecasting with a multivariable
time series modeling method. The framework consisted of four parts: input layer, multi-
hidden layers, fully connected layer, and regression output layer. The framework of the
SLSTM-MLP model is shown in Figure 2.
The input layer is an input matrix Xwith multivariate time series, which is deï¬ned
as a tensor of shape (S, M) format, where S represents the number of time steps, and M
represents the number of variables. In our experiment, M was set to 8, and S needs to
be veriï¬ed by incrementing one by one starting from integer 1. The multi-hidden layer
includes multiple LSTM units. These LSTM units take the output of the ith hidden layer as
the input of the (i + 1) hidden layer and are stacked to form a multi-layer network to learn
the nonlinear and non-stationary feature representations of the original data. Each hidden
layer extracts different levels of feature representation at different time steps until ï¬nally,
the last layer provides the output. The beneï¬t of the stacked LSTM architecture is that the
additional LSTM hidden layer can extract the learned data characteristic representation
of the previously hidden layer to form a higher level of abstraction feature extraction.
Practice has shown that the depth of the network is as important as the number of cells. The
fully connected layer accepts the output vector of the last LSTM model, whose dimension
is equal to the number of neurons in the hidden layer, and it completes the dimension
transformation. The output layer can be a classiï¬er or a regressor, and in this article, we
use a regressor for the WT main bearing temperature forecasting.
2.4. Training Algorithm for the SLSTM-MLP Model
Now, we present the corresponding training algorithm for the SLSTM-MLP model
according to the framework in Figure 2. The major steps of the SLSTM-MLP model
algorithm can be described as: (a) collecting the normal historical SCADA data from 2 M
direct-driven WT; (b) executing the data cleansing and resampling; (c) selecting parameter
variables; (d) constructing training and testing dataset; (e) building the SLSTM-MLP model;
and (f) training and validating the SLSTM-MLP model. The algorithm pseudocode is
outlined in Algorithm 1.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 6 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  5Â ofÂ 22Â 
Â 
Â AsÂ shownÂ inÂ FigureÂ 1,Â theÂ ğ’™à¯§ represents Â inputÂ dataÂ vector.Â TheÂ ğ’‰à¯§à¬¿à¬µÂ andÂ ğ’‰à¯§Â repreâ€
sentÂ theÂ hiddenÂ stateÂ vectorÂ ofÂ theÂ cellÂ inÂ theÂ previous Â timeÂ stepÂ tâ€1Â andÂ atÂ theÂ currentÂ timeÂ 
step,Â respectively. Â TheÂ ğ‘ªà¯§à¬¿à¬µÂ andÂ ğ‘ªà¯§Â represent Â theÂ cellÂ stateÂ atÂ theÂ previous Â timeÂ stepÂ andÂ 
currentÂ timeÂ step,Â respectively. Â TheÂ ğ’‡à¯§,Â ğ’Šà¯§,Â andÂ ğ‘¶à¯§Â represent Â theÂ forget,Â input,Â andÂ outputÂ 
gates,Â respectively; Â ğœÂ andÂ ğ‘¡ğ‘ğ‘›â„Â represent Â twoÂ kindsÂ ofÂ activation Â functions, Â namelyÂ sigâ€
moidÂ andÂ tanh.Â BasedÂ onÂ theÂ backpropagation Â throughÂ timeÂ (BPTT)Â algorithm, Â theseÂ paâ€
rameters Â areÂ updatedÂ byÂ theÂ following Â formulas: Â 
ğ’‡à¯§àµŒğœ áˆº ğ‘¾ à¯™âˆ—áˆ¾ ğ’‰ à¯§à¬¿à¬µ,ğ’™à¯§áˆ¿àµ…ğ’ƒ à¯™áˆ»Â  (2)
ğ’Šà¯§àµŒğœ áˆº ğ‘¾ à¯œâˆ—áˆ¾ ğ’‰ à¯§à¬¿à¬µ,ğ’™à¯§áˆ¿àµ…ğ’ƒ à¯œáˆ»Â  (3)
ğ‘ªà·©à¯§àµŒğ‘¡ ğ‘ ğ‘› â„ áˆº ğ‘¾ à¯–âˆ—áˆ¾ ğ’‰ à¯§à¬¿à¬µ,ğ’™à¯§áˆ¿àµ…ğ’ƒ à¯–áˆ»Â  (4)
ğ‘ªà¯§àµŒğ’‡à¯§âˆ—ğ‘ª à¯§à¬¿à¬µàµ…ğ’Š à¯§âˆ—ğ‘ªà·©à¯§Â  (5)
ğ‘¶à¯§àµŒğœ áˆº ğ‘¾ à¯¢âˆ—áˆ¾ ğ’‰ à¯§à¬¿à¬µ,ğ’™à¯§áˆ¿àµ…ğ’ƒ à¯¢áˆ»Â  (6)
ğ’‰à¯§àµŒğ‘¶ à¯§âˆ—ğ‘¡ ğ‘ ğ‘› â„ áˆº ğ‘ª à¯§áˆ»Â  (7)
whereÂ ğ‘¾à¯™,Â ğ‘¾à¯œ,Â ğ‘¾à¯–,Â ğ‘¾à¯¢,Â ğ’ƒà¯™,Â ğ’ƒà¯œ,Â ğ’ƒà¯–,Â andÂ ğ’ƒà¯¢Â represent Â theÂ corresponding Â weightÂ coeffiâ€
cientÂ matrixes Â andÂ biasÂ terms,Â respectively. Â 
2.3.Â TheÂ Framework Â ofÂ theÂ ProposedÂ ModelÂ 
ToÂ furtherÂ mineÂ theÂ temporal Â correlation Â fromÂ theÂ SCADAÂ dataÂ relatedÂ toÂ WTÂ mainÂ 
bearings Â andÂ achieveÂ forecasting Â withÂ highÂ accuracy, Â weÂ developed Â theÂ framework Â ofÂ theÂ 
SLSTMâ€MLPÂ modelÂ forÂ WTÂ mainÂ bearingÂ temperature Â forecasting Â withÂ aÂ multivariable Â 
timeÂ seriesÂ modeling Â method.Â TheÂ framework Â consisted Â ofÂ fourÂ parts:Â inputÂ layer,Â multiâ€
hiddenÂ layers,Â fullyÂ connected Â layer,Â andÂ regression Â outputÂ layer.Â TheÂ framework Â ofÂ theÂ 
SLSTMâ€MLPÂ modelÂ isÂ shownÂ inÂ FigureÂ 2.Â 
Â 
FigureÂ 2.Â Architecture Â ofÂ theÂ unfolded Â stackedÂ LSTMâ€MLPÂ neuralÂ network. Â 
Figure 2. Architecture of the unfolded stacked LSTM-MLP neural network.
Algorithm 1 : Training the SSAE-MLP Model
Input: D=f(D1,O1), . . . ,(Di,Oi), . . .g,Di2R(m+1)w,Oi2Rk
Output: The optimal SLSTM-MLP model (*.h5)
1: Read normal historical SCADA data from csv ï¬les;
2: Clean and resample data;
3: Select related conditional parameter variables;
//construct training dataset and verify dataset
4: D=?,TD=?,VD=?
5: fori in range (1, n-w) do: // set the sliding step is 1
6: D=D[Di
7: end for
8: According to the ratio of 80% and 20%, split the Dto generate TD,VD
//train SLSTM-MLP model
9: Assign maximum values to these parameters: hidden layers n l, units s l,
iterations e, and set the range of learning rate lr, batch size batch;
10: Initialize parameters;
11: while i <= e:
12: Train the model using training data in batches;
13: Use adam or BPTT algorithms to optimize the model;
14: Verify the model using verify dataset;
15: Reserve the optimum parameters;
16: end while
17: Return The optimal SLSTM-MLP model (*.h5);
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 7 of 23
3. Experiment Setup and Model Determination
In this section, we ï¬rst explore the characteristics of the WT SCADA dataset. Then,
we descript experimental setup details, including the selection of condition parameters,
data cleansing and resampling, and training dataset construction. At last, we analyze the
structure determination of the proposed model in detail. The experiments are conducted on
the server cluster, and the assigned virtual machine (VM) has a dual-core central processing
unit (CPU) conï¬gured by a 2.2 GHz Inten (R) E 7-8860 processor with 32 GB RAM, using
Python 3.6 software package and Keras API under Windows 10 pro with 64-bit operating
system to development.
3.1. Data Description
In this study, our research focuses on a 2 MW direct-driven WT with cut-in, rated, and
cut-out wind speeds of 3, 11, and 25 m/s, located at Lu Hejin wind farm in Chenzhou,
southern China. We collected the dataset from the WT SCADA system with a 1 Hz sampling
frequency. The dataset records 155 conditional parameters for each WT, and all data are
stored in 10 min CSV ï¬les. Table 1 lists a small portion of the raw data with some speciï¬ed
attribute ï¬elds from the SCADA systems.
Table 1. Partial raw WT data from SCADA system.
No. TIME (hh: mm: ss) WS(m/s) RS (rpm) HT () MT () GST () . . . OP (kW)
1 00:17:31 7.0 11.45 39.4 50.3 49.1 . . . 687
2 00:17:32 6.7 11.42 39.4 50.3 49.1 . . . 691
3 00:17:33 6.7 11.40 39.4 50.3 49.1 . . . 691
4 00:17:36 null null null null null . . . null
5 00:17:37 0 0 0 0 0 . . . 0
6 00:17:38 7.5 11.44 39.4 50.2 49.1 697
. . . . . . . . . . . . . . . . . . . . . . . . . . .
Notation: TIME, record time; WS, wind speed; RS, rotor speed; HT, hub temperature; MT, main bearing tempera-
ture; GST, generator stator temperature; OP , output power.
3.2. Condition Parameters Selection
The collected SCADA dataset from direct-driven WT involves many types of operating
condition parameters, such as rote speed, wind speed, voltage, current, temperature, output
power, etc. These condition parameters can be used to analyze and evaluate the operating
and health conditions of wind turbines. In this paper, we study the main bearing of large-
scale direct-driven WTs through temperature indicator variation trends. Based on our
previous research, we chose these parameters through correlation analysis and physical
information redundancy parameter elimination method. These parameters include wind
speed, output power, rotor speed, generator torque, generator stator temperature, generator
operating frequency, and environmental temperature, which are shown in Table 2 [26].
Table 2. Selected operating condition parameters variables of direct-driven WT.
No. Parameter Variable Description Units Abbr
1 Wind speed Wind speed with one second m/s WS
2 Rotor speed Hub rotation speed r/min RS
3 Output power Generator output power kW OP
4 Generator stator temperature Mean of six temperature sensorsC GST
5 Ambient temperature Temperature outside nacelleC AT
6 Operating frequency Generator operating frequency r/min GOF
7 Torque Rotational torque of generator N.m GT
8 Main bearing temperature Mean of two temperature sensorsC MBT
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 8 of 23
3.3. Data Cleansing and Resampling
In the process of WT SCADA data transmission and storage, some unstable factors,
such as control system failure, sensor malfunction, transmission cable problems, etc. lead to
null values, outliers, and other invalid data in the WT SCADA dataset, as seen in lines 4 and
5 in Table 1. In order to obtain high-quality data and ensure high precision of subsequent
modeling results, data cleaning is needed. In other words, some downtime data, packet
loss data, negative data, and null data were deleted in this study. At the same time, we
also resampled the data samples according to the practices of existing studies [ 27â€“30]. The
detailed calculation method for data cleansing and data resampling is shown in Equation
(8) and in our previous study [26].
8
>>>>>>>>>><
>>>>>>>>>>:delete x i,
xi=xi+1or x i 1,f or x i2hault data
f or x i2packet loss data
xi=0,
xi=1
2(xi 1+xi+1)f or x i<0or x iis null
f or x i2xi 1and x i2xi+1or
f or x ixi 1/2and x ixi+1/2
x=1
nn
Ã¥
i=1xi, others(8)
After the collected SCADA data was cleaned and resampled, a partial time series
diagram of eight condition parameter variables is shown in Figure 3.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  8Â ofÂ 22Â 
Â 
Â 3.3.Â DataÂ Cleansing Â andÂ Resampling Â 
InÂ theÂ processÂ ofÂ WTÂ SCADAÂ dataÂ transmission Â andÂ storage,Â someÂ unstableÂ factors,Â 
suchÂ asÂ controlÂ systemÂ failure,Â sensorÂ malfunction, Â transmission Â cableÂ problems, Â etc.Â leadÂ 
toÂ nullÂ values,Â outliers,Â andÂ otherÂ invalidÂ dataÂ inÂ theÂ WTÂ SCADAÂ dataset,Â asÂ seenÂ inÂ linesÂ 
4Â andÂ 5Â inÂ TableÂ 1.Â InÂ orderÂ toÂ obtainÂ highâ€qualityÂ dataÂ andÂ ensureÂ highÂ precision Â ofÂ subâ€
sequentÂ modeling Â results,Â dataÂ cleaningÂ isÂ needed.Â InÂ otherÂ words,Â someÂ downtime Â data,Â 
packetÂ lossÂ data,Â negative Â data,Â andÂ nullÂ dataÂ wereÂ deletedÂ inÂ thisÂ study.Â AtÂ theÂ sameÂ time,Â 
weÂ alsoÂ resampled Â theÂ dataÂ samplesÂ according Â toÂ theÂ practices Â ofÂ existingÂ studiesÂ [27â€“30].Â 
TheÂ detailedÂ calculation Â methodÂ forÂ dataÂ cleansing Â andÂ dataÂ resampling Â isÂ shownÂ inÂ Equaâ€
tionÂ (8)Â andÂ inÂ ourÂ previous Â studyÂ [26].Â 
â©âªâªâ¨âªâªâ§ğ‘‘ğ‘’ğ‘™ğ‘’ğ‘¡ğ‘’ ğ‘¥ à¯œ,
ğ‘¥à¯œàµŒğ‘¥ à¯œà¬¾à¬µ ğ‘œğ‘Ÿ ğ‘¥ à¯œà¬¿à¬µ, ğ‘“ğ‘œğ‘Ÿ ğ‘¥ à¯œâˆˆ â„ğ‘ğ‘¢ğ‘™ğ‘¡ ğ‘‘ğ‘ğ‘¡ğ‘ 
ğ‘“ğ‘œğ‘Ÿ ğ‘¥ à¯œâˆˆ ğ‘ğ‘ğ‘ğ‘˜ğ‘’ğ‘¡ ğ‘™ğ‘œğ‘ ğ‘  ğ‘‘ğ‘ğ‘¡ğ‘ 
ğ‘¥à¯œàµŒ0 ,
ğ‘¥à¯œàµŒ1
2áˆºğ‘¥à¯œà¬¿à¬µàµ…ğ‘¥ à¯œà¬¾à¬µáˆ»ğ‘“ğ‘œğ‘Ÿ ğ‘¥ à¯œàµ0  ğ‘œ ğ‘Ÿ  ğ‘¥ à¯œ ğ‘–ğ‘  ğ‘›ğ‘¢ğ‘™ğ‘™ 
ğ‘“ğ‘œğ‘Ÿ ğ‘¥ à¯œàµ’2 ğ‘¥ à¯œà¬¿à¬µ ğ‘ğ‘›ğ‘‘ ğ‘¥ à¯œàµ’2 ğ‘¥ à¯œà¬¾à¬µ ğ‘œğ‘Ÿ 
ğ‘“ğ‘œğ‘Ÿ ğ‘¥ à¯œàµ‘ğ‘¥ à¯œà¬¿à¬µ/2 ğ‘ğ‘›ğ‘‘ ğ‘¥ à¯œàµ‘ğ‘¥ à¯œà¬¾à¬µ/2 
ğ‘¥àµŒ1
ğ‘›à·ğ‘¥ à¯œà¯¡
à¯œà­€à¬µ,ğ‘œ ğ‘¡ â„ ğ‘’ ğ‘Ÿ ğ‘   Â  (8)
AfterÂ theÂ collected Â SCADAÂ dataÂ wasÂ cleanedÂ andÂ resampled, Â aÂ partialÂ timeÂ seriesÂ 
diagramÂ ofÂ eightÂ condition Â parameter Â variables Â isÂ shownÂ inÂ FigureÂ 3.Â 
Â 
FigureÂ 3.Â PartialÂ timeâ€seriesÂ diagramÂ ofÂ selectedÂ condition Â parameter Â variables Â forÂ aÂ specificÂ timeÂ 
period.Â (a)Â MainÂ bearingÂ temperature. Â (b)Â WindÂ speed.Â (c)Â Ambient Â temperature. Â (d)Â RotorÂ speed.Â 
(e)Â OutputÂ power.Â (f)Â Operating Â frequency Â ofÂ generator. Â (g)Â Generator Â torque.Â (h)Â StatorÂ temperature Â 
ofÂ generator. Â 
InÂ FigureÂ 3,Â theÂ windÂ speedÂ fluctuates Â greatly,Â andÂ theÂ threeÂ temperature Â parameters Â 
showÂ nonlinear Â andÂ gradualÂ variation Â trends.Â WithÂ theÂ increasing Â windÂ speed,Â hubÂ speed,Â 
generator Â torque,Â andÂ outputÂ powerÂ alsoÂ increased Â correspondingly, Â andÂ theÂ correlation Â 
coefficients Â betweenÂ windÂ speedÂ andÂ hubÂ speed,Â generator Â torque,Â andÂ generator Â outputÂ 
powerÂ wereÂ 0.9132,Â 0.9657,Â andÂ 0.9718,Â respectively. Â WithÂ theÂ increaseÂ ofÂ windÂ speed,Â staâ€
torÂ temperature Â andÂ mainÂ bearingÂ temperature Â keptÂ aÂ slowlyÂ risingÂ trend,Â andÂ theÂ correâ€
lationÂ coefficients Â betweenÂ windÂ speedÂ andÂ generator Â statorÂ temperature Â andÂ mainÂ bearâ€
ingÂ temperature Â wereÂ 0.7303Â andÂ 0.4439,Â respectively. Â TheÂ abruptÂ trendÂ ofÂ windÂ speedÂ 
showedÂ aÂ weakening Â characteristic Â inÂ theÂ condition Â parameters Â ofÂ aÂ largeÂ inertiaÂ systemÂ 
andÂ becameÂ weakerÂ inÂ theÂ temperature Â parameters Â trend.Â TheÂ currentÂ valueÂ ofÂ condition Â 
Figure 3. Partial time-series diagram of selected condition parameter variables for a speciï¬c time
period. ( a) Main bearing temperature. ( b) Wind speed. ( c) Ambient temperature. ( d) Rotor speed.
(e) Output power. ( f) Operating frequency of generator. ( g) Generator torque. ( h) Stator temperature
of generator.
In Figure 3, the wind speed ï¬‚uctuates greatly, and the three temperature parameters
show nonlinear and gradual variation trends. With the increasing wind speed, hub speed,
generator torque, and output power also increased correspondingly, and the correlation
coefï¬cients between wind speed and hub speed, generator torque, and generator output
power were 0.9132, 0.9657, and 0.9718, respectively. With the increase of wind speed, stator
temperature and main bearing temperature kept a slowly rising trend, and the correlation
coefï¬cients between wind speed and generator stator temperature and main bearing
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 9 of 23
temperature were 0.7303 and 0.4439, respectively. The abrupt trend of wind speed showed
a weakening characteristic in the condition parameters of a large inertia system and became
weaker in the temperature parameters trend. The current value of condition parameters is
related to the value of a previous period of time. There is a complex inherent correlation
and time dependence relationship among the eight condition parameter variables. The
correlation coefï¬cient values of these condition parameters are shown in Table 3.
Table 3. Correlation coefï¬cient of condition parameter variables.
No. MBT WS AT RS OP GOF GT GST
MBT 1.0000 0.4439  0.7014 0.3286 0.5037 0.3288 0.5271 0.7872
WS 0.4439 1.0000  0.3285 0.9131 0.9718 0.9131 0.9657 0.7303
AT 0.7014 0.3285 1.0000  0.2625 0.4324 0.2629 0.4596 0.6334
RS 0.3286 0.9131  0.2625 1.0000 0.9311 1.0000 0.9013 0.5194
OP 0.5037 0.9718  0.4324 0.9311 1.0000 0.9313 0.9966 0.7464
GOF 0.3288 0.9131  0.2629 1.0000 0.9313 1.0000 0.9015 0.5196
GT 0.5271 0.9657  0.4596 0.9013 0.9966 0.9015 1.0000 0.7776
GST 0.7872 0.7303  0.6334 0.5194 0.7464 0.5196 0.7776 1.0000
3.4. Dataset Construction
The current value of the eight condition parameter variables is affected by its previous
values, and these values show obvious temporal characteristics. In order to explore the
complex internal relationship and temporal characteristic relationship between variables,
we used the sliding window method to process the raw data and generate an input dataset
and output dataset. The speciï¬c construction process is shown in Figure 4.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  9Â ofÂ 22Â 
Â 
Â parameters Â isÂ relatedÂ toÂ theÂ valueÂ ofÂ aÂ previous Â periodÂ ofÂ time.Â ThereÂ isÂ aÂ complex Â inherentÂ 
correlation Â andÂ timeÂ dependence Â relationship Â amongÂ theÂ eightÂ condition Â parameter Â variâ€
ables.Â TheÂ correlation Â coefficient Â valuesÂ ofÂ theseÂ condition Â parameters Â areÂ shownÂ inÂ TableÂ 
3.Â 
TableÂ 3.Â Correlation Â coefficient Â ofÂ condition Â parameter Â variables. Â 
No.Â MBTÂ  WSÂ  ATÂ  RSÂ  OPÂ  GOFÂ  GTÂ  GSTÂ 
MBTÂ 1.0000Â Â 0.4439Â Â  âˆ’0.7014Â Â 0.3286Â Â 0.5037Â Â 0.3288Â Â 0.5271Â Â 0.7872Â 
WSÂ 0.4439Â Â 1.0000Â Â  âˆ’0.3285Â Â 0.9131Â Â 0.9718Â Â 0.9131Â Â 0.9657Â Â 0.7303Â Â 
ATÂ âˆ’0.7014Â Â  âˆ’0.3285Â Â 1.0000Â Â  âˆ’0.2625Â Â  âˆ’0.4324Â Â  âˆ’0.2629Â Â  âˆ’0.4596Â Â  âˆ’0.6334Â Â 
RSÂ 0.3286Â Â 0.9131Â Â  âˆ’0.2625Â Â 1.0000Â Â 0.9311Â Â 1.0000Â Â 0.9013Â Â 0.5194Â Â 
OPÂ 0.5037Â Â 0.9718Â Â  âˆ’0.4324Â Â 0.9311Â Â 1.0000Â Â 0.9313Â Â 0.9966Â Â 0.7464Â Â 
GOFÂ 0.3288Â Â 0.9131Â Â  âˆ’0.2629Â Â 1.0000Â Â 0.9313Â Â 1.0000Â Â 0.9015Â Â 0.5196Â Â 
GTÂ 0.5271Â Â 0.9657Â Â  âˆ’0.4596Â Â 0.9013Â Â 0.9966Â Â 0.9015Â Â 1.0000Â Â 0.7776Â Â 
GSTÂ 0.7872Â Â 0.7303Â Â  âˆ’0.6334Â Â 0.5194Â Â 0.7464Â Â 0.5196Â Â 0.7776Â Â 1.0000Â Â 
3.4.Â DatasetÂ Construction Â 
TheÂ currentÂ valueÂ ofÂ theÂ eightÂ condition Â parameter Â variables Â isÂ affectedÂ byÂ itsÂ previâ€
ousÂ values,Â andÂ theseÂ valuesÂ showÂ obviousÂ temporal Â characteristics. Â InÂ orderÂ toÂ exploreÂ 
theÂ complex Â internalÂ relationship Â andÂ temporal Â characteristic Â relationship Â betweenÂ variaâ€
bles,Â weÂ usedÂ theÂ slidingÂ windowÂ methodÂ toÂ processÂ theÂ rawÂ dataÂ andÂ generate Â anÂ inputÂ 
datasetÂ andÂ outputÂ dataset.Â TheÂ specificÂ construction Â processÂ isÂ shownÂ inÂ FigureÂ 4.Â 
FromÂ FigureÂ 4,Â wÂ isÂ theÂ widthÂ ofÂ theÂ slidingÂ window, Â sÂ isÂ theÂ lengthÂ ofÂ theÂ slidingÂ 
step,Â andÂ ğ·à¯œÂ andÂ ğ·à¯œà¬¾à¬µÂ areÂ takenÂ asÂ inputÂ featureÂ vectors,Â whichÂ represent Â theÂ relevantÂ 
conditional Â parameter Â variables Â beforeÂ timeÂ intervalÂ iÂ andÂ historical Â dataÂ backward Â ofÂ theÂ 
mainÂ bearingÂ temperature Â fromÂ theÂ currentÂ timeÂ intervalÂ i. ğ‘‚à¯œÂ andÂ ğ‘‚à¯œà¬¾à¬µÂ areÂ outputÂ featureÂ 
vectors,Â whichÂ represent Â theÂ mainÂ bearingÂ temperature Â valuesÂ atÂ theÂ nextÂ nÂ steps.Â 
Â 
FigureÂ 4.Â SlidingÂ windowÂ diagramÂ forÂ datasetÂ construction. Â 
3.5.Â Forecasting Â Evaluation Â MetricsÂ 
ThreeÂ evaluation Â metricsÂ wereÂ usedÂ toÂ evaluateÂ theÂ forecasting Â results,Â namelyÂ MAEÂ 
(meanÂ absoluteÂ error),Â MSEÂ (meanÂ squareÂ error),Â andÂ ğ‘…à¬¶Â (Râ€squared). Â TheirÂ expressions Â 
canÂ beÂ listedÂ asÂ follows:Â 
Figure 4. Sliding window diagram for dataset construction.
From Figure 4, wis the width of the sliding window, sis the length of the sliding
step, and Diand Di+1are taken as input feature vectors, which represent the relevant
conditional parameter variables before time interval iand historical data backward of the
main bearing temperature from the current time interval i.Oiand Oi+1are output feature
vectors, which represent the main bearing temperature values at the next nsteps.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 10 of 23
3.5. Forecasting Evaluation Metrics
Three evaluation metrics were used to evaluate the forecasting results, namely MAE
(mean absolute error), MSE (mean square error), and R2(R-squared). Their expressions can
be listed as follows:
MAE =1
NN
Ã¥
i=1y0
pre,i yact,i (9)
MSE =1
NN
Ã¥
i=1(y0
pre,i yact,i)2(10)
R2=N
Ã¥
i=1(y0
pre,i yact)2/N
Ã¥
i=1(yact,i yact)2(11)
where y0
pre,irepresents the forecasted value at time interval i;yact,irepresents the observed
value at time interval i;yactrepresents the average of the active value; Nrepresents the
number of samples. The smaller the MAE and MSE , the higher the forecasting accuracy
will be. R2is the ï¬tting goodness of the regression model. The closer the value is to 1, the
better the model ï¬ts the observed value and vice versa.
3.6. Structure Determination of the SLSTM-MLP
In the training process of the SLSTM-MLP , there are several hyperparameters that
need to be determined, namely time step, batch size, features, units, learning rate, and
dropout. (1) Time step: sequence length (the lagged length of the associated variable in
the time dimension). This parameter determines how many historical data are used for
each parameter variable to forecast. We should ï¬rst understand from the mechanism of
heat transfer what length is reasonable to choose. (2) Features: the number of variables
(the feature dimensions), which is to say the dimension of each sample, these features are
interpreted by a vector with multiple related variables served as input features for the
model. The dimensions of the input data are equal to the number of features multiplied
by the time step. (3) Units: the number of hidden neurons in a single LSTM unit, which is
used to remember and store past states; that is, the size of the cell. Cells are parallel, share
weights for a given time step, and process input data simultaneously, which determines
the output dimension of an LSTM. The unit size usually varies from dozens to hundreds
and is usually an integer multiple. (4) Batch size: the number of samples that are input into
the neural network training at one time to complete weight parameter calculations and
update. The larger the value, the more stable the gradient will be when the model is trained.
There are two extreme cases, one is to feed all the samples at once, which is the traditional
gradient descent method, and the other is to feed only one sample at a time, which is
the stochastic gradient descent method. The convergence rate of the former method is
slower than that of the latter. Practice shows that the training of small-batch samples is
optimal and usually set as a power of 2, such as 8, 16, 32, 64, and 128. (5) Learning rate:
how fast the model can converge to the optimal value. The smaller the learning rate, the
slower the gradient descent speed of the loss function, the longer the convergence time of
the algorithm, and vice versa. The learning rate can be set as 0.1, 0.01, 0.001, and 0.0001.
(6) Dropout: regularization method to prevent overï¬tting by deleting a proportion of
hidden neurons; usually ranges from 10%, 20%, 30%, 40%, and 50%.
Parameter tuning is an important task in machine learning modeling. For these
hyperparameter selections, there are two generic approaches, grid search, and randomized
search. In this study, we used the grid search method to obtain the optimal parameters. For
the input layer, we select eight parameters as input vectors (details are given in Section 3.2),
and the other hyperparameter set is shown in Table 4.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 11 of 23
Table 4. Hyperparameters for the SLSTM-MLP model.
No. Hyperparameters Value Range No. Hyperparameters Value Range
1 Time step [1, 2, 3] 5 Learning rate [0.1, 0.01, 0.001]
2 Features 8 6 Dropout [0.1, 0.2, 0.3]
3 Units [5, 10, 15, . . . , 200] 7 Epoch 100
4 Batch size [8, 16, 31] 8 optimizers Adam
Since there is a certain randomness in the training process of deep learning models
with different structures, i.e., the same input for the same structural model will yield
different results and also show some random instability. Therefore, by executing each
structural model multiple times and by analyzing the statistical characteristics of these
experimental results, we will get the best one for temperature forecasting of the WT main
bearing. In this study, we ï¬rst deï¬ned 9 basic structures through repeated experiments,
namely Model 1, Model 2, and Model 3, respectively, represent the single-layer LSTM
Model with 1 to 3 timesteps; Model 4, Model 5, and Model 6, respectively, represent the
two-layer LSTM Model with 1 to 3 timesteps; Model 7, Model 8, and Model 9 represent
three-layer LSTM models with 1 to 3 timesteps, respectively. Then, we ran each structural
model ten times by using the grid search method, and the experimental results of the
indicator MAE and R2values are shown in Figures 5 and 6, respectively. To evaluate
the performance and stability of these models, we considered the mean and variance of
each structural model as the evaluation basis. In addition to considering the mean as
small as possible, we further considered variance as small as possible because the mean
is susceptible to the inï¬‚uence of extreme values (maximum and minimum values), while
variance describes the degree of dispersion between the data value and the mean, which
better reï¬‚ects the stability of the model. From Figure 5, with the increase of the number
of layers, the median values of all models show a ï¬‚uctuating trend of decreasing ï¬rst
and then increasing, and the overall trend shows a ï¬‚uctuating rising pattern. Figure 6
shows a similar reverse trend, i.e., the ï¬tting degree R2of the regression models shows
a ï¬‚uctuating trend of increasing ï¬rst and then decreasing, and the overall trend shows
a ï¬‚uctuating decreasing pattern. Figure 5 and Table 5 show that, according to the mean,
Model 2 performed best, followed by Model 4. Although the mean value of Model 2 was
6.52% lower than that of Model 4, its variance was 69.67% higher than that of Model 4, and
its ï¬tting degree R2was 8.24% lower than that of Model 4; furthermore, Model 4 had no
extreme outliers while Model 2 had two extreme outliers. Therefore, we chose Model 4 as
the ï¬nal forecasting model for WT main bearing temperature forecasting.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  11Â ofÂ 22Â 
Â 
Â TableÂ 4.Â Hyperparameters Â forÂ theÂ SLSTMâ€MLPÂ model.Â 
No.Â Hyperparameters Â ValueÂ RangeÂ No.Â Hyperparameters Â ValueÂ RangeÂ 
1Â  TimeÂ stepÂ  [1,Â 2,Â 3]Â  5Â  Learning Â rateÂ  [0.1,Â 0.01,Â 0.001]Â 
2Â  Features Â  8Â  6Â  Dropout Â  [0.1,Â 0.2,Â 0.3]Â 
3Â  UnitsÂ  [5,Â 10,Â 15,Â â€¦,Â 200]Â 7Â  EpochÂ  100Â 
4Â  BatchÂ sizeÂ  [8,Â 16,Â 31]Â  8Â  optimizers Â  AdamÂ 
SinceÂ thereÂ isÂ aÂ certainÂ randomness Â inÂ theÂ trainingÂ processÂ ofÂ deepÂ learningÂ modelsÂ 
withÂ different Â structures, Â i.e.,Â theÂ sameÂ inputÂ forÂ theÂ sameÂ structural Â modelÂ willÂ yieldÂ difâ€
ferentÂ resultsÂ andÂ alsoÂ showÂ someÂ randomÂ instability. Â Therefore, Â byÂ executing Â eachÂ strucâ€
turalÂ modelÂ multiple Â timesÂ andÂ byÂ analyzing Â theÂ statistical Â characteristics Â ofÂ theseÂ experiâ€
mentalÂ results,Â weÂ willÂ getÂ theÂ bestÂ oneÂ forÂ temperature Â forecasting Â ofÂ theÂ WTÂ mainÂ bearâ€
ing.Â InÂ thisÂ study,Â weÂ firstÂ definedÂ 9Â basicÂ structures Â throughÂ repeated Â experiments, Â 
namelyÂ ModelÂ 1,Â ModelÂ 2,Â andÂ ModelÂ 3,Â respectively, Â represent Â theÂ singleâ€layerÂ LSTMÂ 
ModelÂ withÂ 1Â toÂ 3Â timesteps; Â ModelÂ 4,Â ModelÂ 5,Â andÂ ModelÂ 6,Â respectively, Â represent Â theÂ 
twoâ€layerÂ LSTMÂ ModelÂ withÂ 1Â toÂ 3Â timesteps; Â ModelÂ 7,Â ModelÂ 8,Â andÂ ModelÂ 9Â represent Â 
threeâ€layerÂ LSTMÂ modelsÂ withÂ 1Â toÂ 3Â timesteps, Â respectively. Â Then,Â weÂ ranÂ eachÂ structural Â 
modelÂ tenÂ timesÂ byÂ usingÂ theÂ gridÂ searchÂ method,Â andÂ theÂ experimental Â resultsÂ ofÂ theÂ inâ€
dicatorÂ MAEÂ andÂ R2Â valuesÂ areÂ shownÂ inÂ FiguresÂ 5Â andÂ 6,Â respectively. Â ToÂ evaluateÂ theÂ 
performance Â andÂ stabilityÂ ofÂ theseÂ models,Â weÂ considered Â theÂ meanÂ andÂ varianceÂ ofÂ eachÂ 
structural Â modelÂ asÂ theÂ evaluation Â basis.Â InÂ addition Â toÂ considering Â theÂ meanÂ asÂ smallÂ asÂ 
possible, Â weÂ furtherÂ considered Â varianceÂ asÂ smallÂ asÂ possibleÂ becauseÂ theÂ meanÂ isÂ suscepâ€
tibleÂ toÂ theÂ influence Â ofÂ extremeÂ valuesÂ (maximum Â andÂ minimum Â values),Â whileÂ variance Â 
describes Â theÂ degreeÂ ofÂ dispersion Â betweenÂ theÂ dataÂ valueÂ andÂ theÂ mean,Â whichÂ betterÂ 
reflectsÂ theÂ stabilityÂ ofÂ theÂ model.Â FromÂ FigureÂ 5,Â withÂ theÂ increaseÂ ofÂ theÂ numberÂ ofÂ layers,Â 
theÂ medianÂ valuesÂ ofÂ allÂ modelsÂ showÂ aÂ fluctuating Â trendÂ ofÂ decreasing Â firstÂ andÂ thenÂ inâ€
creasing, Â andÂ theÂ overallÂ trendÂ showsÂ aÂ fluctuating Â risingÂ pattern.Â FigureÂ 6Â showsÂ aÂ similarÂ 
reverseÂ trend,Â i.e.,Â theÂ fittingÂ degreeÂ R2Â ofÂ theÂ regression Â modelsÂ showsÂ aÂ fluctuating Â trendÂ 
ofÂ increasing Â firstÂ andÂ thenÂ decreasing, Â andÂ theÂ overallÂ trendÂ showsÂ aÂ fluctuating Â decreasâ€
ingÂ pattern.Â FigureÂ 5Â andÂ TableÂ 5Â showÂ that,Â according Â toÂ theÂ mean,Â ModelÂ 2Â performed Â 
best,Â followed Â byÂ ModelÂ 4.Â Although Â theÂ meanÂ valueÂ ofÂ ModelÂ 2Â wasÂ 6.52%Â lowerÂ thanÂ 
thatÂ ofÂ ModelÂ 4,Â itsÂ varianceÂ wasÂ 69.67%Â higherÂ thanÂ thatÂ ofÂ ModelÂ 4,Â andÂ itsÂ fittingÂ degreeÂ 
R2Â wasÂ 8.24%Â lowerÂ thanÂ thatÂ ofÂ ModelÂ 4;Â furthermore, Â ModelÂ 4Â hadÂ noÂ extremeÂ outliersÂ 
whileÂ ModelÂ 2Â hadÂ twoÂ extremeÂ outliers.Â Therefore, Â weÂ choseÂ ModelÂ 4Â asÂ theÂ finalÂ foreâ€
castingÂ modelÂ forÂ WTÂ mainÂ bearingÂ temperature Â forecasting. Â 
 
FigureÂ 5.Â Comparison Â ofÂ different Â SLSTMâ€MLPÂ modelsÂ inÂ termsÂ ofÂ theÂ MAE.Â 
Figure 5. Comparison of different SLSTM-MLP models in terms of the MAE.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 12 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  12Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 6.Â Comparison Â ofÂ different Â SLSTMâ€MLPÂ modelsÂ inÂ termsÂ ofÂ theÂ R2.Â 
TableÂ 5.Â Performance Â indexesÂ ofÂ different Â SLSTMâ€MLPÂ models.Â 
ModelÂ TestingÂ Datasets Â 
MAEÂ  MSEÂ  R2Â 
ModeÂ 1Â  0.064433Â Â±Â 0.007577Â  0.00689Â Â±Â 0.001184Â  0.987706Â Â±Â 0.002110Â 
ModelÂ 2Â  0.055311Â Â±Â 0.007579Â  0.005166Â Â±Â 0.001053Â  0.990768Â Â±Â 0.001882Â 
ModelÂ 3Â  0.065707Â Â±Â 0.006600Â  0.007294Â Â±Â 0.001333Â  0.986966Â Â±Â 0.002382Â 
ModelÂ 4Â  0.059168Â Â±Â 0.004467Â  0.005957Â Â±Â 0.000969Â  0.989383Â Â±Â 0.001727Â 
ModelÂ 5Â  0.065263Â Â±Â 0.006892Â  0.006824Â Â±Â 0.000929Â  0.987806Â Â±Â 0.001660Â 
ModelÂ 6Â  0.074838Â Â±Â 0.006858Â  0.008535Â Â±Â 0.001388Â  0.983134Â Â±Â 0.002481Â 
ModelÂ 7Â  0.068202Â Â±Â 0.009132Â  0.007700Â Â±Â 0.001635Â  0.986276Â Â±Â 0.002914Â 
ModelÂ 8Â  0.073384Â Â±Â 0.005767Â  0.008504Â Â±Â 0.000551Â  0.984804Â Â±Â 0.000984Â 
ModelÂ 9Â  0.076044Â Â±Â 0.006411Â  0.009438Â Â±Â 0.001342Â  0.983134Â Â±Â 0.002399Â 
4.Â Performance Â Comparison Â 
ToÂ evaluateÂ theÂ performance Â ofÂ theÂ SLSTMâ€MLPÂ model,Â severalÂ rivalÂ modelsÂ wereÂ 
used,Â suchÂ asÂ RNN,Â GRU,Â andÂ LSTM,Â fromÂ threeÂ aspects:Â different Â sampleÂ capacityÂ sizes,Â 
different Â sampling Â timeÂ segments, Â andÂ different Â sampling Â frequencies. Â 
4.1.Â DifferentÂ SampleÂ CapacityÂ SizeÂ 
SampleÂ capacityÂ sizeÂ represents Â theÂ necessary Â numberÂ ofÂ samplesÂ inÂ theÂ processÂ ofÂ 
sampling Â investigation, Â whichÂ affectsÂ theÂ accuracy Â andÂ confidence Â valueÂ toÂ aÂ certainÂ exâ€
tent.Â Usually,Â weÂ chooseÂ moreÂ thanÂ 30Â samples, Â andÂ inÂ thisÂ study,Â weÂ choseÂ 60Â andÂ 120Â asÂ 
theÂ researchÂ points,Â respectively. Â WeÂ selectedÂ theÂ SCADAÂ experimental Â dataÂ fromÂ theÂ obâ€
jectiveÂ WT,Â andÂ someÂ windÂ speedÂ dataÂ areÂ shownÂ inÂ FigureÂ 7.Â 
Â 
FigureÂ 7.Â WindÂ speedÂ dataÂ ofÂ twoÂ different Â sampleÂ capacityÂ sizesÂ ofÂ GroupÂ AÂ andÂ GroupÂ B.Â 
Figure 6. Comparison of different SLSTM-MLP models in terms of the R2.
Table 5. Performance indexes of different SLSTM-MLP models.
ModelTesting Datasets
MAE MSE R2
Mode 1 0.064433 0.007577 0.00689 0.001184 0.987706 0.002110
Model 2 0.055311 0.007579 0.005166 0.001053 0.990768 0.001882
Model 3 0.065707 0.006600 0.007294 0.001333 0.986966 0.002382
Model 4 0.059168 0.004467 0.005957 0.000969 0.989383 0.001727
Model 5 0.065263 0.006892 0.006824 0.000929 0.987806 0.001660
Model 6 0.074838 0.006858 0.008535 0.001388 0.983134 0.002481
Model 7 0.068202 0.009132 0.007700 0.001635 0.986276 0.002914
Model 8 0.073384 0.005767 0.008504 0.000551 0.984804 0.000984
Model 9 0.076044 0.006411 0.009438 0.001342 0.983134 0.002399
4. Performance Comparison
To evaluate the performance of the SLSTM-MLP model, several rival models were
used, such as RNN, GRU, and LSTM, from three aspects: different sample capacity sizes,
different sampling time segments, and different sampling frequencies.
4.1. Different Sample Capacity Size
Sample capacity size represents the necessary number of samples in the process of
sampling investigation, which affects the accuracy and conï¬dence value to a certain extent.
Usually, we choose more than 30 samples, and in this study, we chose 60 and 120 as the
research points, respectively. We selected the SCADA experimental data from the objective
WT, and some wind speed data are shown in Figure 7.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  12Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 6.Â Comparison Â ofÂ different Â SLSTMâ€MLPÂ modelsÂ inÂ termsÂ ofÂ theÂ R2.Â 
TableÂ 5.Â Performance Â indexesÂ ofÂ different Â SLSTMâ€MLPÂ models.Â 
ModelÂ TestingÂ Datasets Â 
MAEÂ  MSEÂ  R2Â 
ModeÂ 1Â  0.064433Â Â±Â 0.007577Â  0.00689Â Â±Â 0.001184Â  0.987706Â Â±Â 0.002110Â 
ModelÂ 2Â  0.055311Â Â±Â 0.007579Â  0.005166Â Â±Â 0.001053Â  0.990768Â Â±Â 0.001882Â 
ModelÂ 3Â  0.065707Â Â±Â 0.006600Â  0.007294Â Â±Â 0.001333Â  0.986966Â Â±Â 0.002382Â 
ModelÂ 4Â  0.059168Â Â±Â 0.004467Â  0.005957Â Â±Â 0.000969Â  0.989383Â Â±Â 0.001727Â 
ModelÂ 5Â  0.065263Â Â±Â 0.006892Â  0.006824Â Â±Â 0.000929Â  0.987806Â Â±Â 0.001660Â 
ModelÂ 6Â  0.074838Â Â±Â 0.006858Â  0.008535Â Â±Â 0.001388Â  0.983134Â Â±Â 0.002481Â 
ModelÂ 7Â  0.068202Â Â±Â 0.009132Â  0.007700Â Â±Â 0.001635Â  0.986276Â Â±Â 0.002914Â 
ModelÂ 8Â  0.073384Â Â±Â 0.005767Â  0.008504Â Â±Â 0.000551Â  0.984804Â Â±Â 0.000984Â 
ModelÂ 9Â  0.076044Â Â±Â 0.006411Â  0.009438Â Â±Â 0.001342Â  0.983134Â Â±Â 0.002399Â 
4.Â Performance Â Comparison Â 
ToÂ evaluateÂ theÂ performance Â ofÂ theÂ SLSTMâ€MLPÂ model,Â severalÂ rivalÂ modelsÂ wereÂ 
used,Â suchÂ asÂ RNN,Â GRU,Â andÂ LSTM,Â fromÂ threeÂ aspects:Â different Â sampleÂ capacityÂ sizes,Â 
different Â sampling Â timeÂ segments, Â andÂ different Â sampling Â frequencies. Â 
4.1.Â DifferentÂ SampleÂ CapacityÂ SizeÂ 
SampleÂ capacityÂ sizeÂ represents Â theÂ necessary Â numberÂ ofÂ samplesÂ inÂ theÂ processÂ ofÂ 
sampling Â investigation, Â whichÂ affectsÂ theÂ accuracy Â andÂ confidence Â valueÂ toÂ aÂ certainÂ exâ€
tent.Â Usually,Â weÂ chooseÂ moreÂ thanÂ 30Â samples, Â andÂ inÂ thisÂ study,Â weÂ choseÂ 60Â andÂ 120Â asÂ 
theÂ researchÂ points,Â respectively. Â WeÂ selectedÂ theÂ SCADAÂ experimental Â dataÂ fromÂ theÂ obâ€
jectiveÂ WT,Â andÂ someÂ windÂ speedÂ dataÂ areÂ shownÂ inÂ FigureÂ 7.Â 
Â 
FigureÂ 7.Â WindÂ speedÂ dataÂ ofÂ twoÂ different Â sampleÂ capacityÂ sizesÂ ofÂ GroupÂ AÂ andÂ GroupÂ B.Â 
Figure 7. Wind speed data of two different sample capacity sizes of Group A and Group B.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 13 of 23
From Figure 7, the curve represents new time series data of wind speed. We took
point 92 as the starting point and 60 and 120 samples forward to form two datasets, named
Group A and Group B. The standard deviation of Group B was 64.2% higher than that of
Group A, the xmax-xmin value of Group B was 1.5 times that of Group A, and the average
wind speed value of Group B was 1.14 times that of Group A. It could be said that time
series Group A and Group B represent two completely different wind conditions in a sense.
In the following subsections, we explore the performance of the proposed SLSTM-MLP
model under two different sample capacity sizes and also compare it with other advanced
forecasting models, such as RNN, GRU, and LSTM.
In order to keep the consistency and fairness of the hyper-parameter tuning of the
rival models to be compared, we refer to the hyper-parameter tuning method of structure
determination for the proposed model and also used grid search methods to conduct
hyperparameter tuning for all rival models (RNN, GRU, and LSTM) to ï¬nd their respective
optimal models to predict the WT main bearing temperature. Each rival model was
executed 10 times for selecting the optimal structure in the same parameter search range as
the proposed SLSTM-MLP model, and the statistics results of multiple execution programs
are shown in Figures 8 and 9. As shown in Figures 8 and 9, all rival models showed lower
forecasting errors and higher ï¬tting degrees on the same dataset. The best-performing
model was the LSTM model, followed by the GRU model, and the least performing model
was the RNN model. Speciï¬cally, the average MAEs of RNN, GRU, and LSTM were 0.78153,
0.077327, and 0.064433, respectively, and their standard deviations were all lower than
0.023. The average ï¬tting degrees of RNN, GRU, and LSTM were 0.98346, 0.982952, and
0.987706, respectively, and their standard deviations were all less than 0.0045.
Based on the optimal ï¬tting degree and the deviation degree from the median of the
forecasting error value as the judgment criteria for selecting the best model, we chose the
optimal models among the three rival models to make forecasting under two different
sample capacity sizes. The forecasting results of four competitive models are shown in
Tables 6 and 7.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  13Â ofÂ 22Â 
Â 
Â FromÂ FigureÂ 7,Â theÂ curveÂ represents Â newÂ timeÂ seriesÂ dataÂ ofÂ windÂ speed.Â WeÂ tookÂ 
pointÂ 92Â asÂ theÂ startingÂ pointÂ andÂ 60Â andÂ 120Â samplesÂ forwardÂ toÂ formÂ twoÂ datasets, Â namedÂ 
GroupÂ AÂ andÂ GroupÂ B.Â TheÂ standard Â deviation Â ofÂ GroupÂ BÂ wasÂ 64.2%Â higherÂ thanÂ thatÂ ofÂ 
GroupÂ A,Â theÂ xmaxâ€xminÂ valueÂ ofÂ GroupÂ BÂ wasÂ 1.5Â timesÂ thatÂ ofÂ GroupÂ A,Â andÂ theÂ averageÂ 
windÂ speedÂ valueÂ ofÂ GroupÂ BÂ wasÂ 1.14Â timesÂ thatÂ ofÂ GroupÂ A.Â ItÂ couldÂ beÂ saidÂ thatÂ timeÂ 
seriesÂ GroupÂ AÂ andÂ GroupÂ BÂ represent Â twoÂ completely Â different Â windÂ conditions Â inÂ aÂ 
sense.Â InÂ theÂ following Â subsections, Â weÂ exploreÂ theÂ performance Â ofÂ theÂ proposed Â SLSTMâ€
MLPÂ modelÂ underÂ twoÂ different Â sampleÂ capacityÂ sizesÂ andÂ alsoÂ compare Â itÂ withÂ otherÂ adâ€
vancedÂ forecasting Â models,Â suchÂ asÂ RNN,Â GRU,Â andÂ LSTM.Â 
InÂ orderÂ toÂ keepÂ theÂ consistency Â andÂ fairnessÂ ofÂ theÂ hyperâ€parameter Â tuningÂ ofÂ theÂ 
rivalÂ modelsÂ toÂ beÂ compared, Â weÂ referÂ toÂ theÂ hyperâ€parameter Â tuningÂ methodÂ ofÂ structure Â 
determination Â forÂ theÂ proposed Â modelÂ andÂ alsoÂ usedÂ gridÂ searchÂ methods Â toÂ conductÂ hyâ€
perparameter Â tuningÂ forÂ allÂ rivalÂ modelsÂ (RNN,Â GRU,Â andÂ LSTM)Â toÂ findÂ theirÂ respective Â 
optimalÂ modelsÂ toÂ predictÂ theÂ WTÂ mainÂ bearingÂ temperature. Â EachÂ rivalÂ modelÂ wasÂ exeâ€
cutedÂ 10Â timesÂ forÂ selecting Â theÂ optimalÂ structure Â inÂ theÂ sameÂ parameter Â searchÂ rangeÂ asÂ 
theÂ proposed Â SLSTMâ€MLPÂ model,Â andÂ theÂ statistics Â resultsÂ ofÂ multiple Â execution Â proâ€
gramsÂ areÂ shownÂ inÂ FiguresÂ 8Â andÂ 9.Â AsÂ shownÂ inÂ FiguresÂ 8Â andÂ 9,Â allÂ rivalÂ modelsÂ showedÂ 
lowerÂ forecasting Â errorsÂ andÂ higherÂ fittingÂ degreesÂ onÂ theÂ sameÂ dataset.Â TheÂ bestâ€performâ€
ingÂ modelÂ wasÂ theÂ LSTMÂ model,Â followed Â byÂ theÂ GRUÂ model,Â andÂ theÂ leastÂ performing Â 
modelÂ wasÂ theÂ RNNÂ model.Â Specifically, Â theÂ averageÂ MAEsÂ ofÂ RNN,Â GRU,Â andÂ LSTMÂ 
wereÂ 0.78153,Â 0.077327, Â andÂ 0.064433, Â respectively, Â andÂ theirÂ standard Â deviations Â wereÂ allÂ 
lowerÂ thanÂ 0.023.Â TheÂ averageÂ fittingÂ degreesÂ ofÂ RNN,Â GRU,Â andÂ LSTMÂ wereÂ 0.98346,Â 
0.982952, Â andÂ 0.987706, Â respectively, Â andÂ theirÂ standard Â deviations Â wereÂ allÂ lessÂ thanÂ 
0.0045.Â 
BasedÂ onÂ theÂ optimalÂ fittingÂ degreeÂ andÂ theÂ deviation Â degreeÂ fromÂ theÂ medianÂ ofÂ theÂ 
forecasting Â errorÂ valueÂ asÂ theÂ judgment Â criteriaÂ forÂ selecting Â theÂ bestÂ model,Â weÂ choseÂ theÂ 
optimalÂ modelsÂ amongÂ theÂ threeÂ rivalÂ modelsÂ toÂ makeÂ forecasting Â underÂ twoÂ different Â 
sampleÂ capacityÂ sizes.Â TheÂ forecasting Â resultsÂ ofÂ fourÂ competitive Â modelsÂ areÂ shownÂ inÂ 
TablesÂ 6Â andÂ 7.Â 
Â 
FigureÂ 8.Â MAEÂ valuesÂ ofÂ theÂ rivalÂ modelsÂ (RNN,Â GRU,Â LSTM).Â 
Figure 8. MAE values of the rival models (RNN, GRU, LSTM).
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 14 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  14Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 9.Â Râ€squaredÂ valuesÂ ofÂ theÂ rivalÂ modelsÂ (RNN,Â GRU,Â LSTM).Â 
InÂ theÂ GroupÂ AÂ dataset,Â asÂ shownÂ inÂ TableÂ 6,Â theÂ proposed Â SLSTMâ€MLPÂ modelÂ 
showedÂ theÂ bestÂ performance, Â followed Â byÂ theÂ RNNÂ model,Â andÂ theÂ GRUÂ modelÂ showedÂ 
theÂ worstÂ performance. Â TheÂ interesting Â thingÂ isÂ thatÂ theÂ stackedÂ LSTMÂ modelÂ performed Â 
betterÂ thanÂ theÂ singleâ€layerÂ LSTMÂ model.Â InÂ detail,Â theÂ MAEÂ valueÂ ofÂ theÂ proposed Â modelÂ 
fellÂ byÂ aboutÂ 15.41%,Â 43.58%,Â andÂ 19.7%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respecâ€
tively.Â TheÂ MSEÂ valueÂ ofÂ theÂ proposed Â modelÂ fellÂ byÂ aboutÂ 31.86%,Â 68.11%,Â andÂ 49.62%Â 
compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â TheÂ fittingÂ degreeÂ ofÂ theÂ proposed Â 
modelÂ increased Â byÂ 6.73%,Â 40.54%,Â andÂ 15.34%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â reâ€
spectively. Â TheÂ detailedÂ forecasting Â resultsÂ ofÂ allÂ comparative Â modelsÂ areÂ presented Â inÂ FigureÂ 
10,Â andÂ theÂ corresponding Â forecasting Â residuals Â areÂ shownÂ inÂ FigureÂ 11.Â TheÂ predicted Â 
valuesÂ deviateÂ aÂ littleÂ fromÂ theÂ observed Â value,Â especially Â aroundÂ theÂ 4thÂ andÂ 25thÂ timeÂ 
points.Â 
TableÂ 6.Â Performance Â indexesÂ ofÂ different Â modelsÂ underÂ GroupÂ AÂ dataset.Â 
ModelÂ GroupÂ AÂ DatasetÂ 
MAEÂ  MSEÂ  R2Â 
RNNÂ  0.063578Â  0.006382Â  0.825424Â 
GRUÂ  0.095320Â  0.013639Â  0.626888Â 
LSTMÂ  0.066969Â  0.008633Â  0.763823Â 
SLSTMâ€MLPÂ  0.053779Â  0.004349Â  0.881015Â 
Â 
FigureÂ 10.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ forÂ different Â modelsÂ inÂ GroupÂ AÂ dataset.Â 
Figure 9. R-squared values of the rival models (RNN, GRU, LSTM).
Table 6. Performance indexes of different models under Group A dataset.
ModelGroup A Dataset
MAE MSE R2
RNN 0.063578 0.006382 0.825424
GRU 0.095320 0.013639 0.626888
LSTM 0.066969 0.008633 0.763823
SLSTM-MLP 0.053779 0.004349 0.881015
Table 7. Performance indexes of different models under Group B dataset.
ModelGroup B Dataset
MAE MSE R2
RNN 0.087615 0.009981 0.971486
GRU 0.058759 0.006037 0.982650
LSTM 0.060581 0.006630 0.981058
SLSTM-MLP 0.059514 0.005353 0.984708
In the Group A dataset, as shown in Table 6, the proposed SLSTM-MLP model showed
the best performance, followed by the RNN model, and the GRU model showed the worst
performance. The interesting thing is that the stacked LSTM model performed better than
the single-layer LSTM model. In detail, the MAE value of the proposed model fell by about
15.41%, 43.58%, and 19.7% compared with RNN, GRU, and LSTM, respectively. The MSE
value of the proposed model fell by about 31.86%, 68.11%, and 49.62% compared with
RNN, GRU, and LSTM, respectively. The ï¬tting degree of the proposed model increased
by 6.73%, 40.54%, and 15.34% compared with RNN, GRU, and LSTM, respectively. The
detailed forecasting results of all comparative models are presented in Figure 10, and the
corresponding forecasting residuals are shown in Figure 11. The predicted values deviate a
little from the observed value, especially around the 4th and 25th time points.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 15 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  14Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 9.Â Râ€squaredÂ valuesÂ ofÂ theÂ rivalÂ modelsÂ (RNN,Â GRU,Â LSTM).Â 
InÂ theÂ GroupÂ AÂ dataset,Â asÂ shownÂ inÂ TableÂ 6,Â theÂ proposed Â SLSTMâ€MLPÂ modelÂ 
showedÂ theÂ bestÂ performance, Â followed Â byÂ theÂ RNNÂ model,Â andÂ theÂ GRUÂ modelÂ showedÂ 
theÂ worstÂ performance. Â TheÂ interesting Â thingÂ isÂ thatÂ theÂ stackedÂ LSTMÂ modelÂ performed Â 
betterÂ thanÂ theÂ singleâ€layerÂ LSTMÂ model.Â InÂ detail,Â theÂ MAEÂ valueÂ ofÂ theÂ proposed Â modelÂ 
fellÂ byÂ aboutÂ 15.41%,Â 43.58%,Â andÂ 19.7%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respecâ€
tively.Â TheÂ MSEÂ valueÂ ofÂ theÂ proposed Â modelÂ fellÂ byÂ aboutÂ 31.86%,Â 68.11%,Â andÂ 49.62%Â 
compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â TheÂ fittingÂ degreeÂ ofÂ theÂ proposed Â 
modelÂ increased Â byÂ 6.73%,Â 40.54%,Â andÂ 15.34%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â reâ€
spectively. Â TheÂ detailedÂ forecasting Â resultsÂ ofÂ allÂ comparative Â modelsÂ areÂ presented Â inÂ FigureÂ 
10,Â andÂ theÂ corresponding Â forecasting Â residuals Â areÂ shownÂ inÂ FigureÂ 11.Â TheÂ predicted Â 
valuesÂ deviateÂ aÂ littleÂ fromÂ theÂ observed Â value,Â especially Â aroundÂ theÂ 4thÂ andÂ 25thÂ timeÂ 
points.Â 
TableÂ 6.Â Performance Â indexesÂ ofÂ different Â modelsÂ underÂ GroupÂ AÂ dataset.Â 
ModelÂ GroupÂ AÂ DatasetÂ 
MAEÂ  MSEÂ  R2Â 
RNNÂ  0.063578Â  0.006382Â  0.825424Â 
GRUÂ  0.095320Â  0.013639Â  0.626888Â 
LSTMÂ  0.066969Â  0.008633Â  0.763823Â 
SLSTMâ€MLPÂ  0.053779Â  0.004349Â  0.881015Â 
Â 
FigureÂ 10.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ forÂ different Â modelsÂ inÂ GroupÂ AÂ dataset.Â 
Figure 10. Main bearing temperature forecasting results for different models in Group A dataset.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  15Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 11.Â Forecasting Â residualÂ ofÂ different Â modelsÂ inÂ GroupÂ AÂ dataset.Â 
InÂ theÂ GroupÂ BÂ dataset,Â asÂ shownÂ inÂ TableÂ 7,Â theÂ proposed Â SLSTMâ€MLPÂ modelÂ 
showedÂ theÂ bestÂ performance, Â followed Â byÂ theÂ GRUÂ andÂ LSTMÂ model.Â Meanwhile, Â theÂ 
RNNÂ modelÂ showedÂ theÂ worstÂ performance. Â InÂ detail,Â theÂ MAEÂ ofÂ theÂ proposed Â modelÂ 
fellÂ byÂ aboutÂ 32.07%,Â â€1.29%,Â andÂ 1.76%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respecâ€
tively.Â TheÂ MSEÂ ofÂ theÂ proposed Â modelÂ fellÂ byÂ aboutÂ 46.37%,Â 11.33%,Â andÂ 19.26%Â comâ€
paredÂ withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â TheÂ fittingÂ degreeÂ ofÂ theÂ proposed Â modelÂ 
increased Â byÂ aboutÂ 1.34%,Â 0.21%,Â andÂ 0.37%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â reâ€
spectively. Â TheÂ detailedÂ forecasting Â resultsÂ ofÂ allÂ comparative Â modelsÂ areÂ presented Â inÂ Figâ€
ureÂ 12,Â andÂ theÂ corresponding Â forecasting Â residuals Â areÂ shownÂ inÂ FigureÂ 13.Â 
TableÂ 7.Â Performance Â indexesÂ ofÂ different Â modelsÂ underÂ GroupÂ BÂ dataset.Â 
ModelÂ GroupÂ BÂ DatasetÂ 
MAEÂ  MSEÂ  R2Â 
RNNÂ  0.087615Â  0.009981Â  0.971486Â 
GRUÂ  0.058759Â  0.006037Â  0.982650Â 
LSTMÂ  0.060581Â  0.006630Â  0.981058Â 
SLSTMâ€MLPÂ  0.059514Â  0.005353Â  0.984708Â 
Â 
FigureÂ 12.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ forÂ different Â modelsÂ inÂ GroupÂ BÂ dataset.Â 
Â 
FigureÂ 13.Â Forecasting Â residuals Â ofÂ different Â modelsÂ inÂ GroupÂ BÂ dataset.Â 
Figure 11. Forecasting residual of different models in Group A dataset.
In the Group B dataset, as shown in Table 7, the proposed SLSTM-MLP model showed
the best performance, followed by the GRU and LSTM model. Meanwhile, the RNN model
showed the worst performance. In detail, the MAE of the proposed model fell by about
32.07%, -1.29%, and 1.76% compared with RNN, GRU, and LSTM, respectively. The MSE
of the proposed model fell by about 46.37%, 11.33%, and 19.26% compared with RNN,
GRU, and LSTM, respectively. The ï¬tting degree of the proposed model increased by
about 1.34%, 0.21%, and 0.37% compared with RNN, GRU, and LSTM, respectively. The
detailed forecasting results of all comparative models are presented in Figure 12, and the
corresponding forecasting residuals are shown in Figure 13.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  15Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 11.Â Forecasting Â residualÂ ofÂ different Â modelsÂ inÂ GroupÂ AÂ dataset.Â 
InÂ theÂ GroupÂ BÂ dataset,Â asÂ shownÂ inÂ TableÂ 7,Â theÂ proposed Â SLSTMâ€MLPÂ modelÂ 
showedÂ theÂ bestÂ performance, Â followed Â byÂ theÂ GRUÂ andÂ LSTMÂ model.Â Meanwhile, Â theÂ 
RNNÂ modelÂ showedÂ theÂ worstÂ performance. Â InÂ detail,Â theÂ MAEÂ ofÂ theÂ proposed Â modelÂ 
fellÂ byÂ aboutÂ 32.07%,Â â€1.29%,Â andÂ 1.76%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respecâ€
tively.Â TheÂ MSEÂ ofÂ theÂ proposed Â modelÂ fellÂ byÂ aboutÂ 46.37%,Â 11.33%,Â andÂ 19.26%Â comâ€
paredÂ withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â TheÂ fittingÂ degreeÂ ofÂ theÂ proposed Â modelÂ 
increased Â byÂ aboutÂ 1.34%,Â 0.21%,Â andÂ 0.37%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â reâ€
spectively. Â TheÂ detailedÂ forecasting Â resultsÂ ofÂ allÂ comparative Â modelsÂ areÂ presented Â inÂ Figâ€
ureÂ 12,Â andÂ theÂ corresponding Â forecasting Â residuals Â areÂ shownÂ inÂ FigureÂ 13.Â 
TableÂ 7.Â Performance Â indexesÂ ofÂ different Â modelsÂ underÂ GroupÂ BÂ dataset.Â 
ModelÂ GroupÂ BÂ DatasetÂ 
MAEÂ  MSEÂ  R2Â 
RNNÂ  0.087615Â  0.009981Â  0.971486Â 
GRUÂ  0.058759Â  0.006037Â  0.982650Â 
LSTMÂ  0.060581Â  0.006630Â  0.981058Â 
SLSTMâ€MLPÂ  0.059514Â  0.005353Â  0.984708Â 
Â 
FigureÂ 12.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ forÂ different Â modelsÂ inÂ GroupÂ BÂ dataset.Â 
Â 
FigureÂ 13.Â Forecasting Â residuals Â ofÂ different Â modelsÂ inÂ GroupÂ BÂ dataset.Â 
Figure 12. Main bearing temperature forecasting results for different models in Group B dataset.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 16 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  15Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 11.Â Forecasting Â residualÂ ofÂ different Â modelsÂ inÂ GroupÂ AÂ dataset.Â 
InÂ theÂ GroupÂ BÂ dataset,Â asÂ shownÂ inÂ TableÂ 7,Â theÂ proposed Â SLSTMâ€MLPÂ modelÂ 
showedÂ theÂ bestÂ performance, Â followed Â byÂ theÂ GRUÂ andÂ LSTMÂ model.Â Meanwhile, Â theÂ 
RNNÂ modelÂ showedÂ theÂ worstÂ performance. Â InÂ detail,Â theÂ MAEÂ ofÂ theÂ proposed Â modelÂ 
fellÂ byÂ aboutÂ 32.07%,Â â€1.29%,Â andÂ 1.76%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respecâ€
tively.Â TheÂ MSEÂ ofÂ theÂ proposed Â modelÂ fellÂ byÂ aboutÂ 46.37%,Â 11.33%,Â andÂ 19.26%Â comâ€
paredÂ withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â TheÂ fittingÂ degreeÂ ofÂ theÂ proposed Â modelÂ 
increased Â byÂ aboutÂ 1.34%,Â 0.21%,Â andÂ 0.37%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â reâ€
spectively. Â TheÂ detailedÂ forecasting Â resultsÂ ofÂ allÂ comparative Â modelsÂ areÂ presented Â inÂ Figâ€
ureÂ 12,Â andÂ theÂ corresponding Â forecasting Â residuals Â areÂ shownÂ inÂ FigureÂ 13.Â 
TableÂ 7.Â Performance Â indexesÂ ofÂ different Â modelsÂ underÂ GroupÂ BÂ dataset.Â 
ModelÂ GroupÂ BÂ DatasetÂ 
MAEÂ  MSEÂ  R2Â 
RNNÂ  0.087615Â  0.009981Â  0.971486Â 
GRUÂ  0.058759Â  0.006037Â  0.982650Â 
LSTMÂ  0.060581Â  0.006630Â  0.981058Â 
SLSTMâ€MLPÂ  0.059514Â  0.005353Â  0.984708Â 
Â 
FigureÂ 12.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ forÂ different Â modelsÂ inÂ GroupÂ BÂ dataset.Â 
Â 
FigureÂ 13.Â Forecasting Â residuals Â ofÂ different Â modelsÂ inÂ GroupÂ BÂ dataset.Â 
Figure 13. Forecasting residuals of different models in Group B dataset.
4.2. Different Sampling Time Segments
In this section, we randomly selected another dataset of the SCADA system from the
same target wind turbine to conduct the experiment. The detailed forecasting results are
presented in Table 8 and Figure 14, and the corresponding forecasting residuals are shown
in Figure 15. The proposed SLSTM-MLP model showed the best performance, followed by
the GRU and RNN models. Meanwhile, the single-layer LSTM model showed the worst
performance. In detail, the MAE of the proposed model fell by about 47.33%, 21.35%, and
42.12% compared with RNN, GRU, and LSTM, respectively. The MSE of the proposed
model fell by about 63.5%, 38.66%, and 65.5% compared with RNN, GRU, and LSTM,
respectively. The ï¬tting degree of the proposed model increased by about 1.57%, 0.56%,
and 1.72% compared with RNN, GRU, and LSTM, respectively. As seen from Figure 14,
although the prediction residual deviation of the proposed model was large in the ï¬rst
40 time points, it was near zero in the following 80 time points. Except for the SLSTM-MLP
model, the prediction residual deviations of the other models were large.
Table 8. Performance indexes of different models under different sampling time segments.
Model MAE MSE R2
RNN 0.305746 0.112334 0.975805
GRU 0.204768 0.066844 0.985603
LSTM 0.278253 0.118830 0.974406
SLSTM-MLP 0.161051 0.041001 0.991169
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  16Â ofÂ 22Â 
Â 
Â 4.2.Â DifferentÂ Sampling Â TimeÂ Segments Â 
InÂ thisÂ section,Â weÂ randomly Â selectedÂ anotherÂ datasetÂ ofÂ theÂ SCADAÂ systemÂ fromÂ theÂ 
sameÂ targetÂ windÂ turbineÂ toÂ conductÂ theÂ experiment. Â TheÂ detailedÂ forecasting Â resultsÂ areÂ 
presented Â inÂ TableÂ 8Â andÂ FigureÂ 14,Â andÂ theÂ corresponding Â forecasting Â residuals Â areÂ shownÂ 
inÂ FigureÂ 15.Â TheÂ proposed Â SLSTMâ€MLPÂ modelÂ showedÂ theÂ bestÂ performance, Â followed Â 
byÂ theÂ GRUÂ andÂ RNNÂ models.Â Meanwhile, Â theÂ singleâ€layerÂ LSTMÂ modelÂ showedÂ theÂ 
worstÂ performance. Â InÂ detail,Â theÂ MAEÂ ofÂ theÂ proposed Â modelÂ fellÂ byÂ aboutÂ 47.33%,Â 
21.35%,Â andÂ 42.12%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â TheÂ MSEÂ ofÂ theÂ 
proposed Â modelÂ fellÂ byÂ aboutÂ 63.5%,Â 38.66%,Â andÂ 65.5%Â compared Â withÂ RNN,Â GRU,Â andÂ 
LSTM,Â respectively. Â TheÂ fittingÂ degreeÂ ofÂ theÂ proposed Â modelÂ increased Â byÂ aboutÂ 1.57%,Â 
0.56%,Â andÂ 1.72%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â AsÂ seenÂ fromÂ Figâ€
ureÂ 14,Â although Â theÂ prediction Â residualÂ deviation Â ofÂ theÂ proposed Â modelÂ wasÂ largeÂ inÂ theÂ 
firstÂ 40Â timeÂ points,Â itÂ wasÂ nearÂ zeroÂ inÂ theÂ following Â 80Â timeÂ points.Â ExceptÂ forÂ theÂ SLSTMâ€
MLPÂ model,Â theÂ prediction Â residualÂ deviations Â ofÂ theÂ otherÂ modelsÂ wereÂ large.Â 
TableÂ 8.Â Performance Â indexesÂ ofÂ different Â modelsÂ underÂ different Â sampling Â timeÂ segments. Â 
ModelÂ  MAEÂ  MSEÂ  R2Â 
RNNÂ  0.305746Â  0.112334Â  0.975805Â 
GRUÂ  0.204768Â  0.066844Â  0.985603Â 
LSTMÂ  0.278253Â  0.118830Â  0.974406Â 
SLSTMâ€MLPÂ  0.161051Â  0.041001Â  0.991169Â 
Â 
FigureÂ 14.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ inÂ different Â sampling Â timeÂ segments. Â 
Â 
FigureÂ 15.Â Forecasting Â residuals Â ofÂ different Â modelsÂ inÂ different Â sampling Â timeÂ segments. Â 
4.3.Â DifferentÂ Sampling Â Frequencies Â 
According Â toÂ theÂ different Â sampling Â frequencies Â commonly Â usedÂ byÂ WTÂ SCADAÂ sysâ€
tems,Â weÂ reâ€collected Â 1Â min,Â 2Â min,Â andÂ 10Â minÂ datasetsÂ forÂ testing.Â TheÂ detailedÂ forecastâ€
ingÂ resultsÂ areÂ presented Â inÂ TableÂ 9.Â TheÂ predicted Â value,Â actualÂ value,Â andÂ corresponding Â 
forecasting Â residuals Â areÂ shownÂ inÂ FiguresÂ 16â€“21.Â TheÂ proposed Â modelÂ showedÂ theÂ bestÂ 
performance Â atÂ 1Â minÂ andÂ 2Â minÂ sampling Â frequencies. Â InÂ detail,Â theÂ MAEÂ ofÂ theÂ proposed Â 
Figure 14. Main bearing temperature forecasting results in different sampling time segments.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 17 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  16Â ofÂ 22Â 
Â 
Â 4.2.Â DifferentÂ Sampling Â TimeÂ Segments Â 
InÂ thisÂ section,Â weÂ randomly Â selectedÂ anotherÂ datasetÂ ofÂ theÂ SCADAÂ systemÂ fromÂ theÂ 
sameÂ targetÂ windÂ turbineÂ toÂ conductÂ theÂ experiment. Â TheÂ detailedÂ forecasting Â resultsÂ areÂ 
presented Â inÂ TableÂ 8Â andÂ FigureÂ 14,Â andÂ theÂ corresponding Â forecasting Â residuals Â areÂ shownÂ 
inÂ FigureÂ 15.Â TheÂ proposed Â SLSTMâ€MLPÂ modelÂ showedÂ theÂ bestÂ performance, Â followed Â 
byÂ theÂ GRUÂ andÂ RNNÂ models.Â Meanwhile, Â theÂ singleâ€layerÂ LSTMÂ modelÂ showedÂ theÂ 
worstÂ performance. Â InÂ detail,Â theÂ MAEÂ ofÂ theÂ proposed Â modelÂ fellÂ byÂ aboutÂ 47.33%,Â 
21.35%,Â andÂ 42.12%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â TheÂ MSEÂ ofÂ theÂ 
proposed Â modelÂ fellÂ byÂ aboutÂ 63.5%,Â 38.66%,Â andÂ 65.5%Â compared Â withÂ RNN,Â GRU,Â andÂ 
LSTM,Â respectively. Â TheÂ fittingÂ degreeÂ ofÂ theÂ proposed Â modelÂ increased Â byÂ aboutÂ 1.57%,Â 
0.56%,Â andÂ 1.72%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â AsÂ seenÂ fromÂ Figâ€
ureÂ 14,Â although Â theÂ prediction Â residualÂ deviation Â ofÂ theÂ proposed Â modelÂ wasÂ largeÂ inÂ theÂ 
firstÂ 40Â timeÂ points,Â itÂ wasÂ nearÂ zeroÂ inÂ theÂ following Â 80Â timeÂ points.Â ExceptÂ forÂ theÂ SLSTMâ€
MLPÂ model,Â theÂ prediction Â residualÂ deviations Â ofÂ theÂ otherÂ modelsÂ wereÂ large.Â 
TableÂ 8.Â Performance Â indexesÂ ofÂ different Â modelsÂ underÂ different Â sampling Â timeÂ segments. Â 
ModelÂ  MAEÂ  MSEÂ  R2Â 
RNNÂ  0.305746Â  0.112334Â  0.975805Â 
GRUÂ  0.204768Â  0.066844Â  0.985603Â 
LSTMÂ  0.278253Â  0.118830Â  0.974406Â 
SLSTMâ€MLPÂ  0.161051Â  0.041001Â  0.991169Â 
Â 
FigureÂ 14.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ inÂ different Â sampling Â timeÂ segments. Â 
Â 
FigureÂ 15.Â Forecasting Â residuals Â ofÂ different Â modelsÂ inÂ different Â sampling Â timeÂ segments. Â 
4.3.Â DifferentÂ Sampling Â Frequencies Â 
According Â toÂ theÂ different Â sampling Â frequencies Â commonly Â usedÂ byÂ WTÂ SCADAÂ sysâ€
tems,Â weÂ reâ€collected Â 1Â min,Â 2Â min,Â andÂ 10Â minÂ datasetsÂ forÂ testing.Â TheÂ detailedÂ forecastâ€
ingÂ resultsÂ areÂ presented Â inÂ TableÂ 9.Â TheÂ predicted Â value,Â actualÂ value,Â andÂ corresponding Â 
forecasting Â residuals Â areÂ shownÂ inÂ FiguresÂ 16â€“21.Â TheÂ proposed Â modelÂ showedÂ theÂ bestÂ 
performance Â atÂ 1Â minÂ andÂ 2Â minÂ sampling Â frequencies. Â InÂ detail,Â theÂ MAEÂ ofÂ theÂ proposed Â 
Figure 15. Forecasting residuals of different models in different sampling time segments.
4.3. Different Sampling Frequencies
According to the different sampling frequencies commonly used by WT SCADA sys-
tems, we re-collected 1 min, 2 min, and 10 min datasets for testing. The detailed forecasting
results are presented in Table 9. The predicted value, actual value, and corresponding
forecasting residuals are shown in Figures 16â€“21. The proposed model showed the best
performance at 1 min and 2 min sampling frequencies. In detail, the MAE of the proposed
model fell by about 17.73%, 43.67%, and 0.85% compared with RNN, GRU, and LSTM,
respectively. The MSE of the proposed model fell by about 41.91%, 68.35%, and 7.02%
compared with RNN, GRU, and LSTM, respectively. The ï¬tting degree of the proposed
model increased by about 9.09%, 33.22%, and 0.09% compared with RNN, GRU, and LSTM,
respectively. A similar situation occurred at the 2 min sampling frequency. At the 10 min
sampling frequency, the proposed model was slightly inferior to the RNN and LSTM
models, but better than the GRU model. In terms of ï¬tting goodness, the proposed model
achieved 99.53%, which is close to the other two better models and is completely acceptable
in engineering practices. As can be seen from Figures 16â€“21, except for the 10 min sampling
frequency, the curve ï¬tting trend was consistent with the trend of the observed value,
and the corresponding residual ï¬‚uctuation was also very small. The proposed model still
showed obvious advantages in temperature prediction.
Table 9. Performance indexes of different models at different sampling frequencies.
ModelOne-Minute Two-Minute Ten-Minute
MAE MSE R2MAE MSE R2MAE MSE R2
RNN 0.096849 0.014094 0.821813 0.061238 0.006107 0.933758 0.133430 0.026577 0.995714
GRU 0.141453 0.025870 0.672942 0.189985 0.041294 0.552073 0.159391 0.032778 0.994714
LSTM 0.080363 0.008805 0.888687 0.062779 0.005874 0.936288 0.108897 0.016822 0.997287
SLSTM-MLP 0.079680 0.008187 0.896494 0.064828 0.005776 0.937348 0.144943 0.029054 0.995314
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  17Â ofÂ 22Â 
Â 
Â modelÂ fellÂ byÂ aboutÂ 17.73%,Â 43.67%,Â andÂ 0.85%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â 
respectively. Â TheÂ MSEÂ ofÂ theÂ proposed Â modelÂ fellÂ byÂ aboutÂ 41.91%,Â 68.35%,Â andÂ 7.02%Â 
compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â TheÂ fittingÂ degreeÂ ofÂ theÂ proposed Â 
modelÂ increased Â byÂ aboutÂ 9.09%,Â 33.22%,Â andÂ 0.09%Â compared Â withÂ RNN,Â GRU,Â andÂ 
LSTM,Â respectively. Â AÂ similarÂ situation Â occurred Â atÂ theÂ 2Â minÂ sampling Â frequency. Â AtÂ theÂ 
10Â minÂ sampling Â frequency, Â theÂ proposed Â modelÂ wasÂ slightlyÂ inferiorÂ toÂ theÂ RNNÂ andÂ 
LSTMÂ models,Â butÂ betterÂ thanÂ theÂ GRUÂ model.Â InÂ termsÂ ofÂ fittingÂ goodness, Â theÂ proposed Â 
modelÂ achieved Â 99.53%,Â whichÂ isÂ closeÂ toÂ theÂ otherÂ twoÂ betterÂ modelsÂ andÂ isÂ completely Â 
acceptable Â inÂ engineering Â practices. Â AsÂ canÂ beÂ seenÂ fromÂ FiguresÂ 16â€“21,Â exceptÂ forÂ theÂ 10Â 
minÂ sampling Â frequency, Â theÂ curveÂ fittingÂ trendÂ wasÂ consistent Â withÂ theÂ trendÂ ofÂ theÂ obâ€
servedÂ value,Â andÂ theÂ corresponding Â residualÂ fluctuation Â wasÂ alsoÂ veryÂ small.Â TheÂ proâ€
posedÂ modelÂ stillÂ showedÂ obviousÂ advantages Â inÂ temperature Â prediction. Â 
TableÂ 9.Â Performance Â indexesÂ ofÂ different Â modelsÂ atÂ different Â sampling Â frequencies. Â 
ModelÂ Oneâ€minuteÂ  Twoâ€minuteÂ  Tenâ€minuteÂ 
MAEÂ  MSEÂ  R2Â  MAEÂ  MSEÂ  R2Â  MAEÂ  MSEÂ  R2Â 
RNNÂ  0.096849Â 0.014094Â 0.821813Â 0.061238Â 0.006107Â 0.933758Â 0.133430Â 0.026577Â 0.995714Â 
GRUÂ  0.141453Â 0.025870Â 0.672942Â 0.189985Â 0.041294Â 0.552073Â 0.159391Â 0.032778Â 0.994714Â 
LSTMÂ  0.080363Â 0.008805Â 0.888687Â 0.062779Â 0.005874Â 0.936288Â 0.108897Â 0.016822Â 0.997287Â 
SLSTMâ€MLPÂ 0.079680Â 0.008187Â 0.896494Â 0.064828Â 0.005776Â 0.937348Â 0.144943Â 0.029054Â 0.995314Â 
Â 
FigureÂ 16.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 1Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 17.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 1Â minÂ sampling Â frequency. Â 
Figure 16. Main bearing temperature forecasting results at 1 min sampling frequency.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 18 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  17Â ofÂ 22Â 
Â 
Â modelÂ fellÂ byÂ aboutÂ 17.73%,Â 43.67%,Â andÂ 0.85%Â compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â 
respectively. Â TheÂ MSEÂ ofÂ theÂ proposed Â modelÂ fellÂ byÂ aboutÂ 41.91%,Â 68.35%,Â andÂ 7.02%Â 
compared Â withÂ RNN,Â GRU,Â andÂ LSTM,Â respectively. Â TheÂ fittingÂ degreeÂ ofÂ theÂ proposed Â 
modelÂ increased Â byÂ aboutÂ 9.09%,Â 33.22%,Â andÂ 0.09%Â compared Â withÂ RNN,Â GRU,Â andÂ 
LSTM,Â respectively. Â AÂ similarÂ situation Â occurred Â atÂ theÂ 2Â minÂ sampling Â frequency. Â AtÂ theÂ 
10Â minÂ sampling Â frequency, Â theÂ proposed Â modelÂ wasÂ slightlyÂ inferiorÂ toÂ theÂ RNNÂ andÂ 
LSTMÂ models,Â butÂ betterÂ thanÂ theÂ GRUÂ model.Â InÂ termsÂ ofÂ fittingÂ goodness, Â theÂ proposed Â 
modelÂ achieved Â 99.53%,Â whichÂ isÂ closeÂ toÂ theÂ otherÂ twoÂ betterÂ modelsÂ andÂ isÂ completely Â 
acceptable Â inÂ engineering Â practices. Â AsÂ canÂ beÂ seenÂ fromÂ FiguresÂ 16â€“21,Â exceptÂ forÂ theÂ 10Â 
minÂ sampling Â frequency, Â theÂ curveÂ fittingÂ trendÂ wasÂ consistent Â withÂ theÂ trendÂ ofÂ theÂ obâ€
servedÂ value,Â andÂ theÂ corresponding Â residualÂ fluctuation Â wasÂ alsoÂ veryÂ small.Â TheÂ proâ€
posedÂ modelÂ stillÂ showedÂ obviousÂ advantages Â inÂ temperature Â prediction. Â 
TableÂ 9.Â Performance Â indexesÂ ofÂ different Â modelsÂ atÂ different Â sampling Â frequencies. Â 
ModelÂ Oneâ€minuteÂ  Twoâ€minuteÂ  Tenâ€minuteÂ 
MAEÂ  MSEÂ  R2Â  MAEÂ  MSEÂ  R2Â  MAEÂ  MSEÂ  R2Â 
RNNÂ  0.096849Â 0.014094Â 0.821813Â 0.061238Â 0.006107Â 0.933758Â 0.133430Â 0.026577Â 0.995714Â 
GRUÂ  0.141453Â 0.025870Â 0.672942Â 0.189985Â 0.041294Â 0.552073Â 0.159391Â 0.032778Â 0.994714Â 
LSTMÂ  0.080363Â 0.008805Â 0.888687Â 0.062779Â 0.005874Â 0.936288Â 0.108897Â 0.016822Â 0.997287Â 
SLSTMâ€MLPÂ 0.079680Â 0.008187Â 0.896494Â 0.064828Â 0.005776Â 0.937348Â 0.144943Â 0.029054Â 0.995314Â 
Â 
FigureÂ 16.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 1Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 17.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 1Â minÂ sampling Â frequency. Â 
Figure 17. Forecasting residual of different models at 1 min sampling frequency.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  18Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 18.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 2Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 19.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 2Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 20.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 10Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 21.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 10Â minÂ sampling Â frequency. Â 
5.Â MainÂ BearingÂ Operating Â Condition Â Monitoring Â 
InÂ thisÂ section,Â weÂ firstÂ putÂ forwardÂ aÂ framework Â forÂ onlineÂ operating Â condition Â monâ€
itoringÂ andÂ abnormal Â detection Â ofÂ largeâ€scaleÂ WTÂ mainÂ bearing.Â Then,Â weÂ simulate Â twoÂ 
different Â degreeÂ faultsÂ byÂ addingÂ twoÂ cumulative Â temperature Â offsetsÂ toÂ twoÂ associated Â 
variables Â basedÂ onÂ greyÂ correlation Â theoryÂ andÂ kernelÂ densityÂ calculation Â methods. Â 
Â  Â 
Figure 18. Main bearing temperature forecasting results at 2 min sampling frequency.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  18Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 18.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 2Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 19.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 2Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 20.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 10Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 21.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 10Â minÂ sampling Â frequency. Â 
5.Â MainÂ BearingÂ Operating Â Condition Â Monitoring Â 
InÂ thisÂ section,Â weÂ firstÂ putÂ forwardÂ aÂ framework Â forÂ onlineÂ operating Â condition Â monâ€
itoringÂ andÂ abnormal Â detection Â ofÂ largeâ€scaleÂ WTÂ mainÂ bearing.Â Then,Â weÂ simulate Â twoÂ 
different Â degreeÂ faultsÂ byÂ addingÂ twoÂ cumulative Â temperature Â offsetsÂ toÂ twoÂ associated Â 
variables Â basedÂ onÂ greyÂ correlation Â theoryÂ andÂ kernelÂ densityÂ calculation Â methods. Â 
Â  Â 
Figure 19. Forecasting residual of different models at 2 min sampling frequency.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  18Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 18.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 2Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 19.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 2Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 20.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 10Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 21.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 10Â minÂ sampling Â frequency. Â 
5.Â MainÂ BearingÂ Operating Â Condition Â Monitoring Â 
InÂ thisÂ section,Â weÂ firstÂ putÂ forwardÂ aÂ framework Â forÂ onlineÂ operating Â condition Â monâ€
itoringÂ andÂ abnormal Â detection Â ofÂ largeâ€scaleÂ WTÂ mainÂ bearing.Â Then,Â weÂ simulate Â twoÂ 
different Â degreeÂ faultsÂ byÂ addingÂ twoÂ cumulative Â temperature Â offsetsÂ toÂ twoÂ associated Â 
variables Â basedÂ onÂ greyÂ correlation Â theoryÂ andÂ kernelÂ densityÂ calculation Â methods. Â 
Â  Â 
Figure 20. Main bearing temperature forecasting results at 10 min sampling frequency.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 19 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  18Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 18.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 2Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 19.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 2Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 20.Â MainÂ bearingÂ temperature Â forecasting Â resultsÂ atÂ 10Â minÂ sampling Â frequency. Â 
Â 
FigureÂ 21.Â Forecasting Â residualÂ ofÂ different Â modelsÂ atÂ 10Â minÂ sampling Â frequency. Â 
5.Â MainÂ BearingÂ Operating Â Condition Â Monitoring Â 
InÂ thisÂ section,Â weÂ firstÂ putÂ forwardÂ aÂ framework Â forÂ onlineÂ operating Â condition Â monâ€
itoringÂ andÂ abnormal Â detection Â ofÂ largeâ€scaleÂ WTÂ mainÂ bearing.Â Then,Â weÂ simulate Â twoÂ 
different Â degreeÂ faultsÂ byÂ addingÂ twoÂ cumulative Â temperature Â offsetsÂ toÂ twoÂ associated Â 
variables Â basedÂ onÂ greyÂ correlation Â theoryÂ andÂ kernelÂ densityÂ calculation Â methods. Â 
Â  Â 
Figure 21. Forecasting residual of different models at 10 min sampling frequency.
5. Main Bearing Operating Condition Monitoring
In this section, we ï¬rst put forward a framework for online operating condition
monitoring and abnormal detection of large-scale WT main bearing. Then, we simulate
two different degree faults by adding two cumulative temperature offsets to two associated
variables based on grey correlation theory and kernel density calculation methods.
5.1. Online Condition Monitoring Process
In order to realize the function of online monitoring of the main bearing operating
condition and abnormal detection of a wind turbine, we needed to deploy the developed
SLSTM-MLP model on the monitored wind turbine. The next steps can provide a reference.
First, we loaded the model; then, we obtained real-time data and preprocessed the data
further; and then, the data was put into the model, and the model output the residuals of
the predicted value and the observed value; and then, the operating condition could be
determined by monitoring the residual variation tendency. During the whole monitoring
process, the program automatically counts the number of residuals exceeding the threshold.
If the number does not reach the set number, the monitoring will continue; otherwise,
an alarm message will be sent to the operation and maintenance personnel for further
processing. The detailed ï¬‚ow diagram for online operating condition monitoring and
abnormal detection of wind turbine main bearing is shown in Figure 22.
In Figure 22, Imb is the main bearing index, which is actually the difference between
the predicted value of the model and the measured value in the monitoring process. The
threshold is the critical value of the residual, which refers to the lowest or highest value
of the residual. The threshold needs to be determined according to the statistical process
control (SPC) method.
5.2. Abnormal Operating Condition Monitoring and Detection
Since the direct-driven WT studied had no main bearing failure, in order to verify
the effectiveness of the proposed method, we referred to the fault simulation method of
the literature [ 31,32]. In order to more realistically simulate a fault, we considered the
generator stator component because it is closely connected with the main bearing, and
the rise of the main bearing temperature will inevitably lead to the rise of the generator
stator temperature. The current temperature values of the two components are correlated
with their historical temperature values. According to the grey correlation theory, we can
calculate the grey correlation degree of different historical data of main bearing temperature
and generator stator temperature and then use the kernel density estimation to get its grey
correlation degree value. Through experimental calculation, we got a grey correlation
degree value of 0.6772. Then, starting from the 121st point of the selected normal SCADA
data, we manually added 360 cumulative temperature offset values of 0.005 and 0.008 to
the main bearing temperature variable and generator stator temperature variable one by
one to simulate the two states of minor and serious overheating faults of the main bearing.
The model prediction results and its prediction residuals for minor faults are shown in
Figures 23 and 24, respectively, and results for serious faults are shown in Figures 25 and 26,
respectively. Of course, the setting of minor failure and serious failure depends on the
actual situation, and the setting in this paper is only experimental veriï¬cation from two
different aspects.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 20 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  19Â ofÂ 22Â 
Â 
Â 5.1.Â OnlineÂ Condition Â Monitoring Â ProcessÂ 
InÂ orderÂ toÂ realizeÂ theÂ functionÂ ofÂ onlineÂ monitoring Â ofÂ theÂ mainÂ bearingÂ operating Â 
condition Â andÂ abnormal Â detection Â ofÂ aÂ windÂ turbine,Â weÂ neededÂ toÂ deployÂ theÂ developed Â 
SLSTMâ€MLPÂ modelÂ onÂ theÂ monitored Â windÂ turbine.Â TheÂ nextÂ stepsÂ canÂ provideÂ aÂ referâ€
ence.Â First,Â weÂ loadedÂ theÂ model;Â then,Â weÂ obtained Â realâ€timeÂ dataÂ andÂ preprocessed Â theÂ 
dataÂ further;Â andÂ then,Â theÂ dataÂ wasÂ putÂ intoÂ theÂ model,Â andÂ theÂ modelÂ outputÂ theÂ residuâ€
alsÂ ofÂ theÂ predicted Â valueÂ andÂ theÂ observed Â value;Â andÂ then,Â theÂ operating Â condition Â couldÂ 
beÂ determined Â byÂ monitoring Â theÂ residualÂ variation Â tendency. Â DuringÂ theÂ wholeÂ monitorâ€
ingÂ process,Â theÂ program Â automatically Â countsÂ theÂ numberÂ ofÂ residuals Â exceeding Â theÂ 
threshold. Â IfÂ theÂ numberÂ doesÂ notÂ reachÂ theÂ setÂ number,Â theÂ monitoring Â willÂ continue; Â 
otherwise, Â anÂ alarmÂ messageÂ willÂ beÂ sentÂ toÂ theÂ operation Â andÂ maintenance Â personnel Â forÂ 
furtherÂ processing. Â TheÂ detailedÂ flowÂ diagramÂ forÂ onlineÂ operating Â condition Â monitoring Â 
andÂ abnormal Â detection Â ofÂ windÂ turbineÂ mainÂ bearingÂ isÂ shownÂ inÂ FigureÂ 22.Â 
InÂ FigureÂ 22,Â ImbÂ isÂ theÂ mainÂ bearingÂ index,Â whichÂ isÂ actuallyÂ theÂ difference Â betweenÂ 
theÂ predicted Â valueÂ ofÂ theÂ modelÂ andÂ theÂ measured Â valueÂ inÂ theÂ monitoring Â process.Â TheÂ 
threshold Â isÂ theÂ criticalÂ valueÂ ofÂ theÂ residual, Â whichÂ refersÂ toÂ theÂ lowestÂ orÂ highestÂ valueÂ 
ofÂ theÂ residual. Â TheÂ threshold Â needsÂ toÂ beÂ determined Â according Â toÂ theÂ statistical Â processÂ 
controlÂ (SPC)Â method.Â 
Â 
FigureÂ 22.Â OnlineÂ operating Â condition Â monitoring Â flowchart Â ofÂ WTÂ mainÂ bearingÂ basedÂ onÂ theÂ proâ€
posedÂ model.Â 
5.2.Â Abnormal Â Operating Â Condition Â Monitoring Â andÂ Detection Â 
SinceÂ theÂ directâ€drivenÂ WTÂ studiedÂ hadÂ noÂ mainÂ bearingÂ failure,Â inÂ orderÂ toÂ verifyÂ theÂ 
effectiveness Â ofÂ theÂ proposed Â method,Â weÂ referredÂ toÂ theÂ faultÂ simulation Â methodÂ ofÂ theÂ 
literature Â [31,32].Â InÂ orderÂ toÂ moreÂ realistically Â simulate Â aÂ fault,Â weÂ considered Â theÂ generâ€
atorÂ statorÂ component Â becauseÂ itÂ isÂ closelyÂ connected Â withÂ theÂ mainÂ bearing,Â andÂ theÂ riseÂ 
ofÂ theÂ mainÂ bearingÂ temperature Â willÂ inevitably Â leadÂ toÂ theÂ riseÂ ofÂ theÂ generator Â statorÂ 
Figure 22. Online operating condition monitoring ï¬‚owchart of WT main bearing based on the
proposed model.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  20Â ofÂ 22Â 
Â 
Â temperature. Â TheÂ currentÂ temperature Â valuesÂ ofÂ theÂ twoÂ components Â areÂ correlated Â withÂ 
theirÂ historical Â temperature Â values.Â According Â toÂ theÂ greyÂ correlation Â theory,Â weÂ canÂ calâ€
culateÂ theÂ greyÂ correlation Â degreeÂ ofÂ different Â historical Â dataÂ ofÂ mainÂ bearingÂ temperature Â 
andÂ generator Â statorÂ temperature Â andÂ thenÂ useÂ theÂ kernelÂ densityÂ estimation Â toÂ getÂ itsÂ greyÂ 
correlation Â degreeÂ value.Â Through Â experimental Â calculation, Â weÂ gotÂ aÂ greyÂ correlation Â deâ€
greeÂ valueÂ ofÂ 0.6772.Â Then,Â startingÂ fromÂ theÂ 121stÂ pointÂ ofÂ theÂ selectedÂ normalÂ SCADAÂ 
data,Â weÂ manually Â addedÂ 360Â cumulative Â temperature Â offsetÂ valuesÂ ofÂ 0.005Â andÂ 0.008Â toÂ 
theÂ mainÂ bearingÂ temperature Â variableÂ andÂ generator Â statorÂ temperature Â variableÂ oneÂ byÂ 
oneÂ toÂ simulateÂ theÂ twoÂ statesÂ ofÂ minorÂ andÂ seriousÂ overheating Â faultsÂ ofÂ theÂ mainÂ bearing.Â 
TheÂ modelÂ prediction Â resultsÂ andÂ itsÂ prediction Â residuals Â forÂ minorÂ faultsÂ areÂ shownÂ inÂ FiguresÂ 
23Â andÂ 24,Â respectively, Â andÂ resultsÂ forÂ seriousÂ faultsÂ areÂ shownÂ inÂ FiguresÂ 25Â andÂ 26,Â reâ€
spectively. Â OfÂ course,Â theÂ settingÂ ofÂ minorÂ failureÂ andÂ seriousÂ failureÂ depends Â onÂ theÂ actualÂ 
situation, Â andÂ theÂ settingÂ inÂ thisÂ paperÂ isÂ onlyÂ experimental Â verification Â fromÂ twoÂ different Â 
aspects.Â 
Â 
FigureÂ 23.Â Predicted Â valuesÂ ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.005.Â 
Â 
FigureÂ 24.Â Predicted Â residuals Â ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.005.Â 
Â 
FigureÂ 25.Â Predicted Â valuesÂ ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.008.Â 
Â  Â 
Figure 23. Predicted values of the proposed model with cumulative temperature offset of 0.005.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  20Â ofÂ 22Â 
Â 
Â temperature. Â TheÂ currentÂ temperature Â valuesÂ ofÂ theÂ twoÂ components Â areÂ correlated Â withÂ 
theirÂ historical Â temperature Â values.Â According Â toÂ theÂ greyÂ correlation Â theory,Â weÂ canÂ calâ€
culateÂ theÂ greyÂ correlation Â degreeÂ ofÂ different Â historical Â dataÂ ofÂ mainÂ bearingÂ temperature Â 
andÂ generator Â statorÂ temperature Â andÂ thenÂ useÂ theÂ kernelÂ densityÂ estimation Â toÂ getÂ itsÂ greyÂ 
correlation Â degreeÂ value.Â Through Â experimental Â calculation, Â weÂ gotÂ aÂ greyÂ correlation Â deâ€
greeÂ valueÂ ofÂ 0.6772.Â Then,Â startingÂ fromÂ theÂ 121stÂ pointÂ ofÂ theÂ selectedÂ normalÂ SCADAÂ 
data,Â weÂ manually Â addedÂ 360Â cumulative Â temperature Â offsetÂ valuesÂ ofÂ 0.005Â andÂ 0.008Â toÂ 
theÂ mainÂ bearingÂ temperature Â variableÂ andÂ generator Â statorÂ temperature Â variableÂ oneÂ byÂ 
oneÂ toÂ simulateÂ theÂ twoÂ statesÂ ofÂ minorÂ andÂ seriousÂ overheating Â faultsÂ ofÂ theÂ mainÂ bearing.Â 
TheÂ modelÂ prediction Â resultsÂ andÂ itsÂ prediction Â residuals Â forÂ minorÂ faultsÂ areÂ shownÂ inÂ FiguresÂ 
23Â andÂ 24,Â respectively, Â andÂ resultsÂ forÂ seriousÂ faultsÂ areÂ shownÂ inÂ FiguresÂ 25Â andÂ 26,Â reâ€
spectively. Â OfÂ course,Â theÂ settingÂ ofÂ minorÂ failureÂ andÂ seriousÂ failureÂ depends Â onÂ theÂ actualÂ 
situation, Â andÂ theÂ settingÂ inÂ thisÂ paperÂ isÂ onlyÂ experimental Â verification Â fromÂ twoÂ different Â 
aspects.Â 
Â 
FigureÂ 23.Â Predicted Â valuesÂ ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.005.Â 
Â 
FigureÂ 24.Â Predicted Â residuals Â ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.005.Â 
Â 
FigureÂ 25.Â Predicted Â valuesÂ ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.008.Â 
Â  Â 
Figure 24. Predicted residuals of the proposed model with cumulative temperature offset of 0.005.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 21 of 23
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  20Â ofÂ 22Â 
Â 
Â temperature. Â TheÂ currentÂ temperature Â valuesÂ ofÂ theÂ twoÂ components Â areÂ correlated Â withÂ 
theirÂ historical Â temperature Â values.Â According Â toÂ theÂ greyÂ correlation Â theory,Â weÂ canÂ calâ€
culateÂ theÂ greyÂ correlation Â degreeÂ ofÂ different Â historical Â dataÂ ofÂ mainÂ bearingÂ temperature Â 
andÂ generator Â statorÂ temperature Â andÂ thenÂ useÂ theÂ kernelÂ densityÂ estimation Â toÂ getÂ itsÂ greyÂ 
correlation Â degreeÂ value.Â Through Â experimental Â calculation, Â weÂ gotÂ aÂ greyÂ correlation Â deâ€
greeÂ valueÂ ofÂ 0.6772.Â Then,Â startingÂ fromÂ theÂ 121stÂ pointÂ ofÂ theÂ selectedÂ normalÂ SCADAÂ 
data,Â weÂ manually Â addedÂ 360Â cumulative Â temperature Â offsetÂ valuesÂ ofÂ 0.005Â andÂ 0.008Â toÂ 
theÂ mainÂ bearingÂ temperature Â variableÂ andÂ generator Â statorÂ temperature Â variableÂ oneÂ byÂ 
oneÂ toÂ simulateÂ theÂ twoÂ statesÂ ofÂ minorÂ andÂ seriousÂ overheating Â faultsÂ ofÂ theÂ mainÂ bearing.Â 
TheÂ modelÂ prediction Â resultsÂ andÂ itsÂ prediction Â residuals Â forÂ minorÂ faultsÂ areÂ shownÂ inÂ FiguresÂ 
23Â andÂ 24,Â respectively, Â andÂ resultsÂ forÂ seriousÂ faultsÂ areÂ shownÂ inÂ FiguresÂ 25Â andÂ 26,Â reâ€
spectively. Â OfÂ course,Â theÂ settingÂ ofÂ minorÂ failureÂ andÂ seriousÂ failureÂ depends Â onÂ theÂ actualÂ 
situation, Â andÂ theÂ settingÂ inÂ thisÂ paperÂ isÂ onlyÂ experimental Â verification Â fromÂ twoÂ different Â 
aspects.Â 
Â 
FigureÂ 23.Â Predicted Â valuesÂ ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.005.Â 
Â 
FigureÂ 24.Â Predicted Â residuals Â ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.005.Â 
Â 
FigureÂ 25.Â Predicted Â valuesÂ ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.008.Â 
Â  Â 
Figure 25. Predicted values of the proposed model with cumulative temperature offset of 0.008.
EnergiesÂ 2022,Â 15,Â xÂ FORÂ PEERÂ REVIEW Â  21Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 26.Â Predicted Â residuals Â ofÂ theÂ proposed Â modelÂ withÂ cumulative Â temperature Â offsetÂ ofÂ 0.008.Â 
WeÂ canÂ seeÂ fromÂ FigureÂ 23Â thatÂ inÂ theÂ faultâ€freeÂ areaÂ AÂ andÂ C,Â theÂ predicted Â valuesÂ 
andÂ observed Â valuesÂ fitÂ well.Â However, Â inÂ theÂ simulated Â minorÂ faultÂ zoneÂ B,Â theÂ predicted Â 
andÂ observed Â valuesÂ beganÂ toÂ showÂ anÂ obviousÂ gapÂ atÂ theÂ 160thÂ point,Â andÂ thisÂ gapÂ inâ€
creasedÂ withÂ time;Â thatÂ isÂ toÂ say,Â theÂ predicted Â residualÂ becameÂ largerÂ andÂ largerÂ untilÂ itÂ 
reachedÂ theÂ maximum Â atÂ theÂ 480thÂ point,Â asÂ canÂ beÂ seenÂ fromÂ FigureÂ 24.Â AsÂ seenÂ fromÂ 
FiguresÂ 25Â andÂ 26,Â theÂ sameÂ analysisÂ resultsÂ wereÂ reflected Â inÂ theÂ simulated Â severityÂ faultÂ 
state,Â andÂ theÂ resultsÂ wereÂ moreÂ pronounced. Â 
6.Â Conclusions Â 
InÂ thisÂ paper,Â aÂ novelÂ deepÂ learningÂ recurrent Â neuralÂ networkÂ framework, Â SLSTMâ€
MLP,Â wasÂ proposed Â forÂ forecasting Â theÂ temperature Â ofÂ theÂ mainÂ bearingÂ ofÂ largeâ€scaleÂ diâ€
rectâ€drivenÂ WTsÂ toÂ mineÂ theÂ nonlinear Â andÂ nonâ€stationary Â dynamic Â featuresÂ relationship Â 
betweenÂ theÂ mainÂ bearingÂ temperature Â itselfÂ andÂ itsÂ relatedÂ parameter Â variables. Â Extenâ€
siveÂ experiments Â basedÂ onÂ SCADAÂ datasetsÂ fromÂ aÂ realÂ windÂ farmÂ wereÂ conducted Â toÂ 
evaluateÂ theÂ performance Â ofÂ theÂ proposed Â approach. Â TheÂ resultsÂ ofÂ comparative Â experiâ€
mentsÂ andÂ faultÂ simulations Â showÂ thatÂ theÂ proposed Â modelÂ surpasses Â otherÂ machine Â 
learningÂ modelsÂ andÂ hasÂ betterÂ performance Â forÂ temperature Â forecasting Â ofÂ theÂ mainÂ bearâ€
ingÂ ofÂ largeâ€scaleÂ WTs.Â 
AuthorÂ Contributions: Â TheÂ researchÂ inÂ thisÂ paperÂ wasÂ theÂ resultÂ ofÂ theÂ jointÂ effortsÂ ofÂ allÂ authors.Â 
X.X.:Â methodology, Â software, Â validation, Â writingâ€”original Â draftÂ preparation; Â J.L.:Â conceptualiza â€
tion,Â supervision, Â writingâ€”reviewing Â andÂ editing,Â fundingÂ acquisition; Â D.L.:Â conceptualization, Â suâ€
pervision, Â writingâ€”reviewing Â andÂ editing,Â fundingÂ acquisition; Â Y.T.:Â conceptualization, Â superviâ€
sion,Â writingâ€”reviewing Â andÂ editing;Â F.Z.:Â software, Â validation, Â visualization. Â AllÂ authorsÂ haveÂ readÂ 
andÂ agreedÂ toÂ theÂ published Â versionÂ ofÂ theÂ manuscript. Â 
Funding: Â ThisÂ researchÂ wasÂ fundedÂ byÂ theÂ National Â NaturalÂ ScienceÂ Foundation Â ofÂ China,Â grantÂ 
numberÂ 51475160, Â andÂ theÂ KeyÂ Research Â andÂ Development Â ProjectÂ ofÂ HunanÂ Province, Â China,Â grantÂ 
numberÂ 2018WK2022. Â 
Institutional Â ReviewÂ BoardÂ Statement: Â NotÂ applicable. Â 
Informed Â Consent Â Statement: Â NotÂ applicable. Â 
DataÂ Availability Â Statement: Â NotÂ applicable. Â 
Conflicts Â ofÂ Interest: Â TheÂ authorsÂ declareÂ noÂ conflictÂ ofÂ interest.Â 
References Â 
1. Zhu,Â Y.;Â Zhu,Â C.;Â Song,Â C.;Â Li,Â Y.;Â Chen,Â X.;Â Yong,Â B.Â Improvement Â ofÂ reliability Â andÂ windÂ powerÂ generation Â basedÂ onÂ windÂ 
turbineÂ realâ€timeÂ condition Â assessment. Â Int.Â J.Â Electr.Â PowerÂ EnergyÂ Syst.Â 2019,Â 113,Â 344â€“354.Â 
2. Zhang,Â F.;Â Wen,Â Z.;Â Liu,Â D.;Â Jiao,Â J.;Â Wan,Â H.;Â Zeng,Â B.Â Calculation Â andÂ Analysis Â ofÂ WindÂ TurbineÂ HealthÂ Monitoring Â Indicators Â 
BasedÂ onÂ theÂ Relationships Â withÂ SCADAÂ Data.Â Appl.Â Sci.Â 2020,Â 10,Â 410.Â 
3. Hart,Â E.;Â Clarke,Â B.;Â Nicholas, Â G.;Â KazemiÂ Amiri,Â A.;Â Stirling,Â J.;Â Carroll,Â J.;Â Dwyerâ€Joyce,Â R.;Â McDonald, Â A.;Â Long,Â H.Â AÂ reviewÂ ofÂ 
windÂ turbineÂ mainÂ bearings: Â Design,Â operation, Â modelling, Â damageÂ mechanisms Â andÂ faultÂ detection. Â WindÂ EnergyÂ Sci.Â 2020,Â 5,Â 
105â€“124.Â 
4. Hart,Â E.;Â Turnbull, Â A.;Â Feuchtwang, Â J.;Â McMillan, Â D.;Â Golysheva, Â E.;Â Elliott,Â R.Â WindÂ turbineÂ mainâ€bearingÂ loadingÂ andÂ windÂ 
fieldÂ characteristics. Â WindÂ EnergyÂ 2019,Â 22,Â 1534â€“1547. Â 
Figure 26. Predicted residuals of the proposed model with cumulative temperature offset of 0.008.
We can see from Figure 23 that in the fault-free area A and C, the predicted values and
observed values ï¬t well. However, in the simulated minor fault zone B, the predicted and
observed values began to show an obvious gap at the 160th point, and this gap increased
with time; that is to say, the predicted residual became larger and larger until it reached the
maximum at the 480th point, as can be seen from Figure 24. As seen from Figures 25 and 26,
the same analysis results were reï¬‚ected in the simulated severity fault state, and the results
were more pronounced.
6. Conclusions
In this paper, a novel deep learning recurrent neural network framework, SLSTM-
MLP , was proposed for forecasting the temperature of the main bearing of large-scale
direct-driven WTs to mine the nonlinear and non-stationary dynamic features relationship
between the main bearing temperature itself and its related parameter variables. Extensive
experiments based on SCADA datasets from a real wind farm were conducted to evaluate
the performance of the proposed approach. The results of comparative experiments and
fault simulations show that the proposed model surpasses other machine learning models
and has better performance for temperature forecasting of the main bearing of large-
scale WTs.
Author Contributions: The research in this paper was the result of the joint efforts of all authors.
X.X.: methodology, software, validation, writingâ€”original draft preparation; J.L.: conceptualization,
supervision, writingâ€”reviewing and editing, funding acquisition; D.L.: conceptualization, super-
vision, writingâ€”reviewing and editing, funding acquisition; Y.T.: conceptualization, supervision,
writingâ€”reviewing and editing; F.Z.: software, validation, visualization. All authors have read and
agreed to the published version of the manuscript.
Funding: This research was funded by the National Natural Science Foundation of China, grant
number 51475160, and the Key Research and Development Project of Hunan Province, China, grant
number 2018WK2022.
Institutional Review Board Statement: Not applicable.
Informed Consent Statement: Not applicable.
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 22 of 23
Data Availability Statement: Not applicable.
Conï¬‚icts of Interest: The authors declare no conï¬‚ict of interest.
References
1. Zhu, Y.; Zhu, C.; Song, C.; Li, Y.; Chen, X.; Yong, B. Improvement of reliability and wind power generation based on wind turbine
real-time condition assessment. Int. J. Electr. Power Energy Syst. 2019 ,113, 344â€“354. [CrossRef]
2. Zhang, F.; Wen, Z.; Liu, D.; Jiao, J.; Wan, H.; Zeng, B. Calculation and Analysis of Wind Turbine Health Monitoring Indicators
Based on the Relationships with SCADA Data. Appl. Sci. 2020 ,10, 410. [CrossRef]
3. Hart, E.; Clarke, B.; Nicholas, G.; Kazemi Amiri, A.; Stirling, J.; Carroll, J.; Dwyer-Joyce, R.; McDonald, A.; Long, H. A review of
wind turbine main bearings: Design, operation, modelling, damage mechanisms and fault detection. Wind Energy Sci. 2020 ,5,
105â€“124. [CrossRef]
4. Hart, E.; Turnbull, A.; Feuchtwang, J.; McMillan, D.; Golysheva, E.; Elliott, R. Wind turbine main-bearing loading and wind ï¬eld
characteristics. Wind Energy 2019 ,22, 1534â€“1547. [CrossRef]
5. Liu, Z.; Zhang, L. A review of failure modes, condition monitoring and fault diagnosis methods for large-scale wind turbine
bearings. Measurement 2020 ,149, 107002. [CrossRef]
6. Natili, F.; Daga, A.P .; Castellani, F.; Garibaldi, L. Multi-Scale Wind Turbine Bearings Supervision Techniques Using Industrial
SCADA and Vibration Data. Appl. Sci. 2021 ,11, 6785. [CrossRef]
7. Artigao, E.; Koukoura, S.; Honrubia-Escribano, A.; Carroll, J.; McDonald, A.; G Ã³mez-L Ã¡zaro, E. Current signature and vibration
analyses to diagnose an in-service wind turbine drive train. Energies 2018 ,11, 960. [CrossRef]
8. Siegel, D.; Zhao, W.; Lapira, E.; AbuAli, M.; Lee, J. A comparative study on vibration-based condition monitoring algorithms for
wind turbine drive trains. Wind Energy 2014 ,17, 695â€“714. [CrossRef]
9. Peeters, C.; Guillaume, P .; Helsen, J. Vibration-based bearing fault detection for operations and maintenance cost reduction in
wind energy. Renew. Energy 2018 ,116, 74â€“87. [CrossRef]
10. Lu, J.; ZHANG, X.; ZHANG, W.; GUO, L.; Wen, R. Fault Diagnosis of Main Bearing of Wind Turbine Based on Improved Auxiliary
Classiï¬er Generative Adversarial Network. Autom. Electr. Power Syst. 2021 ,45, 148â€“154.
11. Zhang, Z. Automatic fault prediction of wind turbine main bearing based on SCADA data and artiï¬cial neural network. Open J.
Appl. Sci. 2018 ,8, 1â€“15. [CrossRef]
12. Hongshan, Z.; Huihai, L. Fault detection of wind turbine main bear based on deep learning network. Acta Energ. Sol. Sin. 2018 ,
39, 88â€“595.
13. Wang, H.; Wang, H.; He, Q.; Wang, Y.; Zhou, Z. Condition Monitoring Method for Wind Turbine Main Bearings Based on DBN.
China Mech. Eng. 2018 ,29, 948.
14. Zhao, H.; Liu, H. Condition analysis of wind turbine main bearing based on deep belief network with improved performance.
Electr. Power Autom. Equip. 2018 ,2, 44â€“49.
15. Yucesan, Y.; Viana, F. A hybrid model for main bearing fatigue prognosis based on physics and machine learning. In AIAA Scitech
2020 Forum ; ARC: Reston, VA, USA, 2020; p. 1412.
16. Lee, J.; Jin, C.; Liu, Z.; Ardakani, H.D. Introduction to data-driven methodologies for prognostics and health management. In
Probabilistic Prognostics and Health Management of Energy Systems ; Springer: Berlin/Heidelberg, Germany, 2017; pp. 9â€“32.
17. Encalada-D Ã¡vila,Ã.; Puruncajas, B.; Tutiv Ã©n, C.; Vidal, Y. Wind Turbine Main Bearing Fault Prognosis Based Solely on SCADA
Data. Sensors 2021 ,21, 2228. [CrossRef]
18. Karim, F.; Majumdar, S.; Darabi, H.; Harford, S. Multivariate LSTM-FCNs for time series classiï¬cation. Neural Netw. 2019 ,116,
237â€“245. [CrossRef]
19. Li, J.; Deng, D.; Zhao, J.; Cai, D.; Hu, W.; Zhang, M.; Huang, Q. A Novel Hybrid Short-Term Load Forecasting Method of Smart
Grid Using MLR and LSTM Neural Network. IEEE Trans. Ind. Inform. 2020 ,17, 2443â€“2452. [CrossRef]
20. Choe, D.-E.; Kim, H.C.; Kim, M.-H. Sequence-based modeling of Deep Learning with LSTM and GRU Networks for Structural
Damage Detection of Floating Offshore Wind Turbine Blades. Renew. Energy 2021 ,174, 218â€“235. [CrossRef]
21. Hochreiter, S.; Schmidhuber, J. Long short-term memory. Neural Comput. 1997 ,9, 1735â€“1780. [CrossRef]
22. Lippi, M.; Montemurro, M.A.; Degli Esposti, M.; Cristadoro, G. Natural language statistical features of LSTM-generated texts.
IEEE Trans. Neural Netw. Learn. Syst. 2019 ,30, 3326â€“3337. [CrossRef]
23. Shewalkar, A.; Nyavanandi, D.; Ludwig, S.A. Performance evaluation of deep neural networks applied to speech recognition:
RNN, LSTM and GRU. J. Artif. Intell. Soft Comput. Res. 2019 ,9, 235â€“245. [CrossRef]
24. Tan, Y.H.; Chan, C.S. Phrase-based image caption generator with hierarchical LSTM network. Neurocomputing 2019 ,333, 86â€“100.
[CrossRef]
25. Gao, L.; Guo, Z.; Zhang, H.; Xu, X.; Shen, H.T. Video captioning with attention-based LSTM and semantic consistency. IEEE Trans.
Multimed. 2017 ,19, 2045â€“2055. [CrossRef]
26. Xiao, X.; Liu, J.; Liu, D.; Tang, Y.; Dai, J.; Zhang, F. SSAE-MLP: Stacked sparse autoencoders-based multi-layer perceptron for
main bearing temperature prediction of large-scale wind turbines. Concurr. Comput. Pract. Exp. 2021 ,33, e6315. [CrossRef]
27. Yang, W.; Court, R.; Jiang, J. Wind turbine condition monitoring by the approach of SCADA data analysis. Renew. Energy 2013 ,53,
365â€“376. [CrossRef]
------------------------------End of the page -----------------------------------
Energies 2022 ,15, 1951 23 of 23
28. Dai, J.; Tan, Y.; Yang, W.; Wen, L.; Shen, X. Investigation of wind resource characteristics in mountain wind farm using multiple-
unit SCADA data in Chenzhou: A case study. Energy Convers. Manag. 2017 ,148, 378â€“393. [CrossRef]
29. Leahy, K.; Gallagher, C.; Oâ€™Donovan, P .; Bruton, K.; Oâ€™Sullivan, D. A robust prescriptive framework and performance metric
for diagnosing and predicting wind turbine faults based on SCADA and alarms data with case study. Energies 2018 ,11, 1738.
[CrossRef]
30. Cambron, P .; Masson, C.; Tahan, A.; Pelletier, F. Control chart monitoring of wind turbine generators using the statistical inertia of
a wind farm average. Renew. Energy 2018 ,116, 88â€“98. [CrossRef]
31. Dazhong, L.; Cheng, C.; Bingkun, X. Wind turbine gearing temperature prediction based on sample optimization. J. Syst. Simul.
2017 ,29, 374.
32. Guo, P .; Inï¬eld, D.; Yang, X. Wind turbine generator condition-monitoring using temperature trend analysis. IEEE Trans. Sustain.
Energy 2012 ,3, 124â€“133. [CrossRef]
------------------------------End of the page -----------------------------------
