Citation: Tang, M.; Cao, C.; Wu, H.;
Zhu, H.; Tang, J.; Peng, Z.; Wang, Y.
Fault Detection of Wind Turbine
Gearboxes Based on IBOA-ERF.
Sensors 2022 ,22, 6826. https://
doi.org/10.3390/s22186826
Academic Editors: Kaixiang Peng,
Zhiwen Chen and Kai Zhang
Received: 10 August 2022
Accepted: 29 August 2022
Published: 9 September 2022
Publisherâ€™s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afï¬l-
iations.
Copyright: Â© 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed under the terms and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
sensors
Article
Fault Detection of Wind T urbine Gearboxes Based
on IBOA-ERF
Mingzhu Tang1,â€ 
, Chenhuan Cao1, Huawei Wu2,*, Hongqiu Zhu3,â€ 
, Jun Tang1, Zhonghui Peng1
and Yifan Wang1
1School of Energy and Power Engineering, Changsha University of Science & Technology,
Changsha 410114, China
2Hubei Key Laboratory of Power System Design and Test for Electrical Vehicle, Hubei University of Arts and
Science, Xiangyang 441053, China
3School of Automation, Central South University, Changsha 410083, China
*Correspondence: whw_xy@hbuas.edu.cn
â€  These authors contributed equally to this work.
Abstract: As one of the key components of wind turbines, gearboxes are under complex alternating
loads for a long time, and the safety and reliability of the whole machine are often affected by the
failure of internal gears and bearings. Aiming at the difï¬culty of optimizing the parameters of wind
turbine gearbox fault detection models based on extreme random forest, a fault detection model with
extreme random forest optimized by the improved butterï¬‚y optimization algorithm (IBOA-ERF) is
proposed. The algebraic sum of the false alarm rate and the missing alarm rate of the fault detection
model is constructed as the ï¬tness function, and the initial position and position update strategy
of the individual are improved. A chaotic mapping strategy is introduced to replace the original
population initialization method to enhance the randomness of the initial population distribution.
An adaptive inertia weight factor is proposed, combined with the landmark operator of the pigeon
swarm optimization algorithm to update the population position iteration equation to speed up the
convergence speed and improve the diversity and robustness of the butterï¬‚y optimization algorithm.
The dynamic switching method of local and global search stages is adopted to achieve dynamic
balance between global exploration and local search, and to avoid falling into local optima. The
ERF fault detection model is trained, and the improved butterï¬‚y optimization algorithm is used to
obtain optimal parameters to achieve fast response of the proposed model with good robustness and
generalization under high-dimensional data. The experimental results show that, compared with
other optimization algorithms, the proposed fault detection method of wind turbine gearboxes has a
lower false alarm rate and missing alarm rate.
Keywords: fault detection; butterï¬‚y optimization algorithm; extreme random forest; wind
turbine; gearbox
1. Introduction
As an important source of clean and renewable energy, wind energy resources play an
important role in the sustainable development of the national economy. The use of wind
power is very environmentally friendly, and wind energy reserves are huge, so wind power
is attracting more and more attention from countries all over the world. According to the
forecast of the Global Wind Energy Council (GWEC), global wind power will increase by
557 GW in the next ï¬ve years (2022â€“2026), with a compound annual growth rate of 6.6%.
By 2026, the global newly installed capacity of wind power will reach 128.8 GW, of which
the newly installed capacity of onshore wind power will be 97.4 GW, while the newly
installed capacity of offshore wind power will be 31.4 GW [ 1]. However, abundant wind
resources are often found in remote areas, and the occurrence of some extreme weather
conditions can lead to the failure of wind turbines [ 2]. Compared with the tower base, the
Sensors 2022 ,22, 6826. https://doi.org/10.3390/s22186826 https://www.mdpi.com/journal/sensors
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 2 of 21
narrow nacelle does not have a solid foundation, and the factors of power matching and
torsional deformation in the drive train are always concentrated in a weak link. Much
research has proven that this link is often the gearbox in the unit [ 3]. The gearbox is an
essential mechanical component, and its main purpose is to transport the power generated
by the blades to the power generator in order to obtain the appropriate speed [ 4]. Due to
its special installation position, once a fault occurs, it is very difï¬cult to repair. Compared
with other unit components, the gearbox has the longest downtime and repair time due to
failure, resulting in long-term gearbox downtime. Therefore, providing accurate guidance
at the ï¬rst instance of failure can reduce the operating cost and maintenance cost of the
wind turbine, which has great economic and engineering value [ 5]. In recent years, scholars
have carried out extensive applied research on the fault detection of wind turbines.
Currently, research on fault detection of wind turbine gearboxes mainly includes
methods based on signal processing, along with data-driven and model-based meth-
ods [ 6â€“8]. Signal-based approachesâ€”such as spectral analysis, wavelet transform [ 9], and
non-parametric spectrum estimationâ€”are often carried out. However, for stationary signal
power, unlike the theoretical inï¬nite-length signal, the actual observed signal is a ï¬nite-
length signal. Low resolution of frequency is inevitable in the conversion process. The
data-driven approach requires large volumes of historical data and multidimensional fea-
tures [ 10]. Today, machine-learning-based fault detection approaches are used extensively
in the ï¬eld of industry [11].
In machine learning, the decision tree classiï¬cation model is a tree structure, which is
strongly intuitive and easy to understand, and has become a popular technology of online
detection. Liang [ 12] proposed to encrypt the decision table using a searchable symmetric
encryption method to improve the classiï¬cation speed and solve the detection requirement
in microseconds. Stetco [ 13] reviewed the machine learning methods used in wind turbine
blades, generator temperature fault detection, etc. Classiï¬cation is mostly used when using
SCADA datasets or simulation data, and decision trees are the most commonly used models.
In general, decision trees are prone to overï¬tting and poor generalization performance, and
small changes in the data may lead to the generation of completely different treesâ€”that is,
their stability performance needs to be improved. To solve this problem, Feng [ 14] used the
adaptive boost algorithm to ï¬nd the mapping between incoming data and outgoing data,
and the overall accuracy of the model was improved.
The boost algorithm in machine learning refers to integrating multiple weak classi-
ï¬ers to reduce the time complexity of a single decision tree and make the model easy to
display [ 15]. Liu [ 16] proposed a fault detection method based on NFSW-BP-AdaBoost
to evaluate the combination of multiple classiï¬ers with non-fuzzy solution coefï¬cients to
improve the recognition rate of faults. Chakraborty [ 17] designed the data-driven model
of extreme gradient boosting (XGBoost), using the dynamic adjusted threshold to judge
the occurrence of faults, which improved the quality of the model and had strong general-
ization ability. Xu [ 18] designed cost-sensitive GBDT (CS-GBDT) to improve the problem
of low diagnostic accuracy in the face of unbalanced datasets, and used multiple-domain
feature extraction and feature selection to enhance diagnostic accuracy. However, in the
face of high-dimensional complex data in actual wind farms, the boost algorithm con-
sumes too much memory, making it easy to reduce the calculation accuracy and fault
detection accuracy.
Owing to the large amount of data and high dimensionality of real wind farms,
existing studies usually have problems such as poor performance and long training time.
Extreme random forest is an ensemble tree algorithm with complete randomness proposed
on the basis of decision trees. The feature values are selected for segmentation in the
training phase to obtain the segmentation values. This method has strong randomness,
and in practical applications it shows high accuracy in high-dimensional datasets, can
easily achieve parallelization, and has strong generalization performance. However, in the
domain of practical fault detection, the selection of hyperparameters is extremely critical to
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 3 of 21
the ï¬nal detection results, and suitable hyperparameters can prevent the local convergence
of the model and achieve the best results [19].
For high-dimensional nonlinear problems, the modern intelligent optimization al-
gorithm is widely used in the ï¬eld of fault detection [ 20]. In practical applications, the
optimization algorithm is used to ï¬nd the optimal scheme or parameter value among
many schemes or parameter values, so that some performance and function indices of the
system can reach optimal values. Arora [ 21] introduced a new nature-inspired heuristic
algorithmâ€”the butterï¬‚y optimization algorithm, which has the strengths of requiring
few adjustment parameters and strong convergence. However, in the face of complex
optimization problems such as high-dimensional data, it is prone to being trapped in local
optima, and another problem is its slow convergence speed [22].
In view of the above problems, a fault detection model with extreme random forest
optimized by improved butterï¬‚y optimization algorithm (IBOA-ERF) was proposed. In
the improved butterï¬‚y optimization algorithm, chaotic mapping is introduced to initialize
the population, and the adaptive inertia weight factor is introduced. Combined with the
pigeon swarm optimization algorithm, adaptive dynamic switching is proposed to control
the conversion of the search stage, which is integrated into the population position update
formula, and the convergence speed and optimization accuracy are greatly improved.
Firstly, the data are cleaned using Pearsonâ€™s correlation analysis, reducing the dataâ€™s
dimensions and deleting redundant features. Secondly, the sample dataset is divided into
two categories: a training set and a test set. The improved butterï¬‚y algorithm is used to
generate the best hyperparameters of the extreme random forest, and the IBOA-ERF fault
detection model is constructed to detect the gearbox faults of wind turbines.
2. Fault Detection of Wind T urbine Gearboxes
As one of the most signiï¬cant structural parts of a wind turbine, the gearbox is subject
to very complex forces, and works under complex alternating loads and harsh working
environments for a long time.
Figure 1 shows schematic diagrams of a wind turbineâ€™s structure and the fault detection
process. When the unsteady wind acts on the unit, different loads are generated [ 23]. The
blade produces axial thrust and circumferential shear, resulting in deï¬‚ection movement [ 24].
The torsional main bearing transmits the blade torque to the gearbox to complete the output
of the corresponding load. In the generator, the torque on the motor shaft continuously cuts
the magnetic induction line to output power, and completes the conversion of wind energy,
mechanical energy, and power [ 25]. Subsequently, the coordination of major electrical
parameters and data interaction is completed through the frequency converter and control
unit. The actual operating data of the wind turbine are stored in the SCADA system,
making it easy to extract data for fault detection.
The proportion of failures caused by broken teeth, pitting, gluing, and wear of gears
inside the gearbox is about 60%, while the proportion of failures caused by damage to
bearings such as burns, balls falling off, and cage deformation is about 20%, which seriously
impact the security and stability of the whole machineâ€™s operation [ 26]. Due to the high
fault dimensions and redundant parameters, it is important to mine the fault characteristics
of gearboxes deeply and determine the fault location and category quickly and accurately
for the secure and stable operation of wind turbines.
In summary, in order to further enhance the stability and precision of wind turbine
gearbox fault detection, aiming at the problems of gearbox fault data dimension reduction,
feature selection, and model parameter optimization, combined with extreme random
forest with excellent classiï¬cation performance, a wind turbine fault detection model based
on IBOA-ERF is adopted, which improves the detection precision of the model and ensures
the safe operation of the wind turbine.
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 4 of 21
Sensors 2022 , 22, x FOR PEER REVIEW 4 of 22 
 
  
Figure 1. Schematic diagrams of a wind turbineâ€™s structure and the fault detection process. 
In summary, in order to further enhance the stability and precision of wind turbine 
gearbox fault detection, aiming at the prob lems of gearbox fault data dimension reduc-
tion, feature selection, and model parameter optimization, combined with extreme ran-
dom forest with excellent classification pe rformance, a wind turbine fault detection 
model based on IBOA-ERF is adopted, which improves the detection precision of the 
model and ensures the safe operation of the wind turbine. 
3. Extreme Random Forest 
Random forest (RF) consists of a series of decision trees . The decision tree is a tree 
structure, in which each internal node repr esents a categorical judgment, and each leaf 
node at the bottom represents a classification result; this is detailed in Figures 2 and 3. A 
subset of n samples of the same size as the sample set is obtained by randomly selecting 
the sample set. Next, several weak classifiers are built. A decision tree is a tree classifica-
tion method derived from the training sa mples by using a set of random vectors. 
At the time of node-splitting, through top- down recursion, trav ersing each feature 
and each value of each feature, and use evaluati on criteria such as the Gini coefficient to 
determine the optimal features and feature va lues as node features and thresholds. The 
process iteratively splits down until the entropy of each leaf node is reduced to 0â€”that is, 
the class confusion degree of the sample is 0â€”and then votes to determine the final 
classification. Through the above steps, the unique path of each sample is determined, and the category of the sample is the catego ry corresponding to the leaf node of the 
unique path. 
Figure 1. Schematic diagrams of a wind turbineâ€™s structure and the fault detection process.
3. Extreme Random Forest
Random forest (RF) consists of a series of decision trees. The decision tree is a tree
structure, in which each internal node represents a categorical judgment, and each leaf
node at the bottom represents a classiï¬cation result; this is detailed in Figures 2 and 3. A
subset of n samples of the same size as the sample set is obtained by randomly selecting the
sample set. Next, several weak classiï¬ers are built. A decision tree is a tree classiï¬cation
method derived from the training samples by using a set of random vectors.
SensorsÂ 2022,Â 22,Â xÂ FORÂ PEERÂ REVIEW Â  5Â ofÂ 22Â 
Â 
Â DatasetÂ DDatasetÂ D1
DatasetÂ D2
DatasetÂ DnVote(Â 1Â )Â Generation Â of
Â Â Â Â Â Â Â Â sampleÂ subset(Â 2Â )Â Establishing Â ERT
Â faultÂ treeï¼ˆ3ï¼‰Vote
Â 
FigureÂ 2.Â Structure Â diagramÂ ofÂ ERF.Â 
WhileÂ inheriting Â theÂ goodÂ performance Â ofÂ RF,Â extremeÂ randomÂ forestÂ (ERF)Â hasÂ twoÂ 
mainÂ differences: Â First,Â theÂ originalÂ datasetÂ isÂ usedÂ inÂ theÂ trainingÂ setÂ ofÂ eachÂ decisionÂ tree.Â 
DueÂ toÂ theÂ randomness Â ofÂ featureÂ selection Â andÂ nodeÂ splitting, Â theÂ obtained Â resultsÂ willÂ 
beÂ betterÂ thanÂ thoseÂ ofÂ RF.Â Second,Â afterÂ pickingÂ theÂ segmentation Â features, Â RFÂ selectsÂ anÂ 
optimalÂ featureÂ valueÂ forÂ segmentation, Â whileÂ theÂ ERFÂ splitsÂ theÂ randomly Â selectedÂ 
eigenvalues, Â whichÂ enhances Â theÂ genericÂ performance Â ofÂ theÂ model,Â whileÂ theÂ sizeÂ ofÂ theÂ 
decisionÂ treeÂ increases. Â FigureÂ 2Â showsÂ aÂ structural Â diagramÂ ofÂ ERF.Â 
TheÂ classÂ attributeÂ isÂ determined Â byÂ theÂ voteÂ ofÂ allÂ decisionÂ trees,Â andÂ itsÂ voteÂ isÂ basedÂ 
onÂ Equation Â (1).Â TheÂ largerÂ theÂ calculated Â P,Â theÂ higherÂ theÂ probability Â ofÂ belonging Â toÂ theÂ 
corresponding Â category. Â Equation Â (2)Â isÂ theÂ votingÂ mechanism Â principle Â ofÂ theÂ finalÂ 
decisionÂ tree.Â TheÂ aboveÂ methodÂ isÂ usedÂ toÂ generateÂ theÂ extremeÂ randomÂ forestÂ decisionÂ 
tree.Â 
Páˆºc| fà­§áˆ»àµŒ1
Dà·P à­²áˆºc|V à­§áˆ»à­ˆ
à­²à­€à¬µÂ  (1)Â 
cà·œàµŒa r g m a x à­¡ Páˆºc|V à­§áˆ»Â  (2)Â 
whereÂ Và­§Â denotesÂ theÂ featureÂ vectorÂ ofÂ theÂ sample,Â cÂ isÂ someÂ kindÂ ofÂ category, Â DÂ denotesÂ 
theÂ numberÂ ofÂ treesÂ inÂ theÂ ERF,Â Pà­²áˆºc|V à­§áˆ»Â denotesÂ theÂ probability Â thatÂ theÂ sampleÂ belongsÂ 
toÂ category Â cÂ conditional Â onÂ theÂ featureÂ vectorÂ Và­§,Â Páˆºc|V à­§áˆ»Â isÂ theÂ averageÂ valueÂ inÂ theÂ ERF,Â 
andÂ cà·œÂ represents Â theÂ category Â corresponding Â toÂ theÂ maximum Â valueÂ ofÂ Páˆºc|V à­§áˆ».Â 
DuringÂ theÂ nodeâ€splittingÂ phase,Â forÂ theÂ processÂ ofÂ selecting Â theÂ obtained Â featureÂ asÂ 
theÂ splittingÂ feature,Â Equation Â (3)Â isÂ usedÂ toÂ measureÂ theÂ score.Â WhenÂ theÂ leafÂ nodesÂ areÂ 
split,Â theÂ splittingÂ featureÂ isÂ selectedÂ asÂ theÂ featureÂ withÂ theÂ highestÂ score.Â SamplesÂ 
smallerÂ thanÂ theÂ splittingÂ threshold Â areÂ putÂ inÂ theÂ leftÂ leafÂ nodeÂ afterÂ splitting; Â otherwise, Â 
theyÂ areÂ placedÂ inÂ theÂ rightÂ leafÂ node.Â TheseÂ procedures Â areÂ repeated Â untilÂ theÂ sampleÂ 
confusion Â inÂ theÂ leafÂ nodeÂ isÂ 0.Â FigureÂ 3Â illustrates Â theÂ splittingÂ architecture Â ofÂ theÂ ERFÂ 
faultÂ tree.Â 
Score à­©àµŒ2Ià­©
Hà­©àµ…H à­¡Â  (3)Â 
whereÂ Score à­©Â represents Â theÂ scoreÂ measurement Â ofÂ theÂ calculated Â feature,Â andÂ Ià­©Â 
denotesÂ theÂ mutualÂ information Â ofÂ theÂ twoÂ subsetsÂ ofÂ theÂ nodeÂ afterÂ splittingÂ onÂ theÂ basisÂ 
ofÂ theÂ corresponding Â featuresÂ andÂ splittingÂ threshold Â ofÂ theÂ sampleÂ category. Â Hà­©Â denotesÂ 
Figure 2. Structure diagram of ERF.
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 5 of 21
SensorsÂ 2022,Â 22,Â xÂ FORÂ PEERÂ REVIEW Â  6Â ofÂ 22Â 
Â 
Â theÂ splitÂ entropyÂ ofÂ featureÂ k,Â whileÂ Hà­¡Â represents Â theÂ information Â entropyÂ ofÂ theÂ nodeÂ 
forÂ theÂ corresponding Â category. Â 
FeatureÂ XÂ 
(Â branch
nodeÂ )
NormalÂ 
category
Â (Â leafÂ nodeÂ )
FeatureÂ YÂ 
(Â branchÂ 
nodeÂ )
NormalÂ 
category
Â (Â leafÂ nodeÂ )
FaultÂ category
Â (Â leafÂ nodeÂ )Randomly Â selectedÂ 
splittingÂ threshold Â x
Samples
Â lessÂ thanÂ xÂ inÂ XSamplesÂ greaterÂ thanÂ 
orÂ equalÂ toÂ xÂ inÂ X
Random Â selection Â 
splittingÂ threshold Â y
Samples
Â lessÂ thanÂ yÂ inÂ YSamplesÂ greaterÂ thanÂ 
orÂ equalÂ toÂ yÂ inÂ Y
Â 
FigureÂ 3.Â Illustration Â ofÂ theÂ splittingÂ architecture Â ofÂ theÂ ERFÂ faultÂ tree.Â 
TheÂ choiceÂ ofÂ hyperparameters Â inÂ ERFÂ hasÂ aÂ greatÂ influence Â onÂ theÂ classification Â 
precision Â ofÂ theÂ model,Â andÂ theÂ optimization Â ofÂ theÂ parameters Â isÂ difficult. Â Therefore, Â 
optimization Â algorithms Â mustÂ beÂ introduced Â toÂ searchÂ forÂ theÂ bestÂ parameters Â toÂ enhanceÂ 
theÂ reliability Â ofÂ theÂ faultÂ detection Â model.Â 
4.Â Butterfly Â Optimization Â Algorithm Â 
InÂ nature,Â butterflies Â useÂ theirÂ highÂ sensitivity Â toÂ fragrance Â toÂ searchÂ forÂ foodÂ andÂ 
partners. Â InÂ 2019,Â AroraÂ [21]Â proposed Â theÂ butterfly Â optimization Â algorithm Â (BOA),Â whichÂ 
imitatesÂ theÂ movements Â ofÂ butterflies Â inÂ searchÂ ofÂ foodÂ andÂ mating.Â 
4.1.Â BasicÂ TheoryÂ ofÂ theÂ ButterflyÂ Optimization Â Algorithm Â 
StudiesÂ haveÂ shownÂ thatÂ butterflies Â canÂ accurately Â determine Â theÂ locationÂ ofÂ foodÂ byÂ 
detecting Â different Â flavorsÂ andÂ flavorÂ intensity Â duringÂ predation Â [27].Â InÂ theÂ butterfly Â opâ€
timization Â algorithm, Â eachÂ butterfly Â produces Â aÂ certainÂ intensity Â ofÂ fragrance Â according Â toÂ 
itsÂ fitness,Â andÂ whenÂ itÂ perceives Â thatÂ theÂ fragrance Â emittedÂ byÂ anotherÂ butterfly Â inÂ aÂ cerâ€
tainÂ regionÂ isÂ stronger, Â itÂ willÂ tryÂ toÂ approach Â thisÂ butterfly, Â whichÂ isÂ knownÂ asÂ globalÂ 
search.Â WhenÂ aÂ butterfly Â perceives Â itsÂ ownÂ fragrance Â toÂ beÂ moreÂ intenseÂ thanÂ thatÂ ofÂ otherÂ 
butterflies, Â itÂ willÂ beÂ ableÂ toÂ freelyÂ moveÂ inÂ space,Â whichÂ isÂ knownÂ asÂ localÂ searchÂ [28].Â 
InÂ theÂ BOA,Â butterfly Â fragrance Â calculation Â isÂ asÂ shownÂ inÂ Equation Â (4):Â 
fàµŒs Ià®‘Â  (4)Â 
whereÂ fÂ isÂ theÂ fragrance Â intensity, Â IÂ isÂ theÂ stimulus Â intensity, Â sÂ isÂ theÂ sensoryÂ modality Â 
withÂ aÂ valueÂ ofÂ 0.01,Â andÂ Î±Â isÂ theÂ powerÂ exponent Â withÂ aÂ valueÂ ofÂ 0.1.Â 
InÂ theÂ BOA,Â theÂ stimulus Â intensity Â IÂ ofÂ theÂ individual Â isÂ influenced Â byÂ theÂ objective Â 
function, Â andÂ theÂ powerÂ exponent Â Î±Â isÂ theÂ exponent Â ofÂ theÂ increaseÂ inÂ fragrance Â intensity. Â 
TheÂ transitions Â ofÂ theÂ globalÂ andÂ localÂ searchÂ stagesÂ areÂ controlled Â byÂ theÂ switching Â 
transition Â frequency Â pÂ âˆˆÂ [0,Â 1].Â InÂ theÂ globalÂ searchÂ phase,Â theÂ positionÂ isÂ updatedÂ asÂ 
shownÂ inÂ Equation Â (5):Â 
xà­§à­²à¬¾à¬µàµŒxà­§à­²àµ…áˆºrà¬¶àµˆgâˆ—àµ†xà­§à­²áˆ»àµˆf à­§Â  (5)Â 
whereÂ xà­§à­²à¬¾à¬µÂ andÂ xà­§à­²Â areÂ theÂ locationÂ information Â ofÂ theÂ iâ€thÂ individual Â inÂ theÂ t+1â€thÂ andÂ 
tâ€thÂ iterations, Â respectively; Â gâˆ—Â isÂ theÂ bestÂ valueÂ inÂ theÂ currentÂ iteration; Â fà­§Â isÂ theÂ 
Figure 3. Illustration of the splitting architecture of the ERF fault tree.
At the time of node-splitting, through top-down recursion, traversing each feature
and each value of each feature, and use evaluation criteria such as the Gini coefï¬cient to
determine the optimal features and feature values as node features and thresholds. The
process iteratively splits down until the entropy of each leaf node is reduced to 0â€”that
is, the class confusion degree of the sample is 0â€”and then votes to determine the ï¬nal
classiï¬cation. Through the above steps, the unique path of each sample is determined, and
the category of the sample is the category corresponding to the leaf node of the unique path.
While inheriting the good performance of RF, extreme random forest (ERF) has two
main differences: First, the original dataset is used in the training set of each decision
tree. Due to the randomness of feature selection and node splitting, the obtained results
will be better than those of RF. Second, after picking the segmentation features, RF selects
an optimal feature value for segmentation, while the ERF splits the randomly selected
eigenvalues, which enhances the generic performance of the model, while the size of the
decision tree increases. Figure 2 shows a structural diagram of ERF.
The class attribute is determined by the vote of all decision trees, and its vote is based
on Equation (1). The larger the calculated P, the higher the probability of belonging to the
corresponding category. Equation (2) is the voting mechanism principle of the ï¬nal decision
tree. The above method is used to generate the extreme random forest decision tree.
P(cjfi) =1
DD
Ã¥
t=1Pt(cjVi) (1)
Ë†c=argmaxcP(cVi) (2)
where Videnotes the feature vector of the sample, c is some kind of category, Ddenotes
the number of trees in the ERF, Pt(cjVi)denotes the probability that the sample belongs
to category c conditional on the feature vector Vi,P(cjVi)is the average value in the ERF,
and Ë†c represents the category corresponding to the maximum value of P (cjVi).
During the node-splitting phase, for the process of selecting the obtained feature as
the splitting feature, Equation (3) is used to measure the score. When the leaf nodes are
split, the splitting feature is selected as the feature with the highest score. Samples smaller
than the splitting threshold are put in the left leaf node after splitting; otherwise, they are
placed in the right leaf node. These procedures are repeated until the sample confusion in
the leaf node is 0. Figure 3 illustrates the splitting architecture of the ERF fault tree.
Score k=2Ik
Hk+Hc(3)
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 6 of 21
where Score krepresents the score measurement of the calculated feature, and Ikdenotes
the mutual information of the two subsets of the node after splitting on the basis of the
corresponding features and splitting threshold of the sample category. Hkdenotes the
split entropy of feature k, while H crepresents the information entropy of the node for the
corresponding category.
The choice of hyperparameters in ERF has a great inï¬‚uence on the classiï¬cation
precision of the model, and the optimization of the parameters is difï¬cult. Therefore,
optimization algorithms must be introduced to search for the best parameters to enhance
the reliability of the fault detection model.
4. Butterï¬‚y Optimization Algorithm
In nature, butterï¬‚ies use their high sensitivity to fragrance to search for food and
partners. In 2019, Arora [ 21] proposed the butterï¬‚y optimization algorithm (BOA), which
imitates the movements of butterï¬‚ies in search of food and mating.
4.1. Basic Theory of the Butterï¬‚y Optimization Algorithm
Studies have shown that butterï¬‚ies can accurately determine the location of food
by detecting different ï¬‚avors and ï¬‚avor intensity during predation [ 27]. In the butterï¬‚y
optimization algorithm, each butterï¬‚y produces a certain intensity of fragrance according
to its ï¬tness, and when it perceives that the fragrance emitted by another butterï¬‚y in a
certain region is stronger, it will try to approach this butterï¬‚y, which is known as global
search. When a butterï¬‚y perceives its own fragrance to be more intense than that of other
butterï¬‚ies, it will be able to freely move in space, which is known as local search [28].
In the BOA, butterï¬‚y fragrance calculation is as shown in Equation (4):
f=sI(4)
where f is the fragrance intensity, I is the stimulus intensity, s is the sensory modality with a
value of 0.01, and is the power exponent with a value of 0.1.
In the BOA, the stimulus intensity I of the individual is inï¬‚uenced by the objective
function, and the power exponent is the exponent of the increase in fragrance intensity.
The transitions of the global and local search stages are controlled by the switching transi-
tion frequency p2[0, 1]. In the global search phase, the position is updated as shown in
Equation (5):
xt+1
i=xt
i+
r2g xt
i
fi (5)
where xt+1
iand xt
iare the location information of the i-th individual in the t+1-th and
t-th iterations, respectively; gis the best value in the current iteration; fiis the fragrance
intensity emitted by the i-th individual; and r is the random value from 0 to 1. In the local
search phase, the position is updated as shown in Equation (6):
xt+1
i=xt
i+
r2xt
j xt
k
fi (6)
where j and k are the random numbers generated in each iteration, while xt
jand xt
kare the
location information of the j-th and k-th individuals in the current iteration, respectively.
4.2. Improvement and Innovation of the Butterï¬‚y Optimization Algorithm
Compared with some existing meta-heuristic algorithms, the BOA is relatively novel,
with simple operation, few parameters to be adjusted, and better robustness. It is superior
to some classic intelligent optimization algorithms in terms of optimization ability, and has
achieved good results in the preliminary application of engineering practice. However, in
the face of complex conditions, its performance is not good, and there are still problems
such as its tendency to become trapped in local optima and its low convergence precision
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 7 of 21
when solving high-dimensional functions. To solve this problem, the improved butterï¬‚y
optimization algorithm (IBOA) is constructed through the following four modiï¬cations:
1. Introduce a chaotic map to randomly initialize the population position, so that the
initial population is random and aperiodic, so as to prevent the exploration process
from ending up in a local optimum.
2. Design an adaptive inertia weight factor and apply it to the position update formula
to enhance the capability of local search and accelerate the search rate.
3. Introduce the landmark operator sub-item of the pigeon group optimization algorithm,
design a new position update formula, enhance the global search capability, and
improve the diversity and robustness of the butterï¬‚y optimization algorithm.
4. Design a new dynamic switching method for the local search phase and the global
search phase, and introduce the variant of trigonometric function as the switching
basis, which can effectively prevent trapping in local optima and accelerate the con-
vergence speed.
4.2.1. Chaos Map Initialization
BOA randomly initializes the population position, but using this approach to generate
the initial population may lead to uneven distribution and superposition of individual
butterï¬‚y positions. In the butterï¬‚y population, the small change in the initial distribution
has a great impact on the subsequent iterative search process. To solve this problem,
chaotic variables are used to optimize the search so as to evenly distribute the initial
population [ 29], which can improve the diversity of BOA, greatly improve the convergence
speed and optimization accuracy, and prevent premature convergence. After testing and
comparison, the classical logistical chaotic mapping is used to initialize the population.
The logistic map described in [ 30] is used to map the variables into the chaotic variable
space, and then used the linear transformation to map the generated chaotic variables into
the solution space in need of optimization. Figure 4 shows the comparison between the
initialization using chaotic mapping and the original initialization method. The speciï¬c
expression of the logistic map is as shown in Equation (7):
X(t+1)=X(t)(1 X(t))2[0, 4], X2[0, 1] (7)
whereis the logistics parameter, X is the position parameter, and t is the value of the
iterations. The research shows that when is 4, the range of X is almost evenly distributed
in the entire region of 0 to 1, so the value of in this case is 4.
SensorsÂ 2022,Â 22,Â xÂ FORÂ PEERÂ REVIEW Â  8Â ofÂ 22Â 
Â 
Â   
(a) (b) 
FigureÂ 4.Â (a)Â TheÂ distribution Â afterÂ randomÂ initialization; Â (b)Â theÂ distribution Â afterÂ initialization Â ofÂ 
theÂ chaoticÂ map.Â 
4.2.2.Â Adaptive Â InertiaÂ Weighting Â FactorÂ 
According Â toÂ theÂ basicÂ principle Â ofÂ theÂ BOA,Â eachÂ individual Â updatesÂ orÂ randomly Â 
movesÂ itsÂ positionÂ according Â toÂ theÂ currentÂ bestÂ individual Â position. Â Therefore, Â theÂ posiâ€
tionÂ ofÂ individual Â butterflies Â isÂ notÂ fullyÂ utilized,Â andÂ itÂ isÂ easyÂ toÂ becomeÂ trappedÂ inÂ aÂ 
localÂ optimum. Â WhenÂ theÂ inertiaÂ factorÂ isÂ large,Â theÂ globalÂ searchÂ capability Â isÂ strong,Â 
andÂ viceÂ versa.Â Therefore, Â toÂ addressÂ thisÂ issue,Â anÂ adaptive Â inertiaÂ weighting Â factorÂ wasÂ 
designed Â toÂ applyÂ toÂ theÂ positionÂ updateÂ formula, Â soÂ thatÂ theÂ historical Â optimalÂ positionÂ 
information Â ofÂ theÂ individual Â isÂ fullyÂ utilized.Â Meanwhile, Â asÂ theÂ iterations Â growÂ inÂ size,Â 
theÂ direction Â andÂ distanceÂ ofÂ theÂ individual Â areÂ effectively Â controlled, Â soÂ asÂ toÂ enhanceÂ 
theÂ optimization Â precision Â andÂ convergence Â velocity,Â andÂ avoidÂ fallingÂ intoÂ localÂ optima.Â 
TheÂ expression Â ofÂ theÂ inertiaÂ weighting Â factorÂ isÂ asÂ follows:Â 
Ï‰áˆºtáˆ»àµŒ1àµ†s i n  áˆºÏ€t
âˆšeàµ…1 àµˆT à­§à­²à­£à­°áˆ»Â  (8)Â 
whereÂ Ï‰ Â isÂ theÂ adaptive Â inertiaÂ weight,Â Tà­§à­²à­£à­°Â isÂ theÂ largestÂ valueÂ ofÂ theÂ numberÂ ofÂ 
iterations Â tÂ inÂ theÂ optimization Â process,Â andÂ eÂ isÂ theÂ EulerÂ number.Â 
TheÂ positionÂ updateÂ formulaÂ forÂ theÂ globalÂ searchÂ phaseÂ afterÂ theÂ introduction Â ofÂ 
theÂ adaptive Â inertiaÂ weighting Â factorÂ inÂ BOAÂ isÂ asÂ follows:Â 
xà­§à­²à¬¾à¬µàµŒÏ‰ áˆºtáˆ»àµˆxà­§à­²àµ…áˆºrà¬¶àµˆgâˆ—àµ†xà­§à­²áˆ»àµˆfà­§Â  (9)Â 
TheÂ positionÂ updateÂ formulaÂ forÂ theÂ localÂ searchÂ phaseÂ isÂ asÂ follows:Â 
xà­§à­²à¬¾à¬µàµŒÏ‰ áˆºtáˆ»àµˆxà­§à­²àµ…àµ« rà¬¶àµˆxà­¨à­²àµ†xà­©à­²àµ¯àµˆfà­§Â  (10)Â 
4.2.3.Â Pigeonâ€InspiredÂ Optimization Â Algorithm Â Landmark Â Operator Â 
InspiredÂ byÂ theÂ nestingÂ activityÂ ofÂ pigeons,Â aÂ newÂ population Â intelligence Â optimiza â€
tionÂ algorithmâ€”the Â pigeonâ€inspiredÂ optimization Â (PIO)Â algorithmâ€”was Â firstÂ proposed Â 
byÂ DuanÂ [31]Â inÂ 2014.Â 
PIOÂ simulates Â pigeonÂ homingÂ usingÂ different Â searchÂ mechanisms Â atÂ different Â stages.Â 
TheÂ algorithm Â includesÂ twoÂ models:Â aÂ compass Â modelÂ andÂ aÂ landmark Â model.Â InÂ theÂ 
compass Â model,Â theÂ individual Â updatesÂ theÂ locationÂ according Â toÂ itsÂ previous Â locationÂ 
information Â andÂ theÂ currentÂ globalÂ optimalÂ locationÂ information. Â InÂ theÂ landmark Â operâ€
ator,Â onÂ theÂ basisÂ ofÂ halvingÂ theÂ numberÂ ofÂ groupsÂ inÂ eachÂ iteration, Â theÂ pigeonsÂ accelerâ€
ateÂ theÂ convergence Â rateÂ according Â toÂ theÂ averageÂ valueÂ ofÂ groupÂ fitness.Â PIOÂ hasÂ theÂ 
characteristics Â ofÂ fastÂ convergence Â andÂ highÂ searchÂ accuracy, Â andÂ hasÂ beenÂ widelyÂ usedÂ 
inÂ different Â fieldsÂ [32].Â 
Figure 4. (a) The distribution after random initialization; ( b) the distribution after initialization of the
chaotic map.
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 8 of 21
4.2.2. Adaptive Inertia Weighting Factor
According to the basic principle of the BOA, each individual updates or randomly
moves its position according to the current best individual position. Therefore, the position
of individual butterï¬‚ies is not fully utilized, and it is easy to become trapped in a local
optimum. When the inertia factor is large, the global search capability is strong, and vice
versa. Therefore, to address this issue, an adaptive inertia weighting factor was designed
to apply to the position update formula, so that the historical optimal position information
of the individual is fully utilized. Meanwhile, as the iterations grow in size, the direction
and distance of the individual are effectively controlled, so as to enhance the optimization
precision and convergence velocity, and avoid falling into local optima. The expression of
the inertia weighting factor is as follows:
!(t)=1 sintp
e+1Titer
(8)
where!is the adaptive inertia weight, Titeris the largest value of the number of iterations
t in the optimization process, and e is the Euler number.
The position update formula for the global search phase after the introduction of the
adaptive inertia weighting factor in BOA is as follows:
xt+1
i=!(t)xt
i+
r2g xt
i
fi (9)
The position update formula for the local search phase is as follows:
xt+1
i=!(t)xt
i+
r2xt
j xt
k
fi (10)
4.2.3. Pigeon-Inspired Optimization Algorithm Landmark Operator
Inspired by the nesting activity of pigeons, a new population intelligence optimization
algorithmâ€”the pigeon-inspired optimization (PIO) algorithmâ€”was ï¬rst proposed by
Duan [31] in 2014.
PIO simulates pigeon homing using different search mechanisms at different stages.
The algorithm includes two models: a compass model and a landmark model. In the
compass model, the individual updates the location according to its previous location
information and the current global optimal location information. In the landmark operator,
on the basis of halving the number of groups in each iteration, the pigeons accelerate the
convergence rate according to the average value of group ï¬tness. PIO has the characteristics
of fast convergence and high search accuracy, and has been widely used in different
ï¬elds [32].
The landmark model of PIO is as follows:
xt+1
i=xt
i+r 
xt
c xt
i
(11)
xt
c=Ã¥(xt
iFit(xt
i))
Nt
pÃ¥Fit 
xt
i (12)
Nt+1
p=Nt
p
2(13)
where xt
cis the position of the center of the ï¬‚ock in the current iteration, Fit(xt
i)is the
value of the ï¬tness function of the i-th pigeon, and Nt
pis the number of individuals. Other
variables are deï¬ned as in Equation (5).
In the BOA, the fragrance of butterï¬‚ies plays an important role in guiding individuals
to move to the optimal solution. However, if the population falls into the local optimal
position, it is prone to resulting in a stagnant search that does not lead to a globally optimal
resolution. Based on this problem, inspired by PIO, combined with the landmark model, a
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 9 of 21
new butterï¬‚y position update formula was constructed. Since the landmark model needs
to calculate the average ï¬tness of the group, compared with the compass model, not only is
the global search capability greatly enhanced, but also the convergence velocity is improved.
The improved butterï¬‚y position global search stage update formula is as follows:
xt+1
i=!(t)xt
i+
r2xt
j xt
k
fi+r 
xt
c xt
i
(14)
4.2.4. Adaptive Dynamic Switching
In the BOA, the switching between the local search stage and the global search stage
is controlled by the switching frequency p. The higher the value of the parameter p, the
greater the proportion of global search; the lower the value of p, the greater the proportion
of the local search. The value of p plays a key role in the subsequent search efï¬ciency and
convergence rate. To solve this problem, an adaptive dynamic switching frequency strategy
is proposed. The oscillation trigonometric function is introduced. The proportion of local
and global search stages is dynamically adjusted according to the number of iterations. The
random selection search phase is changed in such a way that global search is performed in
the early stage, while local search is performed in the middle and late stages.
S1(t)=(t+1)sin(wt) (15)
S2(t)=p
e ?((Titer t) +1)sin(w(Titer t)) (16)
where w and ?take the values 100* pand 2.55, respectively, while e is the Euler number. The
iterative process, as shown in Figure 5, enters the local search phase when |S1(t)| > |S 2(t)|,
and otherwise enters the global search phase, which can be experimentally proven to
converge faster and search more efï¬ciently.
SensorsÂ 2022,Â 22,Â xÂ FORÂ PEERÂ REVIEW Â  10Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 5.Â Switching Â betweenÂ globalÂ andÂ localÂ searchÂ phases.Â 
4.3.Â Simulation Â Experiments Â 
InÂ orderÂ toÂ verifyÂ thatÂ theÂ IBOAÂ hasÂ betterÂ performance Â inÂ termsÂ ofÂ convergence Â andÂ 
robustness, Â aÂ performance Â comparison Â experiment Â wasÂ carriedÂ outÂ basedÂ onÂ sixÂ testÂ 
functions: Â F1~F3Â areÂ unimodal Â functions Â toÂ testÂ theÂ convergence Â performance Â ofÂ theÂ alâ€
gorithm, Â whileÂ F4~F6Â areÂ complexÂ multimodal Â functions Â toÂ testÂ globalÂ optimization Â andÂ 
jumpÂ outÂ ofÂ localÂ optimization Â performance. Â TheÂ standard Â testÂ functionÂ information Â isÂ 
shownÂ inÂ TableÂ 1.Â 
InÂ orderÂ toÂ sufficiently Â validateÂ theÂ effectiveness Â ofÂ theÂ IBOA,Â theÂ comparative Â exâ€
periments Â wereÂ conducted Â withÂ mothâ€“flame Â optimization Â (MFO)Â [33],Â multiâ€verseÂ optiâ€
mization Â (MVO)Â [34],Â theÂ sineâ€“cosine Â algorithm Â (SCA)Â [35],Â theÂ salpÂ swarmÂ algorithm Â 
(SSA)Â [36],Â andÂ theÂ BOA.Â TheÂ numberÂ ofÂ iterations Â wasÂ 500,Â andÂ eachÂ methodÂ wasÂ runÂ 30Â 
timesÂ separately Â onÂ eachÂ testÂ functionÂ toÂ preventÂ biasÂ inÂ theÂ outcomes Â dueÂ toÂ randomÂ 
factors,Â asÂ detailedÂ inÂ TableÂ 2.Â 
ToÂ visuallyÂ demonstrate Â theÂ optimized Â capabilities Â ofÂ theÂ IBOA,Â theÂ iterativeÂ graphÂ ofÂ 
theÂ convergence Â curveÂ ofÂ theÂ sixÂ benchmark Â functions Â wasÂ selected,Â asÂ shownÂ inÂ FigureÂ 6.Â 
  
(a)Â  (b)Â 
Figure 5. Switching between global and local search phases.
4.3. Simulation Experiments
In order to verify that the IBOA has better performance in terms of convergence
and robustness, a performance comparison experiment was carried out based on six
test functions: F1~F3 are unimodal functions to test the convergence performance of
the algorithm, while F4~F6 are complex multimodal functions to test global optimization
and jump out of local optimization performance. The standard test function information is
shown in Table 1.
In order to sufï¬ciently validate the effectiveness of the IBOA, the comparative experi-
ments were conducted with mothâ€“ï¬‚ame optimization (MFO) [ 33], multi-verse optimization
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 10 of 21
(MVO) [ 34], the sineâ€“cosine algorithm (SCA) [ 35], the salp swarm algorithm (SSA) [ 36], and
the BOA. The number of iterations was 500, and each method was run 30 times separately
on each test function to prevent bias in the outcomes due to random factors, as detailed
in Table 2.
Table 1. Basic test function information.
Function Types Expressions Scope Optimal Value
UnimodalF1(x)=Ã¥n
i=1x2
i[ 100, 100] 0
F2(x)=Ã¥n
i=1
Ã¥n
j=1x2
j
[ 100, 100] 0
F3(x)=maxfjxi, 1injg [ 100, 100] 0
MultimodalF4(x)=Ã¥n
i=1
x2
i 10 cos (2xi)+10[ 5.12, 5.12] 0
F5(x)= 20expq
1
nÃ¥n
i=1x2
i
 exp1
n(Ã¥n
i=1(cos(2xi))+20+e) [ 32, 32] 0
F6(x)=1
4000Ã¥n
i=1x2
i Ã•n
i=1cosxip
i+1 [ 600, 600] 0
Table 2. Experimental results of the test functions.
Functions Algorithms Optimal Value Worst Value Average Value Standard Deviation
F1IBOA 0 0 0 0
MFO 6.9410 11.001041.351033.45103
MVO 5.9710 11.981001.261003.3910 1
SCA 6.0210 23.301022.981016.89101
SSA 3.0510 83.0410 62.7010 75.7710 7
BOA 1.0810 111.4510 111.2810 118.8110 13
F2IBOA 0 0 0 0
MFO 8.2410 56.671031.111032.29103
MVO 2.4410 22.4810 11.0710 15.5910 2
SCA 8.3210 96.7810 27.9010 31.7410 2
SSA 3.0910 91.9110 61.5010 73.7810 7
BOA 9.4610 121.3210 111.1210 119.0310 13
F3IBOA 0 0 0 0
MFO 2.9310 31.041012.421003.35100
MVO 3.3410 21.9810 19.9810 24.0810 2
SCA 4.8410 72.9910 22.3810 36.9210 3
SSA 1.4710 51.0210 42.8210 51.9410 5
BOA 4.2910 96.2310 95.3510 94.6010 10
F4IBOA 0 0 0 0
MFO 8.951008.461012.471011.61101
MVO 4.981003.381011.541017.15100
SCA 0.001001.271016.4210 12.58100
SSA 3.981004.181011.801018.62100
BOA 5.541005.611013.351011.94101
F5IBOA 8.8810 168.8810 168.8810 160
MFO 1.131002.001011.111018.60100
MVO 1.031003.361001.921004.9910 1
SCA 3.5310 22.031011.111019.62100
SSA 1.9210 14.621002.651008.9110 1
BOA 4.4910 96.8710 96.0110 95.2910 10
F6IBOA 0 0 0 0
MFO 4.6810 23.4910 11.5210 17.7410 2
MVO 1.3510 15.7710 13.3210 11.2010 1
SCA 6.0210 134.4910 18.1910 21.3410 1
SSA 6.6410 26.4410 12.4610 11.4910 1
BOA 4.6310 141.7510 117.2310 133.1810 12
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 11 of 21
To visually demonstrate the optimized capabilities of the IBOA, the iterative graph of
the convergence curve of the six benchmark functions was selected, as shown in Figure 6.
SensorsÂ 2022,Â 22,Â xÂ FORÂ PEERÂ REVIEW Â  10Â ofÂ 22Â 
Â 
Â Â 
FigureÂ 5.Â Switching Â betweenÂ globalÂ andÂ localÂ searchÂ phases.Â 
4.3.Â Simulation Â Experiments Â 
InÂ orderÂ toÂ verifyÂ thatÂ theÂ IBOAÂ hasÂ betterÂ performance Â inÂ termsÂ ofÂ convergence Â andÂ 
robustness, Â aÂ performance Â comparison Â experiment Â wasÂ carriedÂ outÂ basedÂ onÂ sixÂ testÂ 
functions: Â F1~F3Â areÂ unimodal Â functions Â toÂ testÂ theÂ convergence Â performance Â ofÂ theÂ alâ€
gorithm, Â whileÂ F4~F6Â areÂ complexÂ multimodal Â functions Â toÂ testÂ globalÂ optimization Â andÂ 
jumpÂ outÂ ofÂ localÂ optimization Â performance. Â TheÂ standard Â testÂ functionÂ information Â isÂ 
shownÂ inÂ TableÂ 1.Â 
InÂ orderÂ toÂ sufficiently Â validateÂ theÂ effectiveness Â ofÂ theÂ IBOA,Â theÂ comparative Â exâ€
periments Â wereÂ conducted Â withÂ mothâ€“flame Â optimization Â (MFO)Â [33],Â multiâ€verseÂ optiâ€
mization Â (MVO)Â [34],Â theÂ sineâ€“cosine Â algorithm Â (SCA)Â [35],Â theÂ salpÂ swarmÂ algorithm Â 
(SSA)Â [36],Â andÂ theÂ BOA.Â TheÂ numberÂ ofÂ iterations Â wasÂ 500,Â andÂ eachÂ methodÂ wasÂ runÂ 30Â 
timesÂ separately Â onÂ eachÂ testÂ functionÂ toÂ preventÂ biasÂ inÂ theÂ outcomes Â dueÂ toÂ randomÂ 
factors,Â asÂ detailedÂ inÂ TableÂ 2.Â 
ToÂ visuallyÂ demonstrate Â theÂ optimized Â capabilities Â ofÂ theÂ IBOA,Â theÂ iterativeÂ graphÂ ofÂ 
theÂ convergence Â curveÂ ofÂ theÂ sixÂ benchmark Â functions Â wasÂ selected,Â asÂ shownÂ inÂ FigureÂ 6.Â 
  
(a)Â  (b)Â 
SensorsÂ 2022,Â 22,Â xÂ FORÂ PEERÂ REVIEW Â  11Â ofÂ 22Â 
Â 
Â   
(c)Â  (d)Â 
  
(e) (f) 
FigureÂ 6.Â (a)Â Convergence Â curveÂ ofÂ functionÂ F1;Â (b)Â convergence Â curveÂ ofÂ functionÂ F2;Â (c)Â converâ€
genceÂ curveÂ ofÂ functionÂ F3;Â (d)Â convergence Â curveÂ ofÂ functionÂ F4;Â (e)Â convergence Â curveÂ ofÂ functionÂ 
F5;Â (f)Â convergence Â curveÂ ofÂ functionÂ F6.Â 
TableÂ 1.Â BasicÂ testÂ functionÂ information. Â 
Function Â TypesÂ  Expressions Â  ScopeÂ  Optimal Â ValueÂ 
Unimodal Â F1áˆºxáˆ»Â =Â âˆ‘ xà­§à¬¶ à­¬
à­§à­€à¬µÂ  [âˆ’100,100]Â  0Â 
F2áˆºxáˆ»Â =Â âˆ‘ áˆºâˆ‘ xà­¨à¬¶ à­¬
à­¨à­€à¬µ áˆ»à­¬
à­§à­€à¬µ Â  [âˆ’100,100]Â  0Â 
F3áˆºxáˆ»àµŒ m a x  áˆ¼ | x à­§,1 àµ‘ i â‰ª n | áˆ½ Â  [âˆ’100,100]Â  0Â 
Multimodal Â F4áˆºxáˆ»Â =Â âˆ‘ áˆ¾xà­§à¬¶àµ† 10 cos áˆº2Ï€x à­§áˆ»àµ…1 0 áˆ¿à­¬
à­§à­€à¬µ Â  [âˆ’5.12,5.12] Â  0Â 
F5áˆºxáˆ»Â =Â àµ†20 exp àµ¬ à¶§à°­
à±¤âˆ‘ xà­§à¬¶ à­¬
à­§à­€à¬µ àµ°àµ†e x pà°­
à±¤ áˆºâˆ‘ áˆºcos áˆº2Ï€x à­§áˆ»áˆ»àµ…2 0àµ…e áˆ»à­¬
à­§à­€à¬µ Â  [âˆ’32,32]Â  0Â 
F6áˆºxáˆ»Â =Â à°­
à°°à°¬à°¬à°¬âˆ‘ xà­§à¬¶àµ†âˆ cosà±®à±Ÿ
âˆšà±Ÿà­¬
à­§à­€à¬µ àµ…1à­¬à­§à­€à¬µÂ  [âˆ’600,600]Â  0Â 
TableÂ 2.Â Experimental Â resultsÂ ofÂ theÂ testÂ functions. Â 
Functions Â Algorithms Â  Optimal Â ValueÂ  WorstÂ ValueÂ  Average Â ValueÂ  Standard Â Deviation Â 
F1Â IBOAÂ  0Â  0Â  0Â  0Â 
MFOÂ  6.94Â Ã—Â 10âˆ’1Â  1.00Â Ã—Â 104Â  1.35Â Ã—Â 103Â  3.45Â Ã—Â 103Â 
MVOÂ  5.97Â Ã—Â 10âˆ’1Â  1.98Â Ã—Â 100Â  1.26Â Ã—Â 100Â  3.39Â Ã—Â 10âˆ’1Â 
SCAÂ  6.02Â Ã—Â 10âˆ’2Â  3.30Â Ã—Â 102Â  2.98Â Ã—Â 101Â  6.89Â Ã—Â 101Â 
Figure 6. (a) Convergence curve of function F1; ( b) convergence curve of function F2; ( c) convergence
curve of function F3; ( d) convergence curve of function F4; ( e) convergence curve of function F5;
(f) convergence curve of function F6.
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 12 of 21
4.4. Analysis of Simulation Experiment Results
When solving the minimum value problem, the average value is used to evaluate the
optimal ability and convergence precision, the standard deviation is used to evaluate the
robustness, and the best value and the worst value are used to evaluate the quality of the
feasible solution of the algorithm.
As shown in Table 2, in terms of optimal values, the IBOA does not signiï¬cantly
improve in the F5 function, but it still has a great progress trend compared with the basic
BOA, and the optimal value is found in other functions, indicating that the initialization of
the population position through chaotic mapping maintains the diversity of the algorithm.
From an average perspective, the IBOAâ€™s performance is far superior to that of other
algorithms, especially in the unimodal function, indicating that the new location up-
date equation combined with the pigeon swarm algorithm and the strategy of dynamic
search-stage switching not only accelerates the convergence speed, but also further en-
hances the quality of the reï¬ned search at a later stage, and greatly improves the overall
optimization ability.
From the perspective of standard deviation, the capability of the IBOA is signiï¬cantly
superior to that of other methods; the optimization ability is signiï¬cantly enhanced, and the
quality of the IBOAâ€™s feasible solutions is high, indicating that the introduction of the adap-
tive inertia weighting factor strategy in the position update equation effectively maintains
the population diversity, improves the global optimization ability, and maintains strong
robustness throughout the search process, so as to acquire the global optimal solution.
5. ERF Fault Detection Model Based on the IBOA
5.1. Data Pre-Processing
The operation process of the wind turbine gearbox is complex, the state quantity
generated is complex, and there are many redundant variables, increasing the complex-
ity of model training and affecting the prediction performance of the model [ 37]. As
illustrated in Figure 7b, it is important that the data gathered from the SCADA dataset
undergo preliminary data cleaning, and then Pearsonâ€™s correlation analysis is performed
to remove redundant feature values [ 38]. Pearsonâ€™s correlation coefï¬cient is illustrated
in Equation (17):
X,Y=cov(X, Y)
XY(17)
whererepresents the correlation coefï¬cient between features in the sample, represents
the standard deviation of the corresponding features, and covrepresents the covariance
between features.
Pearsonâ€™s correlation coefï¬cient is the upgrade of Euclidean distance, and provides
standard data input for the wind turbine gearbox fault detection model. Through Pearsonâ€™s
correlation analysis, redundant features with low partial correlation are removed, making
the model training more efï¬cient and the prediction results more accurate [39].
5.2. ERF Fault Detection Model Flowchart and Pseudocode Based on the IBOA
After Pearsonâ€™s correlation analysis, the dataset is divided into two categories: the
training dataset is utilized to train the classiï¬cation model, while the test dataset is utilized
for the prediction of the model, measuring the performance and classiï¬cation ability of the
model, and evaluating the modelâ€™s prediction performance.
The optimization of the IBOA parameters is shown in Figure 7. Firstly , the position and
sensory mode of each individual are initialized to obtain the best adaptive value of the group.
According to the adaptive dynamic switching, the local search or global search is selected.
The corresponding positionâ€™s iterative formula is used to update the individual position, and
the ERF model parameters are output to meet the iterative conditions. After obtaining the
ERF model parameters, the ERF fault detection model based on the IBOA (IBOA-ERF) is
constructed with the training data. The performance of the test model is tested by the real
class labels of the test dataset and the predicted class labels generated by the model.
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 13 of 21
SensorsÂ 2022,Â 22,Â xÂ FORÂ PEERÂ REVIEW Â  14Â ofÂ 22Â 
Â 
Â Start
Initializing Â butterfly Â 
population Â parameters Â 
(Â population Â size,Â iterationÂ 
number,Â sensoryÂ modality Â )
Initializing Â butterfly
Â population Â positionÂ withÂ theÂ 
chaoticÂ mapping Â byÂ theÂ 
Equation Â (7)
|S1(t)|Â >Â |S2(t)|Â 
UpdateÂ theÂ positions Â ofÂ 
currentÂ individual Â byÂ 
theÂ Equation Â (10)UpdateÂ theÂ positions Â ofÂ 
currentÂ individual Â byÂ 
theÂ Equation Â (14)
tÂ â‰¤Â MaxItersY NObtaining Â parameters Â ofÂ ERFÂ 
model
fitness(t) Â <Â fitness(tâ€1)
UpdateÂ theÂ solutionÂ 
vectorÂ ofÂ theÂ optimalÂ 
position
g*Y
UpdateÂ theÂ sensoryÂ 
modality
sNERFÂ FaultÂ Detection Â ModelSCADAÂ DatasetsInitializing Â butterfly Â 
population Â parameters, Â 
SCADAÂ Datasets
DataÂ preâ€processing
CurrentÂ optimalÂ solution
g*Calculate Â theÂ fitnessÂ ofÂ eachÂ 
butterfly Â individual
ChooseÂ aÂ wayÂ ofÂ positionÂ 
iteration
byÂ theÂ Equation Â (15)â€“(16)FindÂ theÂ currentÂ optimalÂ 
individual
g*
ERFÂ FaultÂ Detection Â ModelÂ 
optimalÂ parameters
endNtÂ =Â tÂ +Â 1Obtaining Â theÂ valueÂ ofÂ 
MAR,Â FAR
Y
Â 
(a)Â 
Figure 7. Cont .
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 14 of 21
Sensors 2022 , 22, x FOR PEER REVIEW 15 of 22 
 
 Training 
datasetTest datasetPearson correlation analysis
Splitting of pre-processed 
datasetsRemoval of redundant 
featuresSCADA Dataset
Data
pre-processThe dataset is
 a test set?
Y NSCADA
Dataset
Test
datasetTraining 
dataset  
(b) ( c) 
Figure 7. (a) The ï¬‚ow chart of IBOA to find the optimal parameters; ( b) the ï¬‚ow chart of Data 
pre-process; ( c) the ï¬‚ow chart of ERF Fault Detection Model. 
Table 3 shows the optimized ERF hyperparameters Ï„ and Î´ in the IBOA model, 
including the meanings and ranges of the parameters. 
Table 3. Selection of paramete rs for optimization. 
Parameter Meaning Value Range 
n_estimators ( Ï„) The number of decision trees in ERF [10, 1000] 
max_depth ( Î´) Maximum depth of the decision tree [10, 200] 
Algorithm 1 is the pseudo-code of the IBOA  modelâ€™s parameters. Algorithm 2 is the 
pseudo-code of ERF fault detection model us ing optimal parameters. The detailed opti-
mization process of the model hyperparameters is as follows: 
Algorithm 1.  The steps of IBOA optimization parameters. 
Input:  IBOA parameters ( lb(Ï„min, Î´min), ub(Ï„max, ğ›¿max); dimension: dim; maximum number of 
iterations: MaxIter ; population size: N; ERF parameters (ğœ, ğ›¿); 
Output:  g* (Ï„optimal, Î´optimal); 
1: x_train, y_train, x_test, y_test â†’ ERF (ğœ,ğ›¿) 
2: Initialize the butterfly population N (i = 1,2, ..., N)  
3: Calculate the fitness of each butterfly 4: 
g* (ğœ,ğ›¿) = the best individual 
5: Build the fitness function: fitness = FAR + ğœ€ * MAR  
6: While  t < MaxIter  
7:     for i = 1: N 
8 :          C a l c u l a t e  t h e  p e r c e i v e d  m a gnitude of the fragrance using Equation (4) 
9:     end for  
10:     Find the optimal butterfly individual g*  
11:     for i = 1:  N 
1 2 :          if |ğ‘†à¬µ(ğ‘¡)|>| ğ‘†à¬¶(ğ‘¡)| 
Figure 7. (a) The ï¬‚ow chart of IBOA to ï¬nd the optimal parameters; ( b) the ï¬‚ow chart of Data
pre-process; ( c) the ï¬‚ow chart of ERF Fault Detection Model.
Table 3 shows the optimized ERF hyperparameters andin the IBOA model, includ-
ing the meanings and ranges of the parameters.
Algorithm 1 is the pseudo-code of the IBOA modelâ€™s parameters. Algorithm 2 is
the pseudo-code of ERF fault detection model using optimal parameters. The detailed
optimization process of the model hyperparameters is as follows:
Algorithm 1. The steps of IBOA optimization parameters
Input: IBOA parameters ( lb(tmin,dmin),ub(tmax,dmax); dimension: dim; maximum number of
iterations: MaxIter ; population size: N; ERF parameters ( t,d);
Output: g* (toptimal ,doptimal );
1: x_train, y_train, x_test, y_test !ERF ( t,d)
2: Initialize the butterï¬‚y population N(i = 1, 2, . . . , N)
3: Calculate the ï¬tness of each butterï¬‚y
4: g* (t,d) = the best individual
5: Build the ï¬tness function: ï¬tness = FAR + #MAR
6: While t <MaxIter
7: fori = 1: N
8: Calculate the perceived magnitude of the fragrance using Equation (4)
9: end for
10: Find the optimal butterï¬‚y individual g*
11: fori = 1: N
12: ifjS1(t)j>jS2(t)j
13: Enter the local search phase based on Equation (10)
14: else
15: Enter the global search phase based on Equation (14)
16: end if
17: end for
18: Check if each butterï¬‚y exceeds the search space and correct for it
19: Calculate the ï¬tness of each butterï¬‚y
20: Select the location that matches the minimum ï¬tness value
21: Update the value of a
22: If a better solution is available, update g*
23: t = t + 1
24: end while
25: return g* (toptimal ,doptimal )
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 15 of 21
Algorithm 2. ERF Fault Detection Model
Input: the best parameter vector g* (toptimal ,doptimal ); Training dataset; Test dataset;
Output: MAR, FAR
1: Training dataset !x_train, y_train
2: Test dataset !x_test, y_test
3: x_train, y_train !ERF ( toptimal ,doptimal )
4: Training ERF fault detection model using Training dataset
5: x_test, y_test !ERF ( toptimal ,doptimal )
6: Testing ERF fault detection model using Test dataset
7: Obtaining predicted labels of test datasets
8: Calculating MAR and FAR of model performance based on Equations (18) and (19)
9: return MAR, FAR
Table 3. Selection of parameters for optimization.
Parameter Meaning Value Range
n_estimators () The number of decision trees in ERF [10, 1000]
max_depth () Maximum depth of the decision tree [10, 200]
6. Experimental Analysis
6.1. Dataset Description
To validate the validation of the proposed IBOA-ERF fault detection model, the annual
gearbox operation data were extracted from the SCADA dataset with an interval of 1 min
for a 1.5 MW wind turbine in China, and the data structure was selected from 30 min before
the occurrence of the gearbox fault to 30 min after the end of the fault through the analysis
of the wind turbine structure, as shown in Table 4.
Table 4. Partial data of wind turbine operation.
FeaturesTime
18:12 18:13 18:14 . . .. 19:40 19:41 19:42
nacelle_temperature  8.5 8.7 8.8 . . . . 9.3 9.5 9.8
wind_speed_1 10.01 9.94 9.34 . . . . 5.92 6.12 6.01
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
hydraulic_main_sys_pressure 135.87 136.18 135.26 . . . . 144.72 144.72 144.11
hydraulic_rotor_brake_sys_pressure 149.30 148.69 149.90 . . . . 170.36 170.05 170.05
For the purposes of the dataset, as illustrated in Table 5, the dataset can be divided
into two parts: Dataset 1, with data on gearbox supercapacitor overtemperature faults and
fault-free data; and Dataset 2, with data on gearbox nacelle operation overspeed faults and
fault-free data.
Table 5. Description of the datasets.
Dataset Fault-Free FaultyTotal Number of
SamplesTotal Number of
Features
Dataset 1 1059 991 2050 210
Dataset 2 1211 1080 2291 210
6.2. Criteria for Evaluation
For the dichotomous problem of wind turbine gearbox fault detection, a confusion
matrix was introduced. As illustrated in Table 6, the missing alarm rate (MAR) and the
false alarm rate (FAR) of the matrix were utilized as evaluation indices.
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 16 of 21
Table 6. Confusion matrix for binary classiï¬cation problems.
Actual CategoryPredict Category
Normal Fault
Normal S TN(true negative) S FP(false positive)
Fault S FN(false negative) S TP(true positive)
MAR =SFN
SFN+STP(18)
FAR=SFP
SFP+STN(19)
where S FN, SFP, STN, and S TPrepresent the corresponding sample size.
To validate the excellence of ERF under the IBOA for the above extracted dataset, after
data pre-processing, it was compared with the ERF model under MFO, MVO, SSA, SCA,
and BOA optimization, and evaluated the performance of each model using MAR and FAR.
Lower values of MAR and FAR represent better performance of the model. In order to
prevent overï¬tting and improve model accuracy, each model was trained using 10-level
cross-validation when conducting the comparison experiments. At the same population
size and number of iterations, each model was run 10 times individually.
6.3. Experimental Results
When comparing the MAR and FAR of the ERF model under different optimization
algorithms, IBOA-ERF performed better than the other ï¬ve models.
For Dataset 1, as shown in Figure 8a, for the MAR of the six models, the average MAR
of IBOA-ERF running 10 times alone was 0.86%, which is signiï¬cantly improved compared
with the BOA algorithm, and the fault detection ability is very stable. The overall MAR was
maintained at 0.72â€“0.98%, while that of the other models was maintained at 0.84â€“1.53%.
The optimization ability and optimization accuracy of the model were greatly improved.
As shown in Figure 8b, for the FAR of the six models, the average FAR of IBOA-ERF
running alone 10 times was 5.30%. During the detection process, the FAR of MFO-ERF
was up to 9.23%, and the optimization effect was not obvious, while that of IBOA-ERF was
maintained between 4.87% and 5.91%, and the detection performance was very stable. This
shows that the ERF model has lower MAR and FAR, and the convergence efï¬ciency and
optimization performance are greatly improved when using the optimization parameters
of the IBOA.
For Dataset 2, as shown in Figure 8c, the MAR of the ERF model under the IBOA had
a maximum decrease of 1.06% compared to the other ï¬ve models, showing less ï¬‚uctuation
than the classiï¬cation results of the other modelsâ€”which were generally maintained
between 0.54% and 0.77%â€”along with signiï¬cantly improved detection performance
compared to the other models. As shown in Figure 8d, the FAR of the ERF model under
the IBOA was generally stable between 4.97% and 6.65%, while the FAR of the other ï¬ve
models mostly remained above 6.13%, with the maximum reaching 9.75%. The IBOA
has obvious optimization effects, is not prone to becoming trapped in partial optima, and
shows greatly improved accuracy.
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 17 of 21
Sensors 2022 , 22, x FOR PEER REVIEW  18 of 22 
 
 mode ls mostly remain ed above 6.1 3%, with the maximum reaching 9.75%. The IBOA has 
obvious optimization effects, is not prone to be coming  trapped in partial optim a, and 
shows greatly improved accuracy.  
  
(a) (b) 
  
(c) (d) 
Figure 8. (a) MAR of six algorithms for fault detection on Dataset 1; ( b) FAR of six algorithms for 
fault detection on Dataset 1; ( c) MAR of six algorithms for fault detection on Dataset 2; ( d) FAR of 
six algorithms for fault detection on Dataset 2 . 
7. Conclusion s 
Aiming at the difficulty of parameter optimization of wind turbine gearbox fault 
detection model s, the IBOA -ERF fault detection model was proposed. The IBOA was 
used to optimize the hyperparameters  of ERF, so as to improve the detection perfor-
mance.  
There are four main contributions of this paper : First, chaotic map ping  is introduced 
to replace the original population initialization method to enhance the randomness of the 
population distribution and enhance the local development and global exploration ca-
pabilities. Second, the adaptive inertia weight factor is designed  and combined with the 
landmark operator of PIO, so that the best position information of individual history is 
more effectively used, and it is integrated into the position update formula to i mprove 
the diversity and robustness of  the BOA. Third, a new dynamic switching method of the 
search stage is designed, so that two search phases  can reach a dynamic balance, pre-
vent ing a drop into local  optim a and accelerat ing convergence. Finally, an impr oved fault 
detection model for wind turbine gearboxes is proposed by combining the above strate-
gies with ERF.  
Figure 8. (a) MAR of six algorithms for fault detection on Dataset 1; ( b) FAR of six algorithms for
fault detection on Dataset 1; ( c) MAR of six algorithms for fault detection on Dataset 2; ( d) FAR of six
algorithms for fault detection on Dataset 2.
7. Conclusions
Aiming at the difï¬culty of parameter optimization of wind turbine gearbox fault
detection models, the IBOA-ERF fault detection model was proposed. The IBOA was used
to optimize the hyperparameters of ERF, so as to improve the detection performance.
There are four main contributions of this paper: First, chaotic mapping is introduced
to replace the original population initialization method to enhance the randomness of
the population distribution and enhance the local development and global exploration
capabilities. Second, the adaptive inertia weight factor is designed and combined with the
landmark operator of PIO, so that the best position information of individual history is
more effectively used, and it is integrated into the position update formula to improve the
diversity and robustness of the BOA. Third, a new dynamic switching method of the search
stage is designed, so that two search phases can reach a dynamic balance, preventing a
drop into local optima and accelerating convergence. Finally, an improved fault detection
model for wind turbine gearboxes is proposed by combining the above strategies with ERF.
In the experiments, MFO, MVO, SSA, SCA, BOA, and IBOA were introduced to
enhance experimental fairness, each used to act on the ERF model, and the ï¬tness function
was constructed. MAR and FAR were used as assessment indicators. The results indicate
that when using the IBOA to optimize the ERF parameters, the MAR and FAR are still low
when the dataset is complex and the dimensionality is high.
Based on the proposed IBOA-ERF wind turbine gearbox fault detection model, the
recommendations for future research are as follows:
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 18 of 21
 When the data categories are unbalancedâ€”that is, when there are many normal
samples and few fault samplesâ€”further research can be conducted to solve the prob-
lem of the model detection being biased towards the majority of samples, and the
classiï¬cation accuracy is reduced.
 With the upgrading of the wind turbine gearbox technology, the feature dimension-
ality and complexity of the original dataset can increase. There are many data pre-
processing methods and no uniform measurement, which can inï¬‚uence the implemen-
tation of the model. The data pre-processing methods that are most suitable for this
model can be further studied.
 The IBOA can be applied to other fault detection ï¬elds.
Author Contributions: Supervision, M.T.; writingâ€”original draft, C.C.; formal analysis, H.W.;
investigation, H.Z.; data curation, J.T.; conceptualization, Z.P .; visualization, Y.W. All authors have
read and agreed to the published version of the manuscript.
Funding: This work was supported in part by the National Natural Science Foundation of China
(grant no. 62173050), the National Key R&D Program of China (grant no. 2019YFE0105300), the Energy
Conservation and Emission Reduction Hunan University Student Innovation and Entrepreneurship
Education Center, Changsha University of Science and Technologyâ€™s â€œThe Double First Class Univer-
sity Planâ€ International Cooperation and Development Project in Scientiï¬c Research in 2018 (Grant
No. 2018IC14), the Hunan Provincial Department of Transportationâ€™s 2018 Science and Technology
Progress and Innovation Plan Project (grant no. 201843), the Hubei Superior and Distinctive Dis-
cipline Group of â€œNew Energy Vehicle and Smart Transportationâ€, the Open Fund of Hubei Key
Laboratory of Power System Design and Test for Electrical Vehicle (grant no. ZDSYS202201), General
Projects of Hunan University Studentsâ€™ Innovation and Entrepreneurship Training Program in 2022
(grant no. 2565), and the Graduate Scientiï¬c Research Innovation Project of Changsha University of
Science and Technology (grant no. CXCLY2022094).
Institutional Review Board Statement: Not applicable.
Informed Consent Statement: Not applicable.
Data Availability Statement: The data that support the ï¬ndings of this study are available from the
corresponding author upon reasonable request.
Conï¬‚icts of Interest: The authors declare no conï¬‚ict of interest.
Nomenclature and Abbreviations
GWEC Global Wind Energy Council
SCADA Supervisory control and data acquisition
NFSW-BP-AdaBoost Non-fuzzy solution-weighted BP-AdaBoost
XGBoost Extreme gradient boosting
CS-GBDT Cost-sensitive GBDT
RF Random forest
ERF Extreme random forest
BOA Butterï¬‚y optimization algorithm
IBOA Improved butterï¬‚y optimization algorithm
IBOA-ERF Extreme random forest optimized by improved butterï¬‚y
optimization algorithm
PIO Pigeon-inspired optimization
MFO Mothâ€“ï¬‚ame optimization
MVO Multi-verse optimization
SCA Sineâ€“cosine algorithm
SSA Salp swarm algorithm
UCI University of California Irvine
FAR False alarm rate
MAR Missing alarm rate
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 19 of 21
Symbols
D Number of numbers in ERF
Pt(cjVi) The probability that the sample belongs to category c conditional on the
feature vector V i
Vi Feature vector of the sample
P(cjVi) Average value of P t(cjVi)in the ERF
c Some kind of category
Ë†c Category corresponding to the maximum value of P (cjfi)
Ik Mutual information of the two subsets
Hk Split entropy of the feature k
Hc Information entropy
Score k Score measurement of the calculated feature
f Fragrance intensity
I Stimulus intensity
s Sensory modality
 Power exponent
xt
iLocation information of the i-th individual in the t-th iteration
xt+1
iLocation information of the i-th individual in the t + 1-th iteration
r Random value from 0 to 1
gBest value in the current iteration
fi Fragrance intensity emitted by the i-th individual
j Random number
k Random number
X Position parameter
t Current number of iterations
 Logistics parameter
Titer Largest value of the number of iterations t
! Adaptive inertia weight
e Euler number
xtc Position of the center of the ï¬‚ock in the current iteration
Fit 
xt
i
Value of the ï¬tness function of the i-th individual
N Number of individuals
? 100*p
cov Covariance
 Standard deviation
 Correlation coefï¬cient
S Corresponding sample size
References
1. GWEC. Global Wind Energy Council (GWEC)|Global Wind Report. 2022. Available online: https://gwec.net/global-wind-
report-2022/ (accessed on 4 April 2022).
2. Han, Z.; Liu, Z.; Kang, W.; He, W. Boundary Feedback Control of a Nonhomogeneous Wind Turbine Tower with Exogenous
Disturbances. IEEE Trans. Autom. Control 2022 ,67, 1952â€“1959. [CrossRef]
3. Liu, Z.; Zhang, L. Zhang. A review of failure modes, condition monitoring and fault diagnosis methods for large-scale wind
turbine bearings. Measurement 2020 ,149, 107002. [CrossRef]
4. Jiang, G.; He, H.; Yan, J.; Xie, P . Multiscale Convolutional Neural Networks for Fault Diagnosis of Wind Turbine Gearbox. IEEE
Trans. Ind. Electron. 2019 ,66, 3196â€“3207. [CrossRef]
5. Qin, Y.; Wang, X.; Zou, J. The Optimized Deep Belief Networks with Improved Logistic Sigmoid Units and Their Application in
Fault Diagnosis for Planetary Gearboxes of Wind Turbines. IEEE Trans. Ind. Electron. 2019 ,66, 3814â€“3824. [CrossRef]
6. Tang, M.; Zhao, Q.; Ding, S.X.; Wu, H.; Li, L.; Long, W.; Huang, B. An Improved LightGBM Algorithm for Online Fault Detection
of Wind Turbine Gearboxes. Energies 2020 ,13, 807. [CrossRef]
7. Tang, M.; Yi, J.; Wu, H.; Wang, Z. Fault Detection of Wind Turbine Electric Pitch System Based on IGWO-ERF. Sensors 2021 ,21,
6215. [CrossRef]
8. Tang, M.; Zhao, Q.; Wu, H.; Wang, Z. Cost-Sensitive LightGBM-Based Online Fault Detection Method for Wind Turbine Gearboxes.
Front. Energy Res. 2021 ,9, 378. [CrossRef]
9. Wang, D.; Zhao, Y.; Yi, C.; Tsui, K.L.; Lin, J. Sparsity guided empirical wavelet transform for fault diagnosis of rolling element
bearings. Mech. Syst. Signal Process. 2018 ,101, 292â€“308. [CrossRef]
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 20 of 21
10. Chen, H.; Jiang, B.; Ding, S.X.; Huang, B. Huang. Data-Driven Fault Diagnosis for Traction Systems in High-Speed Trains: A
Survey, Challenges, and Perspectives. IEEE Trans. Intell. Transp. Syst. 2022 ,23, 1700â€“1716. [CrossRef]
11. Wang, Y.; Pan, Z.; Yuan, X.; Yang, C.; Gui, W. A novel deep learning based fault diagnosis approach for chemical process with
extended deep belief network. ISA Trans. 2020 ,96, 457â€“467. [CrossRef]
12. Liang, J.; Qin, Z.; Xiao, S.; Ou, L.; Lin, X. Efï¬cient and Secure Decision Tree Classiï¬cation for Cloud-Assisted Online Diagnosis
Services. IEEE Trans. Dependable Secur. Comput. 2021 ,18, 1632â€“1644. [CrossRef]
13. Stetco, A.; Dinmohammadi, F.; Zhao, X.; Robu, V .; Flynn, D.; Barnes, M.; Nenadic, G. Machine learning methods for wind turbine
condition monitoring: A review. Renew. Energy 2019 ,133, 620â€“635. [CrossRef]
14. Feng, D.C.; Liu, Z.T.; Wang, X.D.; Chen, Y.; Chang, J.Q.; Wei, D.F.; Jiang, Z.M. Machine learning-based compressive strength
prediction for concrete: An adaptive boosting approach. Constr. Build. Mater. 2020 ,230, 117000. [CrossRef]
15. Jiang, H.W.; Zou, B.; Xu, C.; Xu, J.; Tang, Y.Y. SVM-Boosting based on Markov resampling: Theory and algorithm. Neural Netw.
2016 ,131, 276â€“290. [CrossRef] [PubMed]
16. Liu, Y.; Zhao, C.C.; Liang, H.Y.; Lu, H.H.; Cui, N.Y.; Bao, K.Y. A rotor fault diagnosis method based on BP-Adaboost weighted by
non-fuzzy solution coefï¬cients. Measurement 2022 ,196, 111280. [CrossRef]
17. Chakraborty, D.; Elzarka, H. Early detection of faults in HVAC systems using an XGBoost model with a dynamic threshold.
Energy Build. 2019 ,185, 326â€“344. [CrossRef]
18. Xu, Q.F.; Lu, S.X.; Jia, W.Y.; Jiang, C.X. Imbalanced fault diagnosis of rotating machinery via multi-domain feature extraction and
cost-sensitive learning. J. Intell. Manuf. 2020 ,31, 1467â€“1481. [CrossRef]
19. Yang, L.; Shami, A. On hyperparameter optimization of machine learning algorithms: Theory and practice. Neurocomputing 2020 ,
415, 295â€“316. [CrossRef]
20. Yang, X.S. Nature-inspired optimization algorithms: Challenges and open problems. J. Comput. Sci. 2020 ,46, 101104. [CrossRef]
21. Arora, S.; Singh, S. Butterï¬‚y optimization algorithm: A novel approach for global optimization. Soft Comput. 2019 ,23, 715â€“734.
[CrossRef]
22. Luo, J.; Tian, Q.; Xu, M. Reverse guidance butterï¬‚y optimization algorithm integrated with information cross-sharing. J. Intell.
Fuzzy Syst. 2021 ,41, 3463â€“3484. [CrossRef]
23. Neshat, M.; Nezhad, M.M.; Abbasnejad, E.; Mirjalili, S.; Tjernberg, L.B.; Garcia, D.A.; Alexander, B.; Wagner, M. A deep learning-
based evolutionary model for short-term wind speed forecasting: A case study of the Lillgrund offshore wind farm. Energy
Convers. Manag. 2021 ,236, 114002. [CrossRef]
24. Song, D.R.; Li, Z.Q.; Wang, L.; Jin, F.J.; Huang, C.E.; Xia, E.; Rizk-Allah, R.M.; Yang, J.; Su, M.; Joo, Y.H. Energy capture efï¬ciency
enhancement of wind turbines via stochastic model predictive yaw control based on intelligent scenarios generation. Appl Energy
2022 ,312, 118773. [CrossRef]
25. Song, D.R.; Tu, Y.P .; Wang, L.; Jin, F.J.; Li, Z.Q.; Huang, C.N.; Xia, E.; Rizk-Allah, R.M.; Yang, J.; Su, M.; et al. Coordinated
optimization on energy capture and torque ï¬‚uctuation of wind turbines via variable weight NMPC with fuzzy regulator. Appl.
Energy 2022 ,312, 118821. [CrossRef]
26. Azamfar, M.; Singh, J.; Bravo-Imaz, I.; Lee, J. Multisensor data fusion for gearbox fault diagnosis using 2-D convolutional neural
network and motor current signature analysis. Mech. Syst. Signal Process. 2020 ,144, 106861. [CrossRef]
27. Long, W.; Jiao, J.J.; Liang, X.M.; Wu, T.B.; Xu, M.; Cai, S.H. Pinhole-imaging-based learning butterï¬‚y optimization algorithm for
global optimization and feature selection. Appl. Soft Comput. 2021 ,103, 107146. [CrossRef]
28. Long, W.; Wu, T.B.; Xu, M.; Tang, M.Z.; Cai, S.H. Parameters identiï¬cation of photovoltaic models by using an enhanced adaptive
butterï¬‚y optimization algorithm. Energy 2021 ,229, 120750. [CrossRef]
29. Zhang, Y.Q.; Wang, X.Y. A symmetric image encryption algorithm based on mixed linear-nonlinear coupled map lattice. Inf. Sci.
2014 ,273, 329â€“351. [CrossRef]
30. Hua, Z.Y.; Zhou, Y.C. Exponential Chaotic Model for Generating Robust Chaos. IEEE Trans. Syst. Man Cybern.-Syst. 2021 ,51,
3713â€“3724. [CrossRef]
31. Duan, H.B.; Wang, X.H. Echo State Networks with Orthogonal Pigeon- Inspired Optimization for Image Restoration. IEEE Trans.
Neural Netw. Learn. Syst. 2016 ,27, 2413â€“2425. [CrossRef]
32. Cui, Z.H.; Zhang, J.J.; Wang, Y.C.; Cao, Y.; Cai, X.; Zhang, W.J.; Chen, J.J. A pigeon-inspired optimization algorithm for
many-objective optimization problems. Sci. China-Inf. Sci. 2019 ,62, 70212. [CrossRef]
33. Shehab, M.; Abualigah, L.; al Hamad, H.; Alabool, H.; Alshinwan, M.; Khasawneh, A.M. Moth-ï¬‚ame optimization algorithm:
Variants and applications. Neural Comput. Appl. 2020 ,32, 9859â€“9884. [CrossRef]
34. Mirjalili, S.; Mirjalili, S.M.; Hatamlou, A. Multi-Verse Optimizer: A nature-inspired algorithm for global optimization. Neural
Comput. Appl. 2016 ,27, 495â€“513. [CrossRef]
35. Abualigah, L.; Diabat, A. Advances in Sine Cosine Algorithm: A comprehensive survey. Artif. Intell. Rev. 2021 ,54, 2567â€“2608.
[CrossRef]
36. Mirjalili, S.; Gandomi, A.H.; Mirjalili, S.Z.; Saremi, S.; Faris, H.; Mirjalili, S.M. Salp Swarm Algorithm: A bio-inspired optimizer
for engineering design problems. Adv. Eng. Softw. 2017 ,114, 163â€“191. [CrossRef]
37. Zhang, K.; Peng, K.; Dong, J. A Common and Individual Feature Extraction-Based Multimode Process Monitoring Method with
Application to the Finishing Mill Process. IEEE Trans. Ind. Inform. 2018 ,14, 4841â€“4850. [CrossRef]
------------------------------End of the page -----------------------------------
Sensors 2022 ,22, 6826 21 of 21
38. Langfelder, P .; Horvath, S. Fast R Functions for Robust Correlations and Hierarchical Clustering. J. Stat. Softw. 2012 ,46, 1â€“17.
[CrossRef]
39. Zhang, K.; Peng, K.X.; Ding, S.X.; Chen, Z.W.; Yang, X. A Correlation-Based Distributed Fault Detection Method and Its
Application to a Hot Tandem Rolling Mill Process. IEEE Trans. Ind. Electron. 2020 ,67, 2380â€“2390. [CrossRef]
------------------------------End of the page -----------------------------------
